{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfFdqimUXDRe",
        "outputId": "7cb45998-ba19-49f3-edd2-310d98dd46ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379374 sha256=0cef5187bed4ee086b8bebabc5df61be4ac79d71cbef17f61658b942f6442f32\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NVhfea7VWizX"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"BipedalWalker-v3\", hardcore=True, render_mode=\"rgb_array\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqLAo19LW_Vi",
        "outputId": "d4e2843f-84e3-4163-a440-62acdccde87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24,)\n",
            "(4,)\n",
            "[-1. -1. -1. -1.] [1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space.shape)\n",
        "print(env.action_space.shape)\n",
        "print(env.action_space.low, env.action_space.high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I2X0fZvo_WJO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.distributions import MultivariateNormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AV1gw55VMrta"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed_5iB0xXuv5",
        "outputId": "3588ca93-ab72-4a28-e2f2-a731dffed58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to : cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "    device = torch.device('cuda:0')\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RbTiurYbajRq"
      },
      "outputs": [],
      "source": [
        "class ActorCritic(nn.Module):\n",
        "  def __init__(self, state_dim, action_dim, action_std):\n",
        "    super(ActorCritic, self).__init__()\n",
        "    self.state_dim = state_dim\n",
        "    self.action_dim = action_dim\n",
        "    self.action_std = action_std\n",
        "    self.action_variance = torch.full((action_dim,), action_std*action_std).to(device) # Corrected size to be a tuple (action_dim,)\n",
        "    self.actor = nn.Sequential(\n",
        "        nn.Linear(state_dim, 512),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(256, action_dim),\n",
        "    )\n",
        "    self.critic = nn.Sequential(\n",
        "        nn.Linear(state_dim, 512),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(256, 1)\n",
        "    )\n",
        "    # Initialize the weights of the last layer of the actor\n",
        "    self.actor[-1].weight.data.mul_(0.1)\n",
        "    # Initialize log_std as a parameter\n",
        "    self.log_std = nn.Parameter(torch.zeros(action_dim))\n",
        "\n",
        "\n",
        "  def set_action_variance(self, new_action_std):\n",
        "    self.action_variance = torch.full((self.action_dim,), new_action_std*new_action_std).to(device) # Corrected size to be a tuple (self.action_dim,)\n",
        "\n",
        "  def forward(self):\n",
        "    pass\n",
        "  def act(self, state):\n",
        "    action_mean = self.actor(state) # Get action mean directly from the actor network\n",
        "    action_mean = F.tanh(action_mean)\n",
        "    std = torch.exp(self.log_std)\n",
        "    covariance_matrix = torch.diag(std ** 2).unsqueeze(0) #covariance diagonal matrix with added dimension of shape action_dim*action_dim and value action_variance\n",
        "    distribution = MultivariateNormal(action_mean, covariance_matrix) # to allow exploration as it enables sampling actions and computing probabilites in continuous action spaces\n",
        "    action = distribution.sample() #tensor of shape action_dim\n",
        "    action_log_probs = distribution.log_prob(action) #log of probability of the action needed for gradient updates while learning\n",
        "    state_values = self.critic(state)\n",
        "    return action.detach(), action_log_probs.detach(), state_values.detach()\n",
        "  def evaluate(self, state, action):\n",
        "    action_mean = self.actor(state)\n",
        "    action_var = self.action_variance.expand_as(action_mean)\n",
        "    cov_mat = torch.diag_embed(action_var).to(device)\n",
        "    dist = MultivariateNormal(action_mean, cov_mat)\n",
        "    if self.action_dim == 1:\n",
        "      action = action.reshape(-1, self.action_dim)\n",
        "    action_logprobs = dist.log_prob(action)\n",
        "    dist_entropy = dist.entropy().mean() #entropy to allow exploration\n",
        "    state_values = self.critic(state)\n",
        "    return action_logprobs, state_values, dist_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XTeL_daNNX6W"
      },
      "outputs": [],
      "source": [
        "class RolloutBuffer:\n",
        "  def __init__(self):\n",
        "    self.actions = []\n",
        "    self.states = []\n",
        "    self.rewards = []\n",
        "    self.log_probs = []\n",
        "    self.entropy = []\n",
        "    self.state_values = []\n",
        "    self.is_terminals = []\n",
        "  def clear(self):\n",
        "    del self.actions[:]\n",
        "    del self.states[:]\n",
        "    del self.rewards[:]\n",
        "    del self.log_probs[:]\n",
        "    del self.entropy[:]\n",
        "    del self.state_values[:]\n",
        "    del self.is_terminals[:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4j2mDTwloVvC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "olcOYItXxJX1"
      },
      "outputs": [],
      "source": [
        "class PPO:\n",
        "  def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma,K_epochs ,eps_clip, action_std = 0.6):\n",
        "    self.lr_actor = lr_actor\n",
        "    self.lr_critic = lr_critic\n",
        "    self.gamma = gamma\n",
        "    self.eps_clip = eps_clip\n",
        "    self.action_std = action_std\n",
        "    self.K_epochs = K_epochs\n",
        "    self.entropy_coef = 0.01\n",
        "    self.entropy_coef_start = 0.01\n",
        "    self.entropy_coef_end = 0.001\n",
        "    self.entropy_decay_steps = 3e6\n",
        "\n",
        "\n",
        "    self.buffer = RolloutBuffer()  #create buffer instance\n",
        "    self.policy = ActorCritic(state_dim, action_dim, action_std).to(device) #define policy network\n",
        "    self.optimizer = torch.optim.Adam([\n",
        "        {'params': self.policy.actor.parameters(), 'lr': self.lr_actor},\n",
        "        {'params': self.policy.critic.parameters(), 'lr': self.lr_critic}\n",
        "    ]) # set optimizers for both actor and critic networks\n",
        "    self.policy_old = ActorCritic(state_dim, action_dim, action_std).to(device) #old policy (frozen) for computin loss\n",
        "    self.policy_old.load_state_dict(self.policy.state_dict()) # save weights of current policy network to old policy\n",
        "\n",
        "    self.MseLoss = nn.MSELoss() #define loss function for critic loss\n",
        "  def set_action_std(self, new_action_std): #set new action standard deviation (exploration noise level)\n",
        "    self.action_std = new_action_std\n",
        "    self.policy.set_action_variance(new_action_std) #update action variance inside both policies\n",
        "    self.policy_old.set_action_variance(new_action_std)\n",
        "\n",
        "  def decay_action_std(self, action_std_decay_rate, min_action_std): # gradually decay the action standard deviation to reduce exploration over time\n",
        "    self.action_std = self.action_std*0.9995 #reduce current std dev by decay rate\n",
        "    self.action_std = round(self.action_std, 4)\n",
        "    if(self.action_std < min_action_std): #ensure it doesnt go below minimum\n",
        "      self.action_std = min_action_std\n",
        "    print(\"setting action_std to \", self.action_std)\n",
        "    self.policy.set_action_variance(self.action_std) #apply new std dev to current policy\n",
        "  def select_action(self, state): # to select action based on action values and probs received\n",
        "    with torch.no_grad(): #disable gradient compute\n",
        "      state = torch.FloatTensor(state).to(device) #tensor of current state\n",
        "      action, action_log_probs, state_values = self.policy_old.act(state) #get action values, probs and state value based on previous state\n",
        "      self.buffer.states.append(state)\n",
        "      self.buffer.actions.append(action)\n",
        "      self.buffer.log_probs.append(action_log_probs)\n",
        "      self.buffer.state_values.append(state_values) #store values in buffer for training\n",
        "\n",
        "      return action.detach().cpu().numpy().flatten() #convert action tensor to numpy array, detach from computation graph, flatten to 1D array.\n",
        "\n",
        "  def update(self):\n",
        "    rewards = []\n",
        "    discounted_reward = 0\n",
        "\n",
        "    for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "        if is_terminal:\n",
        "            discounted_reward = 0\n",
        "        discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "        rewards.insert(0, discounted_reward)\n",
        "\n",
        "    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "\n",
        "    old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "    old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "    old_log_probs = torch.squeeze(torch.stack(self.buffer.log_probs, dim=0)).detach().to(device)\n",
        "    old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
        "\n",
        "    # GAE-Lambda Advantage Estimation\n",
        "    advantages = []\n",
        "    gae = 0\n",
        "    next_value = 0\n",
        "    for t in reversed(range(len(rewards))):\n",
        "        delta = rewards[t] + self.gamma * next_value * (1 - int(self.buffer.is_terminals[t])) - old_state_values[t]\n",
        "        gae = delta + self.gamma * 0.95 * (1 - int(self.buffer.is_terminals[t])) * gae\n",
        "        advantages.insert(0, gae)\n",
        "        next_value = old_state_values[t]\n",
        "    advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n",
        "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-6)\n",
        "\n",
        "    # PPO update with mini-batch training\n",
        "    batch_size = old_states.size(0)\n",
        "    mini_batch_size = 512\n",
        "\n",
        "    for _ in range(self.K_epochs):\n",
        "        # Shuffle the indices\n",
        "        indices = torch.randperm(batch_size)\n",
        "\n",
        "        for start in range(0, batch_size, mini_batch_size):\n",
        "            end = start + mini_batch_size\n",
        "            mb_idx = indices[start:end]\n",
        "\n",
        "            states = old_states[mb_idx]\n",
        "            actions = old_actions[mb_idx]\n",
        "            old_log_probs_mb = old_log_probs[mb_idx]\n",
        "            advantages_mb = advantages[mb_idx]\n",
        "            rewards_mb = rewards[mb_idx]\n",
        "            old_state_values_mb = old_state_values[mb_idx]\n",
        "\n",
        "            log_probs, state_values, dist_entropy = self.policy.evaluate(states, actions)\n",
        "            state_values = torch.squeeze(state_values)\n",
        "\n",
        "            ratios = torch.exp(log_probs - old_log_probs_mb.detach())\n",
        "            surrogate1 = ratios * advantages_mb\n",
        "            surrogate2 = torch.clamp(ratios, 1 - self.eps_clip, 1 + self.eps_clip) * advantages_mb\n",
        "\n",
        "            actor_loss = -torch.min(surrogate1, surrogate2)\n",
        "            critic_loss = self.MseLoss(state_values, rewards_mb)\n",
        "\n",
        "            current_entropy_coef = self.entropy_coef_start - (self.entropy_coef_start - self.entropy_coef_end) * min(time_step / self.entropy_decay_steps, 1.0)\n",
        "            loss = actor_loss + 0.5 * critic_loss - current_entropy_coef * dist_entropy\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.policy.parameters(), max_norm=0.5)\n",
        "            self.optimizer.step()\n",
        "\n",
        "    self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "    self.buffer.clear()\n",
        "\n",
        "    return actor_loss.mean().item(), critic_loss.mean().item(), dist_entropy.mean().item()\n",
        "\n",
        "  def save(self, checkpoint_path):\n",
        "    torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "\n",
        "  def laod(self, checkpoint_path):\n",
        "    self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "    self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0rlXEIa4x25N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nKBgnJX5x2y0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "env_name = \"BipedalWalker-v3\"\n",
        "directory = directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}.pth\".format(env_name, 42)\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn9HWFIUV7Hv",
        "outputId": "5dba5182-de8e-49c0-94c8-4578c4019f9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "episode : 6, timestep : 890400, average reward : -69.02999877929688\n",
            "episode : 4, timestep : 892800, average reward : -73.52999877929688\n",
            "[892928] Avg reward (last 50 episodes): -0.07683190703392029\n",
            "episode : 6, timestep : 895200, average reward : -68.8499984741211\n",
            "episode : 5, timestep : 897600, average reward : -67.12999725341797\n",
            "episode : 6, timestep : 900000, average reward : -63.439998626708984\n",
            "setting action_std to  0.5985\n",
            "[901120] Avg reward (last 50 episodes): -0.08855648338794708\n",
            "episode : 4, timestep : 902400, average reward : -66.44999694824219\n",
            "episode : 4, timestep : 904800, average reward : -40.36000061035156\n",
            "episode : 4, timestep : 907200, average reward : -40.79999923706055\n",
            "[909312] Avg reward (last 50 episodes): -0.03156334534287453\n",
            "episode : 4, timestep : 909600, average reward : -38.849998474121094\n",
            "episode : 4, timestep : 912000, average reward : -43.54999923706055\n",
            "episode : 5, timestep : 914400, average reward : -57.58000183105469\n",
            "episode : 6, timestep : 916800, average reward : -65.91000366210938\n",
            "[917504] Avg reward (last 50 episodes): -0.049786243587732315\n",
            "episode : 6, timestep : 919200, average reward : -66.68000030517578\n",
            "episode : 4, timestep : 921600, average reward : -64.80999755859375\n",
            "episode : 8, timestep : 924000, average reward : -92.55000305175781\n",
            "[925696] Avg reward (last 50 episodes): -0.06460848450660706\n",
            "episode : 8, timestep : 926400, average reward : -88.08999633789062\n",
            "episode : 8, timestep : 928800, average reward : -77.80000305175781\n",
            "episode : 9, timestep : 931200, average reward : -86.83999633789062\n",
            "episode : 5, timestep : 933600, average reward : -54.4900016784668\n",
            "[933888] Avg reward (last 50 episodes): -0.09329798817634583\n",
            "episode : 5, timestep : 936000, average reward : -53.380001068115234\n",
            "episode : 7, timestep : 938400, average reward : -69.29000091552734\n",
            "episode : 7, timestep : 940800, average reward : -79.45999908447266\n",
            "[942080] Avg reward (last 50 episodes): -0.06744830310344696\n",
            "episode : 4, timestep : 943200, average reward : -42.56999969482422\n",
            "episode : 6, timestep : 945600, average reward : -63.18000030517578\n",
            "episode : 6, timestep : 948000, average reward : -62.93000030517578\n",
            "[950272] Avg reward (last 50 episodes): -0.24044357240200043\n",
            "episode : 4, timestep : 950400, average reward : -58.369998931884766\n",
            "episode : 7, timestep : 952800, average reward : -73.91999816894531\n",
            "episode : 4, timestep : 955200, average reward : -46.619998931884766\n",
            "episode : 4, timestep : 957600, average reward : -47.70000076293945\n",
            "[958464] Avg reward (last 50 episodes): -0.0978756844997406\n",
            "episode : 4, timestep : 960000, average reward : -76.01000213623047\n",
            "episode : 5, timestep : 962400, average reward : -62.36000061035156\n",
            "episode : 4, timestep : 964800, average reward : -51.56999969482422\n",
            "[966656] Avg reward (last 50 episodes): -0.08697724342346191\n",
            "episode : 4, timestep : 967200, average reward : -44.130001068115234\n",
            "episode : 5, timestep : 969600, average reward : -58.029998779296875\n",
            "episode : 4, timestep : 972000, average reward : -46.86000061035156\n",
            "episode : 4, timestep : 974400, average reward : -45.380001068115234\n",
            "[974848] Avg reward (last 50 episodes): -0.03905186429619789\n",
            "episode : 5, timestep : 976800, average reward : -58.54999923706055\n",
            "episode : 5, timestep : 979200, average reward : -72.0199966430664\n",
            "episode : 4, timestep : 981600, average reward : -50.18000030517578\n",
            "[983040] Avg reward (last 50 episodes): -0.1620834767818451\n",
            "episode : 4, timestep : 984000, average reward : -49.939998626708984\n",
            "episode : 5, timestep : 986400, average reward : -57.849998474121094\n",
            "episode : 4, timestep : 988800, average reward : -48.470001220703125\n",
            "episode : 8, timestep : 991200, average reward : -84.43000030517578\n",
            "[991232] Avg reward (last 50 episodes): -0.15294741094112396\n",
            "episode : 4, timestep : 993600, average reward : -45.06999969482422\n",
            "episode : 5, timestep : 996000, average reward : -64.01000213623047\n",
            "episode : 4, timestep : 998400, average reward : -62.9900016784668\n",
            "[999424] Avg reward (last 50 episodes): -0.08775579184293747\n",
            "episode : 4, timestep : 1000800, average reward : -45.779998779296875\n",
            "setting action_std to  0.5982\n",
            "episode : 5, timestep : 1003200, average reward : -56.93000030517578\n",
            "episode : 5, timestep : 1005600, average reward : -59.31999969482422\n",
            "[1007616] Avg reward (last 50 episodes): -0.1782587766647339\n",
            "episode : 6, timestep : 1008000, average reward : -77.94000244140625\n",
            "episode : 6, timestep : 1010400, average reward : -62.61000061035156\n",
            "episode : 5, timestep : 1012800, average reward : -56.83000183105469\n",
            "episode : 5, timestep : 1015200, average reward : -67.56999969482422\n",
            "[1015808] Avg reward (last 50 episodes): -0.057600606232881546\n",
            "episode : 4, timestep : 1017600, average reward : -50.13999938964844\n",
            "episode : 6, timestep : 1020000, average reward : -63.790000915527344\n",
            "episode : 5, timestep : 1022400, average reward : -57.209999084472656\n",
            "[1024000] Avg reward (last 50 episodes): -0.12533336877822876\n",
            "episode : 4, timestep : 1024800, average reward : -44.33000183105469\n",
            "episode : 4, timestep : 1027200, average reward : -60.06999969482422\n",
            "episode : 4, timestep : 1029600, average reward : -64.48999786376953\n",
            "episode : 4, timestep : 1032000, average reward : -46.970001220703125\n",
            "[1032192] Avg reward (last 50 episodes): -2.2959836316108704\n",
            "episode : 5, timestep : 1034400, average reward : -64.18000030517578\n",
            "episode : 4, timestep : 1036800, average reward : -52.650001525878906\n",
            "episode : 4, timestep : 1039200, average reward : -53.439998626708984\n",
            "[1040384] Avg reward (last 50 episodes): 0.013920295983552933\n",
            "episode : 4, timestep : 1041600, average reward : -50.70000076293945\n",
            "episode : 4, timestep : 1044000, average reward : -48.790000915527344\n",
            "episode : 4, timestep : 1046400, average reward : -50.310001373291016\n",
            "[1048576] Avg reward (last 50 episodes): -0.07107732445001602\n",
            "episode : 4, timestep : 1048800, average reward : -50.0\n",
            "episode : 4, timestep : 1051200, average reward : -44.029998779296875\n",
            "episode : 4, timestep : 1053600, average reward : -39.81999969482422\n",
            "episode : 4, timestep : 1056000, average reward : -99.45999908447266\n",
            "[1056768] Avg reward (last 50 episodes): -0.05662111937999725\n",
            "episode : 4, timestep : 1058400, average reward : -38.220001220703125\n",
            "episode : 4, timestep : 1060800, average reward : -38.459999084472656\n",
            "episode : 5, timestep : 1063200, average reward : -50.02000045776367\n",
            "[1064960] Avg reward (last 50 episodes): 0.0002571360091678798\n",
            "episode : 5, timestep : 1065600, average reward : -54.029998779296875\n",
            "episode : 4, timestep : 1068000, average reward : -47.08000183105469\n",
            "episode : 5, timestep : 1070400, average reward : -55.970001220703125\n",
            "episode : 4, timestep : 1072800, average reward : -42.97999954223633\n",
            "[1073152] Avg reward (last 50 episodes): -0.0928983986377716\n",
            "episode : 6, timestep : 1075200, average reward : -64.72000122070312\n",
            "episode : 4, timestep : 1077600, average reward : -40.15999984741211\n",
            "episode : 6, timestep : 1080000, average reward : -63.16999816894531\n",
            "[1081344] Avg reward (last 50 episodes): -0.05261785164475441\n",
            "episode : 4, timestep : 1082400, average reward : -61.779998779296875\n",
            "episode : 4, timestep : 1084800, average reward : -46.560001373291016\n",
            "episode : 4, timestep : 1087200, average reward : -49.34000015258789\n",
            "[1089536] Avg reward (last 50 episodes): -0.05169018357992172\n",
            "episode : 4, timestep : 1089600, average reward : -46.130001068115234\n",
            "episode : 4, timestep : 1092000, average reward : -46.65999984741211\n",
            "episode : 5, timestep : 1094400, average reward : -59.84000015258789\n",
            "episode : 4, timestep : 1096800, average reward : -45.220001220703125\n",
            "[1097728] Avg reward (last 50 episodes): -0.1187329888343811\n",
            "episode : 5, timestep : 1099200, average reward : -58.22999954223633\n",
            "setting action_std to  0.5979\n",
            "episode : 4, timestep : 1101600, average reward : -52.279998779296875\n",
            "episode : 4, timestep : 1104000, average reward : -52.099998474121094\n",
            "[1105920] Avg reward (last 50 episodes): -0.06558994948863983\n",
            "episode : 4, timestep : 1106400, average reward : -49.09000015258789\n",
            "episode : 4, timestep : 1108800, average reward : -47.18000030517578\n",
            "episode : 4, timestep : 1111200, average reward : -48.72999954223633\n",
            "episode : 5, timestep : 1113600, average reward : -70.25\n",
            "[1114112] Avg reward (last 50 episodes): -0.17435434460639954\n",
            "episode : 5, timestep : 1116000, average reward : -83.1500015258789\n",
            "episode : 5, timestep : 1118400, average reward : -60.02000045776367\n",
            "episode : 4, timestep : 1120800, average reward : -47.97999954223633\n",
            "[1122304] Avg reward (last 50 episodes): -0.03274369239807129\n",
            "episode : 5, timestep : 1123200, average reward : -63.66999816894531\n",
            "episode : 6, timestep : 1125600, average reward : -72.79000091552734\n",
            "episode : 6, timestep : 1128000, average reward : -77.12999725341797\n",
            "episode : 4, timestep : 1130400, average reward : -48.040000915527344\n",
            "[1130496] Avg reward (last 50 episodes): -0.21341438591480255\n",
            "episode : 4, timestep : 1132800, average reward : -73.51000213623047\n",
            "episode : 4, timestep : 1135200, average reward : -45.060001373291016\n",
            "episode : 4, timestep : 1137600, average reward : -49.9900016784668\n",
            "[1138688] Avg reward (last 50 episodes): -0.1299648880958557\n",
            "episode : 4, timestep : 1140000, average reward : -45.150001525878906\n",
            "episode : 5, timestep : 1142400, average reward : -60.33000183105469\n",
            "episode : 4, timestep : 1144800, average reward : -49.11000061035156\n",
            "[1146880] Avg reward (last 50 episodes): -0.06947126239538193\n",
            "episode : 5, timestep : 1147200, average reward : -59.45000076293945\n",
            "episode : 4, timestep : 1149600, average reward : -43.369998931884766\n",
            "episode : 4, timestep : 1152000, average reward : -44.93000030517578\n",
            "episode : 4, timestep : 1154400, average reward : -47.47999954223633\n",
            "[1155072] Avg reward (last 50 episodes): -0.0181881170719862\n",
            "episode : 5, timestep : 1156800, average reward : -58.900001525878906\n",
            "episode : 4, timestep : 1159200, average reward : -67.51000213623047\n",
            "episode : 4, timestep : 1161600, average reward : -42.2599983215332\n",
            "[1163264] Avg reward (last 50 episodes): -0.08580823242664337\n",
            "episode : 5, timestep : 1164000, average reward : -58.290000915527344\n",
            "episode : 6, timestep : 1166400, average reward : -79.05999755859375\n",
            "episode : 4, timestep : 1168800, average reward : -43.099998474121094\n",
            "episode : 6, timestep : 1171200, average reward : -63.81999969482422\n",
            "[1171456] Avg reward (last 50 episodes): 0.03081769496202469\n",
            "episode : 4, timestep : 1173600, average reward : -38.959999084472656\n",
            "episode : 4, timestep : 1176000, average reward : -55.29999923706055\n",
            "episode : 6, timestep : 1178400, average reward : -62.29999923706055\n",
            "[1179648] Avg reward (last 50 episodes): -0.06653150916099548\n",
            "episode : 4, timestep : 1180800, average reward : -39.130001068115234\n",
            "episode : 6, timestep : 1183200, average reward : -64.45999908447266\n",
            "episode : 4, timestep : 1185600, average reward : -35.0099983215332\n",
            "[1187840] Avg reward (last 50 episodes): -0.16870489716529846\n",
            "episode : 4, timestep : 1188000, average reward : -43.400001525878906\n",
            "episode : 4, timestep : 1190400, average reward : -43.91999816894531\n",
            "episode : 4, timestep : 1192800, average reward : -47.84000015258789\n",
            "episode : 4, timestep : 1195200, average reward : -44.79999923706055\n",
            "[1196032] Avg reward (last 50 episodes): -0.09463585913181305\n",
            "episode : 4, timestep : 1197600, average reward : -42.77000045776367\n",
            "episode : 5, timestep : 1200000, average reward : -70.87000274658203\n",
            "setting action_std to  0.5976\n",
            "episode : 4, timestep : 1202400, average reward : -42.90999984741211\n",
            "[1204224] Avg reward (last 50 episodes): -0.05209013447165489\n",
            "episode : 5, timestep : 1204800, average reward : -54.59000015258789\n",
            "episode : 4, timestep : 1207200, average reward : -80.76000213623047\n",
            "episode : 4, timestep : 1209600, average reward : -35.86000061035156\n",
            "episode : 4, timestep : 1212000, average reward : -38.88999938964844\n",
            "[1212416] Avg reward (last 50 episodes): -0.06598669290542603\n",
            "episode : 4, timestep : 1214400, average reward : -40.75\n",
            "episode : 4, timestep : 1216800, average reward : -41.52000045776367\n",
            "episode : 6, timestep : 1219200, average reward : -71.02999877929688\n",
            "[1220608] Avg reward (last 50 episodes): -0.069371297955513\n",
            "episode : 4, timestep : 1221600, average reward : -42.41999816894531\n",
            "episode : 4, timestep : 1224000, average reward : -39.11000061035156\n",
            "episode : 4, timestep : 1226400, average reward : -61.029998779296875\n",
            "[1228800] Avg reward (last 50 episodes): -0.11383867263793945\n",
            "episode : 4, timestep : 1228800, average reward : -45.5099983215332\n",
            "episode : 6, timestep : 1231200, average reward : -63.16999816894531\n",
            "episode : 4, timestep : 1233600, average reward : -37.5\n",
            "episode : 5, timestep : 1236000, average reward : -52.86000061035156\n",
            "[1236992] Avg reward (last 50 episodes): -0.0701473131775856\n",
            "episode : 5, timestep : 1238400, average reward : -52.630001068115234\n",
            "episode : 4, timestep : 1240800, average reward : -55.43000030517578\n",
            "episode : 4, timestep : 1243200, average reward : -56.209999084472656\n",
            "[1245184] Avg reward (last 50 episodes): -0.009375208988785744\n",
            "episode : 8, timestep : 1245600, average reward : -74.02999877929688\n",
            "episode : 4, timestep : 1248000, average reward : -34.25\n",
            "episode : 4, timestep : 1250400, average reward : -53.380001068115234\n",
            "episode : 4, timestep : 1252800, average reward : -30.030000686645508\n",
            "[1253376] Avg reward (last 50 episodes): -0.09797980636358261\n",
            "episode : 6, timestep : 1255200, average reward : -72.2699966430664\n",
            "episode : 4, timestep : 1257600, average reward : -53.599998474121094\n",
            "episode : 4, timestep : 1260000, average reward : -33.099998474121094\n",
            "[1261568] Avg reward (last 50 episodes): -0.0020975733641535044\n",
            "episode : 5, timestep : 1262400, average reward : -60.36000061035156\n",
            "episode : 5, timestep : 1264800, average reward : -44.7400016784668\n",
            "episode : 4, timestep : 1267200, average reward : -34.22999954223633\n",
            "episode : 4, timestep : 1269600, average reward : -30.219999313354492\n",
            "[1269760] Avg reward (last 50 episodes): -0.06774791330099106\n",
            "episode : 7, timestep : 1272000, average reward : -66.37999725341797\n",
            "episode : 4, timestep : 1274400, average reward : -56.45000076293945\n",
            "episode : 4, timestep : 1276800, average reward : -36.40999984741211\n",
            "[1277952] Avg reward (last 50 episodes): 0.014650963246822357\n",
            "episode : 4, timestep : 1279200, average reward : -60.38999938964844\n",
            "episode : 4, timestep : 1281600, average reward : -55.630001068115234\n",
            "episode : 4, timestep : 1284000, average reward : -34.66999816894531\n",
            "[1286144] Avg reward (last 50 episodes): -0.00318808201700449\n",
            "episode : 4, timestep : 1286400, average reward : -34.720001220703125\n",
            "episode : 4, timestep : 1288800, average reward : -34.65999984741211\n",
            "episode : 5, timestep : 1291200, average reward : -56.400001525878906\n",
            "episode : 5, timestep : 1293600, average reward : -51.65999984741211\n",
            "[1294336] Avg reward (last 50 episodes): -0.037932462990283966\n",
            "episode : 5, timestep : 1296000, average reward : -50.33000183105469\n",
            "episode : 4, timestep : 1298400, average reward : -60.75\n",
            "episode : 4, timestep : 1300800, average reward : -38.90999984741211\n",
            "setting action_std to  0.5973\n",
            "[1302528] Avg reward (last 50 episodes): -0.009642159566283226\n",
            "episode : 4, timestep : 1303200, average reward : -37.400001525878906\n",
            "episode : 5, timestep : 1305600, average reward : -49.86000061035156\n",
            "episode : 5, timestep : 1308000, average reward : -48.459999084472656\n",
            "episode : 4, timestep : 1310400, average reward : -57.91999816894531\n",
            "[1310720] Avg reward (last 50 episodes): -0.06714730709791183\n",
            "episode : 5, timestep : 1312800, average reward : -48.619998931884766\n",
            "episode : 4, timestep : 1315200, average reward : -59.560001373291016\n",
            "episode : 4, timestep : 1317600, average reward : -33.189998626708984\n",
            "[1318912] Avg reward (last 50 episodes): -0.07226163148880005\n",
            "episode : 4, timestep : 1320000, average reward : -55.66999816894531\n",
            "episode : 4, timestep : 1322400, average reward : -39.040000915527344\n",
            "episode : 4, timestep : 1324800, average reward : -36.56999969482422\n",
            "[1327104] Avg reward (last 50 episodes): -0.05457945168018341\n",
            "episode : 4, timestep : 1327200, average reward : -35.959999084472656\n",
            "episode : 5, timestep : 1329600, average reward : -50.439998626708984\n",
            "episode : 4, timestep : 1332000, average reward : -34.599998474121094\n",
            "episode : 4, timestep : 1334400, average reward : -32.41999816894531\n",
            "[1335296] Avg reward (last 50 episodes): -0.061137448996305466\n",
            "episode : 4, timestep : 1336800, average reward : -37.209999084472656\n",
            "episode : 4, timestep : 1339200, average reward : -38.290000915527344\n",
            "episode : 4, timestep : 1341600, average reward : -38.40999984741211\n",
            "[1343488] Avg reward (last 50 episodes): -0.07295038551092148\n",
            "episode : 4, timestep : 1344000, average reward : -38.41999816894531\n",
            "episode : 5, timestep : 1346400, average reward : -50.689998626708984\n",
            "episode : 4, timestep : 1348800, average reward : -34.58000183105469\n",
            "episode : 6, timestep : 1351200, average reward : -58.79999923706055\n",
            "[1351680] Avg reward (last 50 episodes): -0.031065350398421288\n",
            "episode : 4, timestep : 1353600, average reward : -38.209999084472656\n",
            "episode : 5, timestep : 1356000, average reward : -48.09000015258789\n",
            "episode : 5, timestep : 1358400, average reward : -49.91999816894531\n",
            "[1359872] Avg reward (last 50 episodes): -0.05334729328751564\n",
            "episode : 6, timestep : 1360800, average reward : -85.22000122070312\n",
            "episode : 5, timestep : 1363200, average reward : -58.369998931884766\n",
            "episode : 5, timestep : 1365600, average reward : -57.36000061035156\n",
            "episode : 5, timestep : 1368000, average reward : -55.150001525878906\n",
            "[1368064] Avg reward (last 50 episodes): -0.13294650614261627\n",
            "episode : 4, timestep : 1370400, average reward : -53.16999816894531\n",
            "episode : 4, timestep : 1372800, average reward : -38.959999084472656\n",
            "episode : 4, timestep : 1375200, average reward : -44.36000061035156\n",
            "[1376256] Avg reward (last 50 episodes): -0.07214038074016571\n",
            "episode : 4, timestep : 1377600, average reward : -37.93000030517578\n",
            "episode : 4, timestep : 1380000, average reward : -40.4900016784668\n",
            "episode : 4, timestep : 1382400, average reward : -37.18000030517578\n",
            "[1384448] Avg reward (last 50 episodes): -0.026806816458702087\n",
            "episode : 5, timestep : 1384800, average reward : -51.099998474121094\n",
            "episode : 4, timestep : 1387200, average reward : -38.619998931884766\n",
            "episode : 5, timestep : 1389600, average reward : -54.209999084472656\n",
            "episode : 4, timestep : 1392000, average reward : -42.22999954223633\n",
            "[1392640] Avg reward (last 50 episodes): -0.052622076123952866\n",
            "episode : 7, timestep : 1394400, average reward : -71.7699966430664\n",
            "episode : 4, timestep : 1396800, average reward : -58.529998779296875\n",
            "episode : 5, timestep : 1399200, average reward : -54.279998779296875\n",
            "[1400832] Avg reward (last 50 episodes): -0.053257785737514496\n",
            "episode : 5, timestep : 1401600, average reward : -55.0099983215332\n",
            "setting action_std to  0.597\n",
            "episode : 4, timestep : 1404000, average reward : -44.4900016784668\n",
            "episode : 6, timestep : 1406400, average reward : -63.88999938964844\n",
            "episode : 4, timestep : 1408800, average reward : -45.20000076293945\n",
            "[1409024] Avg reward (last 50 episodes): -0.06874417513608932\n",
            "episode : 4, timestep : 1411200, average reward : -45.93000030517578\n",
            "episode : 4, timestep : 1413600, average reward : -43.900001525878906\n",
            "episode : 4, timestep : 1416000, average reward : -42.41999816894531\n",
            "[1417216] Avg reward (last 50 episodes): -0.06601741909980774\n",
            "episode : 4, timestep : 1418400, average reward : -44.849998474121094\n",
            "episode : 4, timestep : 1420800, average reward : -47.220001220703125\n",
            "episode : 4, timestep : 1423200, average reward : -42.77000045776367\n",
            "[1425408] Avg reward (last 50 episodes): -0.06403408199548721\n",
            "episode : 5, timestep : 1425600, average reward : -58.97999954223633\n",
            "episode : 4, timestep : 1428000, average reward : -44.04999923706055\n",
            "episode : 5, timestep : 1430400, average reward : -56.09000015258789\n",
            "episode : 4, timestep : 1432800, average reward : -62.310001373291016\n",
            "[1433600] Avg reward (last 50 episodes): -0.05977635830640793\n",
            "episode : 4, timestep : 1435200, average reward : -47.220001220703125\n",
            "episode : 4, timestep : 1437600, average reward : -44.0099983215332\n",
            "episode : 4, timestep : 1440000, average reward : -42.619998931884766\n",
            "[1441792] Avg reward (last 50 episodes): -0.08579246699810028\n",
            "episode : 4, timestep : 1442400, average reward : -45.54999923706055\n",
            "episode : 6, timestep : 1444800, average reward : -65.45999908447266\n",
            "episode : 4, timestep : 1447200, average reward : -40.130001068115234\n",
            "episode : 4, timestep : 1449600, average reward : -37.060001373291016\n",
            "[1449984] Avg reward (last 50 episodes): 0.004589248448610306\n",
            "episode : 7, timestep : 1452000, average reward : -84.04000091552734\n",
            "episode : 6, timestep : 1454400, average reward : -59.66999816894531\n",
            "episode : 7, timestep : 1456800, average reward : -78.47000122070312\n",
            "[1458176] Avg reward (last 50 episodes): -0.10529827326536179\n",
            "episode : 4, timestep : 1459200, average reward : -38.959999084472656\n",
            "episode : 7, timestep : 1461600, average reward : -70.33000183105469\n",
            "episode : 7, timestep : 1464000, average reward : -78.19000244140625\n",
            "[1466368] Avg reward (last 50 episodes): -0.005809845868498087\n",
            "episode : 7, timestep : 1466400, average reward : -71.97000122070312\n",
            "episode : 4, timestep : 1468800, average reward : -39.220001220703125\n",
            "episode : 5, timestep : 1471200, average reward : -52.939998626708984\n",
            "episode : 4, timestep : 1473600, average reward : -38.88999938964844\n",
            "[1474560] Avg reward (last 50 episodes): -0.08247347921133041\n",
            "episode : 4, timestep : 1476000, average reward : -40.029998779296875\n",
            "episode : 6, timestep : 1478400, average reward : -66.23999786376953\n",
            "episode : 4, timestep : 1480800, average reward : -44.959999084472656\n",
            "[1482752] Avg reward (last 50 episodes): -2.0668545406870544\n",
            "episode : 5, timestep : 1483200, average reward : -65.05999755859375\n",
            "episode : 4, timestep : 1485600, average reward : -40.189998626708984\n",
            "episode : 5, timestep : 1488000, average reward : -50.7400016784668\n",
            "episode : 9, timestep : 1490400, average reward : -79.08000183105469\n",
            "[1490944] Avg reward (last 50 episodes): -0.08045263588428497\n",
            "episode : 4, timestep : 1492800, average reward : -42.27000045776367\n",
            "episode : 5, timestep : 1495200, average reward : -50.7400016784668\n",
            "episode : 5, timestep : 1497600, average reward : -67.01000213623047\n",
            "[1499136] Avg reward (last 50 episodes): -0.08014681935310364\n",
            "episode : 5, timestep : 1500000, average reward : -54.40999984741211\n",
            "setting action_std to  0.5967\n",
            "episode : 6, timestep : 1502400, average reward : -65.68000030517578\n",
            "episode : 6, timestep : 1504800, average reward : -64.43000030517578\n",
            "episode : 4, timestep : 1507200, average reward : -40.20000076293945\n",
            "[1507328] Avg reward (last 50 episodes): -0.04374539479613304\n",
            "episode : 5, timestep : 1509600, average reward : -55.81999969482422\n",
            "episode : 4, timestep : 1512000, average reward : -41.33000183105469\n",
            "episode : 4, timestep : 1514400, average reward : -40.779998779296875\n",
            "[1515520] Avg reward (last 50 episodes): -0.07666224986314774\n",
            "episode : 4, timestep : 1516800, average reward : -59.380001068115234\n",
            "episode : 4, timestep : 1519200, average reward : -45.56999969482422\n",
            "episode : 5, timestep : 1521600, average reward : -57.150001525878906\n",
            "[1523712] Avg reward (last 50 episodes): -0.013255126774311066\n",
            "episode : 6, timestep : 1524000, average reward : -61.13999938964844\n",
            "episode : 4, timestep : 1526400, average reward : -42.83000183105469\n",
            "episode : 4, timestep : 1528800, average reward : -38.470001220703125\n",
            "episode : 5, timestep : 1531200, average reward : -54.900001525878906\n",
            "[1531904] Avg reward (last 50 episodes): -0.07783514261245728\n",
            "episode : 4, timestep : 1533600, average reward : -44.70000076293945\n",
            "episode : 4, timestep : 1536000, average reward : -45.40999984741211\n",
            "episode : 4, timestep : 1538400, average reward : -45.779998779296875\n",
            "[1540096] Avg reward (last 50 episodes): -0.08024232089519501\n",
            "episode : 4, timestep : 1540800, average reward : -41.779998779296875\n",
            "episode : 4, timestep : 1543200, average reward : -42.41999816894531\n",
            "episode : 4, timestep : 1545600, average reward : -43.529998779296875\n",
            "episode : 4, timestep : 1548000, average reward : -41.4900016784668\n",
            "[1548288] Avg reward (last 50 episodes): -0.09817048907279968\n",
            "episode : 4, timestep : 1550400, average reward : -36.54999923706055\n",
            "episode : 4, timestep : 1552800, average reward : -32.68000030517578\n",
            "episode : 4, timestep : 1555200, average reward : -58.70000076293945\n",
            "[1556480] Avg reward (last 50 episodes): -0.11029339581727982\n",
            "episode : 4, timestep : 1557600, average reward : -41.31999969482422\n",
            "episode : 5, timestep : 1560000, average reward : -58.56999969482422\n",
            "episode : 4, timestep : 1562400, average reward : -43.31999969482422\n",
            "[1564672] Avg reward (last 50 episodes): -0.06030217185616493\n",
            "episode : 4, timestep : 1564800, average reward : -42.310001373291016\n",
            "episode : 4, timestep : 1567200, average reward : -65.94000244140625\n",
            "episode : 5, timestep : 1569600, average reward : -55.4900016784668\n",
            "episode : 5, timestep : 1572000, average reward : -56.75\n",
            "[1572864] Avg reward (last 50 episodes): -0.1262311339378357\n",
            "episode : 4, timestep : 1574400, average reward : -39.790000915527344\n",
            "episode : 5, timestep : 1576800, average reward : -55.7599983215332\n",
            "episode : 5, timestep : 1579200, average reward : -50.09000015258789\n",
            "[1581056] Avg reward (last 50 episodes): -0.07950732111930847\n",
            "episode : 4, timestep : 1581600, average reward : -39.209999084472656\n",
            "episode : 4, timestep : 1584000, average reward : -36.13999938964844\n",
            "episode : 4, timestep : 1586400, average reward : -38.52000045776367\n",
            "episode : 5, timestep : 1588800, average reward : -54.38999938964844\n",
            "[1589248] Avg reward (last 50 episodes): -0.057616543024778366\n",
            "episode : 4, timestep : 1591200, average reward : -35.33000183105469\n",
            "episode : 4, timestep : 1593600, average reward : -36.13999938964844\n",
            "episode : 4, timestep : 1596000, average reward : -38.560001373291016\n",
            "[1597440] Avg reward (last 50 episodes): -0.05292360484600067\n",
            "episode : 4, timestep : 1598400, average reward : -54.86000061035156\n",
            "episode : 6, timestep : 1600800, average reward : -59.959999084472656\n",
            "setting action_std to  0.5964\n",
            "episode : 4, timestep : 1603200, average reward : -51.630001068115234\n",
            "episode : 4, timestep : 1605600, average reward : -34.459999084472656\n",
            "[1605632] Avg reward (last 50 episodes): -0.054223738610744476\n",
            "episode : 5, timestep : 1608000, average reward : -50.91999816894531\n",
            "episode : 5, timestep : 1610400, average reward : -50.849998474121094\n",
            "episode : 6, timestep : 1612800, average reward : -62.33000183105469\n",
            "[1613824] Avg reward (last 50 episodes): -0.04624486342072487\n",
            "episode : 4, timestep : 1615200, average reward : -37.95000076293945\n",
            "episode : 5, timestep : 1617600, average reward : -51.0099983215332\n",
            "episode : 4, timestep : 1620000, average reward : -38.22999954223633\n",
            "[1622016] Avg reward (last 50 episodes): -0.0677681565284729\n",
            "episode : 4, timestep : 1622400, average reward : -35.95000076293945\n",
            "episode : 4, timestep : 1624800, average reward : -35.13999938964844\n",
            "episode : 6, timestep : 1627200, average reward : -64.30999755859375\n",
            "episode : 5, timestep : 1629600, average reward : -52.939998626708984\n",
            "[1630208] Avg reward (last 50 episodes): -0.1141001284122467\n",
            "episode : 4, timestep : 1632000, average reward : -38.72999954223633\n",
            "episode : 4, timestep : 1634400, average reward : -34.20000076293945\n",
            "episode : 5, timestep : 1636800, average reward : -65.87999725341797\n",
            "[1638400] Avg reward (last 50 episodes): -0.03875918313860893\n",
            "episode : 6, timestep : 1639200, average reward : -60.209999084472656\n",
            "episode : 6, timestep : 1641600, average reward : -62.40999984741211\n",
            "episode : 6, timestep : 1644000, average reward : -71.87000274658203\n",
            "episode : 6, timestep : 1646400, average reward : -74.05000305175781\n",
            "[1646592] Avg reward (last 50 episodes): -0.08342498540878296\n",
            "episode : 4, timestep : 1648800, average reward : -36.7599983215332\n",
            "episode : 4, timestep : 1651200, average reward : -54.099998474121094\n",
            "episode : 5, timestep : 1653600, average reward : -52.88999938964844\n",
            "[1654784] Avg reward (last 50 episodes): -0.08531096577644348\n",
            "episode : 4, timestep : 1656000, average reward : -32.470001220703125\n",
            "episode : 4, timestep : 1658400, average reward : -41.47999954223633\n",
            "episode : 4, timestep : 1660800, average reward : -57.150001525878906\n",
            "[1662976] Avg reward (last 50 episodes): -0.03565002977848053\n",
            "episode : 4, timestep : 1663200, average reward : -41.150001525878906\n",
            "episode : 5, timestep : 1665600, average reward : -56.08000183105469\n",
            "episode : 4, timestep : 1668000, average reward : -41.599998474121094\n",
            "episode : 4, timestep : 1670400, average reward : -41.130001068115234\n",
            "[1671168] Avg reward (last 50 episodes): -0.1733839213848114\n",
            "episode : 4, timestep : 1672800, average reward : -44.97999954223633\n",
            "episode : 5, timestep : 1675200, average reward : -58.11000061035156\n",
            "episode : 5, timestep : 1677600, average reward : -61.65999984741211\n",
            "[1679360] Avg reward (last 50 episodes): -0.0791582465171814\n",
            "episode : 5, timestep : 1680000, average reward : -58.34000015258789\n",
            "episode : 5, timestep : 1682400, average reward : -57.470001220703125\n",
            "episode : 4, timestep : 1684800, average reward : -43.130001068115234\n",
            "episode : 4, timestep : 1687200, average reward : -47.689998626708984\n",
            "[1687552] Avg reward (last 50 episodes): -0.006788302678614855\n",
            "episode : 4, timestep : 1689600, average reward : -47.689998626708984\n",
            "episode : 5, timestep : 1692000, average reward : -57.52000045776367\n",
            "episode : 4, timestep : 1694400, average reward : -44.630001068115234\n",
            "[1695744] Avg reward (last 50 episodes): -0.05054115131497383\n",
            "episode : 4, timestep : 1696800, average reward : -46.959999084472656\n",
            "episode : 5, timestep : 1699200, average reward : -73.5199966430664\n",
            "episode : 4, timestep : 1701600, average reward : -47.849998474121094\n",
            "setting action_std to  0.5961\n",
            "[1703936] Avg reward (last 50 episodes): -0.1129675805568695\n",
            "episode : 4, timestep : 1704000, average reward : -49.040000915527344\n",
            "episode : 7, timestep : 1706400, average reward : -73.44000244140625\n",
            "episode : 4, timestep : 1708800, average reward : -50.810001373291016\n",
            "episode : 4, timestep : 1711200, average reward : -49.119998931884766\n",
            "[1712128] Avg reward (last 50 episodes): -0.12285402417182922\n",
            "episode : 5, timestep : 1713600, average reward : -60.45000076293945\n",
            "episode : 7, timestep : 1716000, average reward : -90.6500015258789\n",
            "episode : 4, timestep : 1718400, average reward : -65.2699966430664\n",
            "[1720320] Avg reward (last 50 episodes): -0.08725296705961227\n",
            "episode : 9, timestep : 1720800, average reward : -87.37000274658203\n",
            "episode : 4, timestep : 1723200, average reward : -65.5\n",
            "episode : 6, timestep : 1725600, average reward : -71.94000244140625\n",
            "episode : 5, timestep : 1728000, average reward : -59.22999954223633\n",
            "[1728512] Avg reward (last 50 episodes): -0.06022558733820915\n",
            "episode : 5, timestep : 1730400, average reward : -62.2599983215332\n",
            "episode : 4, timestep : 1732800, average reward : -69.0199966430664\n",
            "episode : 4, timestep : 1735200, average reward : -52.040000915527344\n",
            "[1736704] Avg reward (last 50 episodes): -0.02958635613322258\n",
            "episode : 5, timestep : 1737600, average reward : -63.52000045776367\n",
            "episode : 8, timestep : 1740000, average reward : -78.81999969482422\n",
            "episode : 4, timestep : 1742400, average reward : -43.13999938964844\n",
            "episode : 6, timestep : 1744800, average reward : -81.30999755859375\n",
            "[1744896] Avg reward (last 50 episodes): -0.05847814679145813\n",
            "episode : 4, timestep : 1747200, average reward : -41.220001220703125\n",
            "episode : 7, timestep : 1749600, average reward : -72.36000061035156\n",
            "episode : 8, timestep : 1752000, average reward : -87.30999755859375\n",
            "[1753088] Avg reward (last 50 episodes): -0.09350310266017914\n",
            "episode : 5, timestep : 1754400, average reward : -56.25\n",
            "episode : 4, timestep : 1756800, average reward : -40.880001068115234\n",
            "episode : 4, timestep : 1759200, average reward : -42.279998779296875\n",
            "[1761280] Avg reward (last 50 episodes): -0.033302415162324905\n",
            "episode : 6, timestep : 1761600, average reward : -67.62000274658203\n",
            "episode : 4, timestep : 1764000, average reward : -47.86000061035156\n",
            "episode : 4, timestep : 1766400, average reward : -43.349998474121094\n",
            "episode : 4, timestep : 1768800, average reward : -46.290000915527344\n",
            "[1769472] Avg reward (last 50 episodes): -0.05572795867919922\n",
            "episode : 4, timestep : 1771200, average reward : -40.619998931884766\n",
            "episode : 6, timestep : 1773600, average reward : -65.7699966430664\n",
            "episode : 4, timestep : 1776000, average reward : -59.45000076293945\n",
            "[1777664] Avg reward (last 50 episodes): -0.05908026173710823\n",
            "episode : 4, timestep : 1778400, average reward : -41.83000183105469\n",
            "episode : 4, timestep : 1780800, average reward : -44.619998931884766\n",
            "episode : 6, timestep : 1783200, average reward : -70.44999694824219\n",
            "episode : 4, timestep : 1785600, average reward : -45.709999084472656\n",
            "[1785856] Avg reward (last 50 episodes): -0.06719882786273956\n",
            "episode : 4, timestep : 1788000, average reward : -38.63999938964844\n",
            "episode : 4, timestep : 1790400, average reward : -39.36000061035156\n",
            "episode : 4, timestep : 1792800, average reward : -39.27000045776367\n",
            "[1794048] Avg reward (last 50 episodes): -0.034141961485147476\n",
            "episode : 4, timestep : 1795200, average reward : -39.099998474121094\n",
            "episode : 4, timestep : 1797600, average reward : -41.0\n",
            "episode : 4, timestep : 1800000, average reward : -38.709999084472656\n",
            "[1802240] Avg reward (last 50 episodes): -0.018605345860123634\n",
            "episode : 4, timestep : 1802400, average reward : -39.18000030517578\n",
            "setting action_std to  0.5958\n",
            "episode : 4, timestep : 1804800, average reward : -39.59000015258789\n",
            "episode : 4, timestep : 1807200, average reward : -44.470001220703125\n",
            "episode : 4, timestep : 1809600, average reward : -41.16999816894531\n",
            "[1810432] Avg reward (last 50 episodes): -0.1185331717133522\n",
            "episode : 4, timestep : 1812000, average reward : -42.04999923706055\n",
            "episode : 4, timestep : 1814400, average reward : -40.709999084472656\n",
            "episode : 4, timestep : 1816800, average reward : -43.720001220703125\n",
            "[1818624] Avg reward (last 50 episodes): -0.05382559821009636\n",
            "episode : 4, timestep : 1819200, average reward : -41.95000076293945\n",
            "episode : 4, timestep : 1821600, average reward : -36.119998931884766\n",
            "episode : 4, timestep : 1824000, average reward : -38.959999084472656\n",
            "episode : 4, timestep : 1826400, average reward : -39.11000061035156\n",
            "[1826816] Avg reward (last 50 episodes): -0.09106525778770447\n",
            "episode : 4, timestep : 1828800, average reward : -44.33000183105469\n",
            "episode : 4, timestep : 1831200, average reward : -44.83000183105469\n",
            "episode : 4, timestep : 1833600, average reward : -46.15999984741211\n",
            "[1835008] Avg reward (last 50 episodes): -0.08692537248134613\n",
            "episode : 4, timestep : 1836000, average reward : -44.66999816894531\n",
            "episode : 4, timestep : 1838400, average reward : -48.08000183105469\n",
            "episode : 4, timestep : 1840800, average reward : -41.20000076293945\n",
            "[1843200] Avg reward (last 50 episodes): -0.07171747088432312\n",
            "episode : 4, timestep : 1843200, average reward : -40.68000030517578\n",
            "episode : 4, timestep : 1845600, average reward : -46.83000183105469\n",
            "episode : 4, timestep : 1848000, average reward : -44.40999984741211\n",
            "episode : 4, timestep : 1850400, average reward : -41.560001373291016\n",
            "[1851392] Avg reward (last 50 episodes): -0.05430464446544647\n",
            "episode : 4, timestep : 1852800, average reward : -48.54999923706055\n",
            "episode : 4, timestep : 1855200, average reward : -44.7400016784668\n",
            "episode : 4, timestep : 1857600, average reward : -44.84000015258789\n",
            "[1859584] Avg reward (last 50 episodes): -0.09370296448469162\n",
            "episode : 4, timestep : 1860000, average reward : -47.40999984741211\n",
            "episode : 4, timestep : 1862400, average reward : -48.970001220703125\n",
            "episode : 5, timestep : 1864800, average reward : -60.709999084472656\n",
            "episode : 4, timestep : 1867200, average reward : -46.959999084472656\n",
            "[1867776] Avg reward (last 50 episodes): -0.06419487297534943\n",
            "episode : 5, timestep : 1869600, average reward : -59.310001373291016\n",
            "episode : 5, timestep : 1872000, average reward : -58.38999938964844\n",
            "episode : 4, timestep : 1874400, average reward : -46.119998931884766\n",
            "[1875968] Avg reward (last 50 episodes): -0.04124422371387482\n",
            "episode : 5, timestep : 1876800, average reward : -73.66999816894531\n",
            "episode : 5, timestep : 1879200, average reward : -64.04000091552734\n",
            "episode : 7, timestep : 1881600, average reward : -78.04000091552734\n",
            "episode : 4, timestep : 1884000, average reward : -47.779998779296875\n",
            "[1884160] Avg reward (last 50 episodes): -0.02181761898100376\n",
            "episode : 4, timestep : 1886400, average reward : -55.7599983215332\n",
            "episode : 4, timestep : 1888800, average reward : -65.68000030517578\n",
            "episode : 4, timestep : 1891200, average reward : -48.0\n",
            "[1892352] Avg reward (last 50 episodes): -0.08359424769878387\n",
            "episode : 5, timestep : 1893600, average reward : -76.27999877929688\n",
            "episode : 4, timestep : 1896000, average reward : -99.5\n",
            "episode : 5, timestep : 1898400, average reward : -113.22000122070312\n",
            "[1900544] Avg reward (last 50 episodes): -0.031307172030210495\n",
            "episode : 6, timestep : 1900800, average reward : -95.62000274658203\n",
            "episode : 8, timestep : 1903200, average reward : -86.58999633789062\n",
            "setting action_std to  0.5955\n",
            "episode : 7, timestep : 1905600, average reward : -105.47000122070312\n",
            "episode : 8, timestep : 1908000, average reward : -99.94000244140625\n",
            "[1908736] Avg reward (last 50 episodes): -0.061788223683834076\n",
            "episode : 6, timestep : 1910400, average reward : -96.02999877929688\n",
            "episode : 5, timestep : 1912800, average reward : -83.2300033569336\n",
            "episode : 4, timestep : 1915200, average reward : -52.439998626708984\n",
            "[1916928] Avg reward (last 50 episodes): -0.03791781887412071\n",
            "episode : 4, timestep : 1917600, average reward : -51.04999923706055\n",
            "episode : 4, timestep : 1920000, average reward : -48.58000183105469\n",
            "episode : 4, timestep : 1922400, average reward : -47.16999816894531\n",
            "episode : 4, timestep : 1924800, average reward : -47.13999938964844\n",
            "[1925120] Avg reward (last 50 episodes): -0.013935301452875137\n",
            "episode : 5, timestep : 1927200, average reward : -58.720001220703125\n",
            "episode : 6, timestep : 1929600, average reward : -78.70999908447266\n",
            "episode : 6, timestep : 1932000, average reward : -64.8499984741211\n",
            "[1933312] Avg reward (last 50 episodes): -0.21487250924110413\n",
            "episode : 6, timestep : 1934400, average reward : -74.05999755859375\n",
            "episode : 5, timestep : 1936800, average reward : -56.83000183105469\n",
            "episode : 4, timestep : 1939200, average reward : -36.93000030517578\n",
            "[1941504] Avg reward (last 50 episodes): -0.0677540972828865\n",
            "episode : 4, timestep : 1941600, average reward : -37.369998931884766\n",
            "episode : 10, timestep : 1944000, average reward : -101.43000030517578\n",
            "episode : 8, timestep : 1946400, average reward : -89.8499984741211\n",
            "episode : 7, timestep : 1948800, average reward : -100.98999786376953\n",
            "[1949696] Avg reward (last 50 episodes): -0.15529277920722961\n",
            "episode : 7, timestep : 1951200, average reward : -85.66000366210938\n",
            "episode : 9, timestep : 1953600, average reward : -90.05000305175781\n",
            "episode : 10, timestep : 1956000, average reward : -90.62999725341797\n",
            "[1957888] Avg reward (last 50 episodes): -0.05732009559869766\n",
            "episode : 4, timestep : 1958400, average reward : -43.93000030517578\n",
            "episode : 4, timestep : 1960800, average reward : -60.58000183105469\n",
            "episode : 4, timestep : 1963200, average reward : -38.09000015258789\n",
            "episode : 9, timestep : 1965600, average reward : -80.80000305175781\n",
            "[1966080] Avg reward (last 50 episodes): -0.06076987087726593\n",
            "episode : 5, timestep : 1968000, average reward : -74.62000274658203\n",
            "episode : 4, timestep : 1970400, average reward : -42.459999084472656\n",
            "episode : 4, timestep : 1972800, average reward : -42.349998474121094\n",
            "[1974272] Avg reward (last 50 episodes): -0.03291410580277443\n",
            "episode : 5, timestep : 1975200, average reward : -73.77999877929688\n",
            "episode : 4, timestep : 1977600, average reward : -65.18000030517578\n",
            "episode : 7, timestep : 1980000, average reward : -85.41000366210938\n",
            "episode : 5, timestep : 1982400, average reward : -50.959999084472656\n",
            "[1982464] Avg reward (last 50 episodes): -0.025197777897119522\n",
            "episode : 4, timestep : 1984800, average reward : -56.41999816894531\n",
            "episode : 6, timestep : 1987200, average reward : -64.55000305175781\n",
            "episode : 8, timestep : 1989600, average reward : -88.0\n",
            "[1990656] Avg reward (last 50 episodes): -0.05485849827528\n",
            "episode : 6, timestep : 1992000, average reward : -62.349998474121094\n",
            "episode : 4, timestep : 1994400, average reward : -62.099998474121094\n",
            "episode : 4, timestep : 1996800, average reward : -42.279998779296875\n",
            "[1998848] Avg reward (last 50 episodes): -0.019254732877016068\n",
            "episode : 4, timestep : 1999200, average reward : -37.349998474121094\n",
            "episode : 5, timestep : 2001600, average reward : -52.5099983215332\n",
            "setting action_std to  0.5952\n",
            "episode : 4, timestep : 2004000, average reward : -36.220001220703125\n",
            "episode : 5, timestep : 2006400, average reward : -68.69999694824219\n",
            "[2007040] Avg reward (last 50 episodes): -0.046175871044397354\n",
            "episode : 4, timestep : 2008800, average reward : -38.36000061035156\n",
            "episode : 4, timestep : 2011200, average reward : -39.18000030517578\n",
            "episode : 4, timestep : 2013600, average reward : -42.459999084472656\n",
            "[2015232] Avg reward (last 50 episodes): -0.13048186898231506\n",
            "episode : 4, timestep : 2016000, average reward : -43.529998779296875\n",
            "episode : 4, timestep : 2018400, average reward : -70.1500015258789\n",
            "episode : 4, timestep : 2020800, average reward : -59.31999969482422\n",
            "episode : 5, timestep : 2023200, average reward : -56.150001525878906\n",
            "[2023424] Avg reward (last 50 episodes): -0.03466987609863281\n",
            "episode : 4, timestep : 2025600, average reward : -38.029998779296875\n",
            "episode : 4, timestep : 2028000, average reward : -42.4900016784668\n",
            "episode : 5, timestep : 2030400, average reward : -53.529998779296875\n",
            "[2031616] Avg reward (last 50 episodes): -0.07227703928947449\n",
            "episode : 5, timestep : 2032800, average reward : -55.040000915527344\n",
            "episode : 4, timestep : 2035200, average reward : -39.38999938964844\n",
            "episode : 4, timestep : 2037600, average reward : -64.12999725341797\n",
            "[2039808] Avg reward (last 50 episodes): -0.07170983403921127\n",
            "episode : 4, timestep : 2040000, average reward : -36.470001220703125\n",
            "episode : 5, timestep : 2042400, average reward : -52.650001525878906\n",
            "episode : 4, timestep : 2044800, average reward : -37.779998779296875\n",
            "episode : 5, timestep : 2047200, average reward : -49.36000061035156\n",
            "[2048000] Avg reward (last 50 episodes): -0.08923114091157913\n",
            "episode : 4, timestep : 2049600, average reward : -35.22999954223633\n",
            "episode : 4, timestep : 2052000, average reward : -53.11000061035156\n",
            "episode : 8, timestep : 2054400, average reward : -76.45999908447266\n",
            "[2056192] Avg reward (last 50 episodes): -0.025209443643689156\n",
            "episode : 4, timestep : 2056800, average reward : -40.11000061035156\n",
            "episode : 4, timestep : 2059200, average reward : -35.16999816894531\n",
            "episode : 4, timestep : 2061600, average reward : -40.29999923706055\n",
            "episode : 5, timestep : 2064000, average reward : -68.79000091552734\n",
            "[2064384] Avg reward (last 50 episodes): -0.07059463858604431\n",
            "episode : 4, timestep : 2066400, average reward : -39.88999938964844\n",
            "episode : 5, timestep : 2068800, average reward : -54.650001525878906\n",
            "episode : 4, timestep : 2071200, average reward : -39.16999816894531\n",
            "[2072576] Avg reward (last 50 episodes): -0.06723406910896301\n",
            "episode : 5, timestep : 2073600, average reward : -51.25\n",
            "episode : 6, timestep : 2076000, average reward : -63.84000015258789\n",
            "episode : 5, timestep : 2078400, average reward : -50.9900016784668\n",
            "[2080768] Avg reward (last 50 episodes): -0.13378068804740906\n",
            "episode : 7, timestep : 2080800, average reward : -73.18000030517578\n",
            "episode : 6, timestep : 2083200, average reward : -94.13999938964844\n",
            "episode : 5, timestep : 2085600, average reward : -53.88999938964844\n",
            "episode : 5, timestep : 2088000, average reward : -55.849998474121094\n",
            "[2088960] Avg reward (last 50 episodes): -0.025734005495905876\n",
            "episode : 6, timestep : 2090400, average reward : -82.5199966430664\n",
            "episode : 5, timestep : 2092800, average reward : -58.02000045776367\n",
            "episode : 5, timestep : 2095200, average reward : -55.189998626708984\n",
            "[2097152] Avg reward (last 50 episodes): -0.11807259917259216\n",
            "episode : 4, timestep : 2097600, average reward : -38.43000030517578\n",
            "episode : 4, timestep : 2100000, average reward : -35.5099983215332\n",
            "episode : 4, timestep : 2102400, average reward : -43.650001525878906\n",
            "setting action_std to  0.5949\n",
            "episode : 4, timestep : 2104800, average reward : -44.59000015258789\n",
            "[2105344] Avg reward (last 50 episodes): -0.12890101969242096\n",
            "episode : 6, timestep : 2107200, average reward : -65.80000305175781\n",
            "episode : 4, timestep : 2109600, average reward : -41.060001373291016\n",
            "episode : 4, timestep : 2112000, average reward : -39.79999923706055\n",
            "[2113536] Avg reward (last 50 episodes): -0.15995973348617554\n",
            "episode : 5, timestep : 2114400, average reward : -69.47000122070312\n",
            "episode : 4, timestep : 2116800, average reward : -40.7599983215332\n",
            "episode : 5, timestep : 2119200, average reward : -49.650001525878906\n",
            "episode : 4, timestep : 2121600, average reward : -34.439998626708984\n",
            "[2121728] Avg reward (last 50 episodes): -0.07785680890083313\n",
            "episode : 6, timestep : 2124000, average reward : -65.41000366210938\n",
            "episode : 4, timestep : 2126400, average reward : -64.83000183105469\n",
            "episode : 4, timestep : 2128800, average reward : -45.369998931884766\n",
            "[2129920] Avg reward (last 50 episodes): -0.08487139642238617\n",
            "episode : 5, timestep : 2131200, average reward : -60.119998931884766\n",
            "episode : 5, timestep : 2133600, average reward : -56.4900016784668\n",
            "episode : 6, timestep : 2136000, average reward : -86.63999938964844\n",
            "[2138112] Avg reward (last 50 episodes): -0.05421608313918114\n",
            "episode : 6, timestep : 2138400, average reward : -66.08000183105469\n",
            "episode : 5, timestep : 2140800, average reward : -73.43000030517578\n",
            "episode : 6, timestep : 2143200, average reward : -68.52999877929688\n",
            "episode : 5, timestep : 2145600, average reward : -84.55000305175781\n",
            "[2146304] Avg reward (last 50 episodes): -0.021755415946245193\n",
            "episode : 6, timestep : 2148000, average reward : -68.43000030517578\n",
            "episode : 6, timestep : 2150400, average reward : -68.58999633789062\n",
            "episode : 6, timestep : 2152800, average reward : -68.23999786376953\n",
            "[2154496] Avg reward (last 50 episodes): -0.11192891001701355\n",
            "episode : 4, timestep : 2155200, average reward : -63.75\n",
            "episode : 8, timestep : 2157600, average reward : -79.0999984741211\n",
            "episode : 6, timestep : 2160000, average reward : -68.72000122070312\n",
            "episode : 6, timestep : 2162400, average reward : -68.31999969482422\n",
            "[2162688] Avg reward (last 50 episodes): -0.11939048767089844\n",
            "episode : 4, timestep : 2164800, average reward : -36.59000015258789\n",
            "episode : 5, timestep : 2167200, average reward : -71.5999984741211\n",
            "episode : 6, timestep : 2169600, average reward : -70.87999725341797\n",
            "[2170880] Avg reward (last 50 episodes): -0.011724740266799927\n",
            "episode : 4, timestep : 2172000, average reward : -43.7599983215332\n",
            "episode : 5, timestep : 2174400, average reward : -61.0099983215332\n",
            "episode : 4, timestep : 2176800, average reward : -45.790000915527344\n",
            "[2179072] Avg reward (last 50 episodes): -0.03785933554172516\n",
            "episode : 5, timestep : 2179200, average reward : -61.099998474121094\n",
            "episode : 9, timestep : 2181600, average reward : -88.58999633789062\n",
            "episode : 9, timestep : 2184000, average reward : -85.52999877929688\n",
            "episode : 8, timestep : 2186400, average reward : -88.88999938964844\n",
            "[2187264] Avg reward (last 50 episodes): -0.12460358440876007\n",
            "episode : 6, timestep : 2188800, average reward : -70.13999938964844\n",
            "episode : 4, timestep : 2191200, average reward : -75.20999908447266\n",
            "episode : 7, timestep : 2193600, average reward : -72.3499984741211\n",
            "[2195456] Avg reward (last 50 episodes): -0.03417230769991875\n",
            "episode : 8, timestep : 2196000, average reward : -79.93000030517578\n",
            "episode : 4, timestep : 2198400, average reward : -54.20000076293945\n",
            "episode : 5, timestep : 2200800, average reward : -72.45999908447266\n",
            "episode : 6, timestep : 2203200, average reward : -70.58000183105469\n",
            "[2203648] Avg reward (last 50 episodes): -0.06918830424547195\n",
            "setting action_std to  0.5946\n",
            "episode : 7, timestep : 2205600, average reward : -76.41999816894531\n",
            "episode : 7, timestep : 2208000, average reward : -88.72000122070312\n",
            "episode : 6, timestep : 2210400, average reward : -70.16000366210938\n",
            "[2211840] Avg reward (last 50 episodes): -0.0810977965593338\n",
            "episode : 7, timestep : 2212800, average reward : -75.91000366210938\n",
            "episode : 9, timestep : 2215200, average reward : -90.70999908447266\n",
            "episode : 7, timestep : 2217600, average reward : -75.91999816894531\n",
            "episode : 6, timestep : 2220000, average reward : -69.16000366210938\n",
            "[2220032] Avg reward (last 50 episodes): -2.144653670815751\n",
            "episode : 4, timestep : 2222400, average reward : -59.369998931884766\n",
            "episode : 4, timestep : 2224800, average reward : -45.599998474121094\n",
            "episode : 5, timestep : 2227200, average reward : -60.959999084472656\n",
            "[2228224] Avg reward (last 50 episodes): -0.039629194885492325\n",
            "episode : 4, timestep : 2229600, average reward : -46.02000045776367\n",
            "episode : 9, timestep : 2232000, average reward : -81.26000213623047\n",
            "episode : 6, timestep : 2234400, average reward : -77.7699966430664\n",
            "[2236416] Avg reward (last 50 episodes): -0.19200152158737183\n",
            "episode : 7, timestep : 2236800, average reward : -74.56999969482422\n",
            "episode : 9, timestep : 2239200, average reward : -80.08999633789062\n",
            "episode : 11, timestep : 2241600, average reward : -92.9000015258789\n",
            "episode : 10, timestep : 2244000, average reward : -91.73999786376953\n",
            "[2244608] Avg reward (last 50 episodes): -0.0689774677157402\n",
            "episode : 14, timestep : 2246400, average reward : -98.30999755859375\n",
            "episode : 6, timestep : 2248800, average reward : -69.55000305175781\n",
            "episode : 7, timestep : 2251200, average reward : -85.11000061035156\n",
            "[2252800] Avg reward (last 50 episodes): -0.122138112783432\n",
            "episode : 9, timestep : 2253600, average reward : -80.81999969482422\n",
            "episode : 13, timestep : 2256000, average reward : -100.58999633789062\n",
            "episode : 18, timestep : 2258400, average reward : -99.75\n",
            "episode : 12, timestep : 2260800, average reward : -93.23999786376953\n",
            "[2260992] Avg reward (last 50 episodes): 0.046177271753549576\n",
            "episode : 6, timestep : 2263200, average reward : -78.76000213623047\n",
            "episode : 10, timestep : 2265600, average reward : -91.08000183105469\n",
            "episode : 9, timestep : 2268000, average reward : -83.20999908447266\n",
            "[2269184] Avg reward (last 50 episodes): -0.06925546377897263\n",
            "episode : 12, timestep : 2270400, average reward : -94.20999908447266\n",
            "episode : 12, timestep : 2272800, average reward : -94.95999908447266\n",
            "episode : 10, timestep : 2275200, average reward : -91.41999816894531\n",
            "[2277376] Avg reward (last 50 episodes): -0.02984781563282013\n",
            "episode : 12, timestep : 2277600, average reward : -95.3499984741211\n",
            "episode : 8, timestep : 2280000, average reward : -79.7699966430664\n",
            "episode : 16, timestep : 2282400, average reward : -98.25\n",
            "episode : 15, timestep : 2284800, average reward : -101.73999786376953\n",
            "[2285568] Avg reward (last 50 episodes): -0.0668165385723114\n",
            "episode : 28, timestep : 2287200, average reward : -107.16000366210938\n",
            "episode : 29, timestep : 2289600, average reward : -109.7300033569336\n",
            "episode : 16, timestep : 2292000, average reward : -103.16999816894531\n",
            "[2293760] Avg reward (last 50 episodes): -0.16559110581874847\n",
            "episode : 30, timestep : 2294400, average reward : -106.8499984741211\n",
            "episode : 14, timestep : 2296800, average reward : -100.18000030517578\n",
            "episode : 24, timestep : 2299200, average reward : -105.06999969482422\n",
            "episode : 17, timestep : 2301600, average reward : -99.31999969482422\n",
            "[2301952] Avg reward (last 50 episodes): -2.217226757407188\n",
            "episode : 12, timestep : 2304000, average reward : -95.68000030517578\n",
            "setting action_std to  0.5943\n",
            "episode : 5, timestep : 2306400, average reward : -57.209999084472656\n",
            "episode : 4, timestep : 2308800, average reward : -57.97999954223633\n",
            "[2310144] Avg reward (last 50 episodes): -0.12450023740530014\n",
            "episode : 11, timestep : 2311200, average reward : -84.77999877929688\n",
            "episode : 8, timestep : 2313600, average reward : -83.47000122070312\n",
            "episode : 8, timestep : 2316000, average reward : -75.02999877929688\n",
            "[2318336] Avg reward (last 50 episodes): -0.08520712703466415\n",
            "episode : 7, timestep : 2318400, average reward : -88.31999969482422\n",
            "episode : 9, timestep : 2320800, average reward : -86.54000091552734\n",
            "episode : 5, timestep : 2323200, average reward : -54.90999984741211\n",
            "episode : 9, timestep : 2325600, average reward : -85.23999786376953\n",
            "[2326528] Avg reward (last 50 episodes): -0.01868460886180401\n",
            "episode : 17, timestep : 2328000, average reward : -99.01000213623047\n",
            "episode : 6, timestep : 2330400, average reward : -74.94000244140625\n",
            "episode : 9, timestep : 2332800, average reward : -80.68000030517578\n",
            "[2334720] Avg reward (last 50 episodes): -0.07063572108745575\n",
            "episode : 8, timestep : 2335200, average reward : -87.06999969482422\n",
            "episode : 4, timestep : 2337600, average reward : -43.880001068115234\n",
            "episode : 4, timestep : 2340000, average reward : -43.560001373291016\n",
            "episode : 5, timestep : 2342400, average reward : -58.380001068115234\n",
            "[2342912] Avg reward (last 50 episodes): -0.06081850081682205\n",
            "episode : 6, timestep : 2344800, average reward : -72.29000091552734\n",
            "episode : 6, timestep : 2347200, average reward : -73.16000366210938\n",
            "episode : 5, timestep : 2349600, average reward : -79.08000183105469\n",
            "[2351104] Avg reward (last 50 episodes): -0.05091799795627594\n",
            "episode : 6, timestep : 2352000, average reward : -60.0099983215332\n",
            "episode : 4, timestep : 2354400, average reward : -37.939998626708984\n",
            "episode : 4, timestep : 2356800, average reward : -56.209999084472656\n",
            "episode : 6, timestep : 2359200, average reward : -65.1500015258789\n",
            "[2359296] Avg reward (last 50 episodes): 0.023979566991329193\n",
            "episode : 5, timestep : 2361600, average reward : -51.58000183105469\n",
            "episode : 4, timestep : 2364000, average reward : -73.86000061035156\n",
            "episode : 8, timestep : 2366400, average reward : -75.7699966430664\n",
            "[2367488] Avg reward (last 50 episodes): 0.03361468389630318\n",
            "episode : 4, timestep : 2368800, average reward : -36.13999938964844\n",
            "episode : 4, timestep : 2371200, average reward : -36.45000076293945\n",
            "episode : 6, timestep : 2373600, average reward : -62.31999969482422\n",
            "[2375680] Avg reward (last 50 episodes): -0.020831722766160965\n",
            "episode : 4, timestep : 2376000, average reward : -30.75\n",
            "episode : 5, timestep : 2378400, average reward : -71.3499984741211\n",
            "episode : 4, timestep : 2380800, average reward : -33.68000030517578\n",
            "episode : 4, timestep : 2383200, average reward : -51.529998779296875\n",
            "[2383872] Avg reward (last 50 episodes): -0.07985023409128189\n",
            "episode : 8, timestep : 2385600, average reward : -71.0999984741211\n",
            "episode : 5, timestep : 2388000, average reward : -67.29000091552734\n",
            "episode : 9, timestep : 2390400, average reward : -89.56999969482422\n",
            "[2392064] Avg reward (last 50 episodes): -0.07997621595859528\n",
            "episode : 5, timestep : 2392800, average reward : -52.5099983215332\n",
            "episode : 6, timestep : 2395200, average reward : -81.86000061035156\n",
            "episode : 5, timestep : 2397600, average reward : -70.7300033569336\n",
            "episode : 4, timestep : 2400000, average reward : -42.720001220703125\n",
            "[2400256] Avg reward (last 50 episodes): -2.205474186614156\n",
            "episode : 5, timestep : 2402400, average reward : -60.41999816894531\n",
            "episode : 5, timestep : 2404800, average reward : -57.84000015258789\n",
            "setting action_std to  0.594\n",
            "episode : 6, timestep : 2407200, average reward : -73.5999984741211\n",
            "[2408448] Avg reward (last 50 episodes): -0.05669902637600899\n",
            "episode : 7, timestep : 2409600, average reward : -71.18000030517578\n",
            "episode : 11, timestep : 2412000, average reward : -93.4000015258789\n",
            "episode : 5, timestep : 2414400, average reward : -53.91999816894531\n",
            "[2416640] Avg reward (last 50 episodes): -0.07560814172029495\n",
            "episode : 10, timestep : 2416800, average reward : -88.37999725341797\n",
            "episode : 6, timestep : 2419200, average reward : -76.26000213623047\n",
            "episode : 8, timestep : 2421600, average reward : -74.05999755859375\n",
            "episode : 10, timestep : 2424000, average reward : -91.80000305175781\n",
            "[2424832] Avg reward (last 50 episodes): -0.0744938924908638\n",
            "episode : 8, timestep : 2426400, average reward : -84.25\n",
            "episode : 9, timestep : 2428800, average reward : -93.37999725341797\n",
            "episode : 10, timestep : 2431200, average reward : -82.9000015258789\n",
            "[2433024] Avg reward (last 50 episodes): -0.13830353319644928\n",
            "episode : 11, timestep : 2433600, average reward : -89.16999816894531\n",
            "episode : 16, timestep : 2436000, average reward : -102.22000122070312\n",
            "episode : 6, timestep : 2438400, average reward : -74.02999877929688\n",
            "episode : 13, timestep : 2440800, average reward : -94.08000183105469\n",
            "[2441216] Avg reward (last 50 episodes): -0.1039196103811264\n",
            "episode : 9, timestep : 2443200, average reward : -81.0999984741211\n",
            "episode : 6, timestep : 2445600, average reward : -73.5199966430664\n",
            "episode : 13, timestep : 2448000, average reward : -92.54000091552734\n",
            "[2449408] Avg reward (last 50 episodes): -0.06712255626916885\n",
            "episode : 9, timestep : 2450400, average reward : -87.20999908447266\n",
            "episode : 5, timestep : 2452800, average reward : -69.87000274658203\n",
            "episode : 9, timestep : 2455200, average reward : -80.05999755859375\n",
            "[2457600] Avg reward (last 50 episodes): -0.061436910182237625\n",
            "episode : 9, timestep : 2457600, average reward : -84.93000030517578\n",
            "episode : 14, timestep : 2460000, average reward : -95.73999786376953\n",
            "episode : 13, timestep : 2462400, average reward : -102.4000015258789\n",
            "episode : 23, timestep : 2464800, average reward : -105.86000061035156\n",
            "[2465792] Avg reward (last 50 episodes): -0.07917258143424988\n",
            "episode : 9, timestep : 2467200, average reward : -86.1500015258789\n",
            "episode : 11, timestep : 2469600, average reward : -94.97000122070312\n",
            "episode : 16, timestep : 2472000, average reward : -103.62000274658203\n",
            "[2473984] Avg reward (last 50 episodes): -0.0654158815741539\n",
            "episode : 23, timestep : 2474400, average reward : -103.86000061035156\n",
            "episode : 11, timestep : 2476800, average reward : -92.83999633789062\n",
            "episode : 5, timestep : 2479200, average reward : -70.68000030517578\n",
            "episode : 8, timestep : 2481600, average reward : -77.02999877929688\n",
            "[2482176] Avg reward (last 50 episodes): -0.08457575738430023\n",
            "episode : 14, timestep : 2484000, average reward : -97.77999877929688\n",
            "episode : 6, timestep : 2486400, average reward : -65.0999984741211\n",
            "episode : 20, timestep : 2488800, average reward : -104.69999694824219\n",
            "[2490368] Avg reward (last 50 episodes): -2.106524731107056\n",
            "episode : 14, timestep : 2491200, average reward : -96.36000061035156\n",
            "episode : 6, timestep : 2493600, average reward : -76.47000122070312\n",
            "episode : 9, timestep : 2496000, average reward : -82.20999908447266\n",
            "episode : 7, timestep : 2498400, average reward : -81.73999786376953\n",
            "[2498560] Avg reward (last 50 episodes): -0.09590914845466614\n",
            "episode : 8, timestep : 2500800, average reward : -77.83000183105469\n",
            "episode : 5, timestep : 2503200, average reward : -57.720001220703125\n",
            "setting action_std to  0.5937\n",
            "episode : 6, timestep : 2505600, average reward : -64.7699966430664\n",
            "[2506752] Avg reward (last 50 episodes): -0.08208438009023666\n",
            "episode : 20, timestep : 2508000, average reward : -105.08999633789062\n",
            "episode : 19, timestep : 2510400, average reward : -106.45999908447266\n",
            "episode : 13, timestep : 2512800, average reward : -96.9000015258789\n",
            "[2514944] Avg reward (last 50 episodes): -2.185556706376374\n",
            "episode : 16, timestep : 2515200, average reward : -105.43000030517578\n",
            "episode : 16, timestep : 2517600, average reward : -106.05000305175781\n",
            "episode : 16, timestep : 2520000, average reward : -107.13999938964844\n",
            "episode : 27, timestep : 2522400, average reward : -112.11000061035156\n",
            "[2523136] Avg reward (last 50 episodes): -0.05966811999678612\n",
            "episode : 17, timestep : 2524800, average reward : -104.70999908447266\n",
            "episode : 18, timestep : 2527200, average reward : -104.38999938964844\n",
            "episode : 24, timestep : 2529600, average reward : -109.69999694824219\n",
            "[2531328] Avg reward (last 50 episodes): 0.019513746723532677\n",
            "episode : 20, timestep : 2532000, average reward : -107.87999725341797\n",
            "episode : 9, timestep : 2534400, average reward : -78.41000366210938\n",
            "episode : 4, timestep : 2536800, average reward : -40.29999923706055\n",
            "episode : 6, timestep : 2539200, average reward : -64.66000366210938\n",
            "[2539520] Avg reward (last 50 episodes): -0.10802458971738815\n",
            "episode : 4, timestep : 2541600, average reward : -39.9900016784668\n",
            "episode : 6, timestep : 2544000, average reward : -74.08999633789062\n",
            "episode : 5, timestep : 2546400, average reward : -71.48999786376953\n",
            "[2547712] Avg reward (last 50 episodes): -0.05408132076263428\n",
            "episode : 4, timestep : 2548800, average reward : -42.54999923706055\n",
            "episode : 6, timestep : 2551200, average reward : -65.91000366210938\n",
            "episode : 5, timestep : 2553600, average reward : -52.15999984741211\n",
            "[2555904] Avg reward (last 50 episodes): -0.06791894137859344\n",
            "episode : 4, timestep : 2556000, average reward : -46.95000076293945\n",
            "episode : 6, timestep : 2558400, average reward : -67.19000244140625\n",
            "episode : 4, timestep : 2560800, average reward : -41.29999923706055\n",
            "episode : 5, timestep : 2563200, average reward : -55.36000061035156\n",
            "[2564096] Avg reward (last 50 episodes): -0.11774194985628128\n",
            "episode : 4, timestep : 2565600, average reward : -41.540000915527344\n",
            "episode : 6, timestep : 2568000, average reward : -62.369998931884766\n",
            "episode : 6, timestep : 2570400, average reward : -76.12000274658203\n",
            "[2572288] Avg reward (last 50 episodes): -0.023182934150099754\n",
            "episode : 5, timestep : 2572800, average reward : -89.44000244140625\n",
            "episode : 4, timestep : 2575200, average reward : -36.7599983215332\n",
            "episode : 5, timestep : 2577600, average reward : -58.619998931884766\n",
            "episode : 5, timestep : 2580000, average reward : -66.2300033569336\n",
            "[2580480] Avg reward (last 50 episodes): -0.11946108937263489\n",
            "episode : 5, timestep : 2582400, average reward : -53.79999923706055\n",
            "episode : 4, timestep : 2584800, average reward : -38.34000015258789\n",
            "episode : 6, timestep : 2587200, average reward : -66.55000305175781\n",
            "[2588672] Avg reward (last 50 episodes): -0.10714558511972427\n",
            "episode : 6, timestep : 2589600, average reward : -75.29000091552734\n",
            "episode : 7, timestep : 2592000, average reward : -73.70999908447266\n",
            "episode : 7, timestep : 2594400, average reward : -74.9000015258789\n",
            "episode : 6, timestep : 2596800, average reward : -76.2300033569336\n",
            "[2596864] Avg reward (last 50 episodes): -0.07298524677753448\n",
            "episode : 4, timestep : 2599200, average reward : -44.529998779296875\n",
            "episode : 4, timestep : 2601600, average reward : -45.72999954223633\n",
            "episode : 5, timestep : 2604000, average reward : -64.98999786376953\n",
            "[2605056] Avg reward (last 50 episodes): -0.09050873667001724\n",
            "setting action_std to  0.5934\n",
            "episode : 4, timestep : 2606400, average reward : -45.41999816894531\n",
            "episode : 6, timestep : 2608800, average reward : -68.33999633789062\n",
            "episode : 8, timestep : 2611200, average reward : -78.8499984741211\n",
            "[2613248] Avg reward (last 50 episodes): -0.046335719525814056\n",
            "episode : 6, timestep : 2613600, average reward : -80.45999908447266\n",
            "episode : 5, timestep : 2616000, average reward : -58.150001525878906\n",
            "episode : 6, timestep : 2618400, average reward : -63.560001373291016\n",
            "episode : 7, timestep : 2620800, average reward : -72.95999908447266\n",
            "[2621440] Avg reward (last 50 episodes): -0.152263343334198\n",
            "episode : 8, timestep : 2623200, average reward : -90.04000091552734\n",
            "episode : 5, timestep : 2625600, average reward : -72.05999755859375\n",
            "episode : 6, timestep : 2628000, average reward : -63.279998779296875\n",
            "[2629632] Avg reward (last 50 episodes): -2.2265070515871046\n",
            "episode : 8, timestep : 2630400, average reward : -75.80000305175781\n",
            "episode : 5, timestep : 2632800, average reward : -69.43000030517578\n",
            "episode : 8, timestep : 2635200, average reward : -79.37000274658203\n",
            "episode : 6, timestep : 2637600, average reward : -62.7599983215332\n",
            "[2637824] Avg reward (last 50 episodes): -0.07320886105298996\n",
            "episode : 4, timestep : 2640000, average reward : -35.849998474121094\n",
            "episode : 4, timestep : 2642400, average reward : -55.849998474121094\n",
            "episode : 5, timestep : 2644800, average reward : -68.25\n",
            "[2646016] Avg reward (last 50 episodes): -0.04147382080554962\n",
            "episode : 8, timestep : 2647200, average reward : -74.08999633789062\n",
            "episode : 4, timestep : 2649600, average reward : -35.63999938964844\n",
            "episode : 7, timestep : 2652000, average reward : -72.5199966430664\n",
            "[2654208] Avg reward (last 50 episodes): 0.10847585648298264\n",
            "episode : 6, timestep : 2654400, average reward : -75.05000305175781\n",
            "episode : 4, timestep : 2656800, average reward : -43.91999816894531\n",
            "episode : 4, timestep : 2659200, average reward : -38.38999938964844\n",
            "episode : 6, timestep : 2661600, average reward : -63.689998626708984\n",
            "[2662400] Avg reward (last 50 episodes): -0.104921855032444\n",
            "episode : 6, timestep : 2664000, average reward : -66.13999938964844\n",
            "episode : 5, timestep : 2666400, average reward : -53.86000061035156\n",
            "episode : 4, timestep : 2668800, average reward : -59.939998626708984\n",
            "[2670592] Avg reward (last 50 episodes): -0.08227849006652832\n",
            "episode : 6, timestep : 2671200, average reward : -67.77999877929688\n",
            "episode : 5, timestep : 2673600, average reward : -56.060001373291016\n",
            "episode : 5, timestep : 2676000, average reward : -57.310001373291016\n",
            "episode : 4, timestep : 2678400, average reward : -42.81999969482422\n",
            "[2678784] Avg reward (last 50 episodes): 0.012438773177564144\n",
            "episode : 6, timestep : 2680800, average reward : -69.63999938964844\n",
            "episode : 6, timestep : 2683200, average reward : -86.63999938964844\n",
            "episode : 4, timestep : 2685600, average reward : -45.709999084472656\n",
            "[2686976] Avg reward (last 50 episodes): -0.019941046833992004\n",
            "episode : 6, timestep : 2688000, average reward : -68.0999984741211\n",
            "episode : 7, timestep : 2690400, average reward : -85.22000122070312\n",
            "episode : 6, timestep : 2692800, average reward : -89.44999694824219\n",
            "[2695168] Avg reward (last 50 episodes): -0.043033868074417114\n",
            "episode : 8, timestep : 2695200, average reward : -85.5\n",
            "episode : 10, timestep : 2697600, average reward : -92.62999725341797\n",
            "episode : 6, timestep : 2700000, average reward : -82.8499984741211\n",
            "episode : 4, timestep : 2702400, average reward : -59.02000045776367\n",
            "[2703360] Avg reward (last 50 episodes): 0.028890900313854218\n",
            "episode : 6, timestep : 2704800, average reward : -65.44000244140625\n",
            "setting action_std to  0.5931\n",
            "episode : 6, timestep : 2707200, average reward : -68.55000305175781\n",
            "episode : 6, timestep : 2709600, average reward : -67.4000015258789\n",
            "[2711552] Avg reward (last 50 episodes): -0.05920054763555527\n",
            "episode : 5, timestep : 2712000, average reward : -74.23999786376953\n",
            "episode : 8, timestep : 2714400, average reward : -94.7300033569336\n",
            "episode : 5, timestep : 2716800, average reward : -59.150001525878906\n",
            "episode : 8, timestep : 2719200, average reward : -90.30000305175781\n",
            "[2719744] Avg reward (last 50 episodes): -0.018014736473560333\n",
            "episode : 9, timestep : 2721600, average reward : -92.77999877929688\n",
            "episode : 6, timestep : 2724000, average reward : -83.77999877929688\n",
            "episode : 8, timestep : 2726400, average reward : -101.04000091552734\n",
            "[2727936] Avg reward (last 50 episodes): -2.2752185812592507\n",
            "episode : 8, timestep : 2728800, average reward : -95.7300033569336\n",
            "episode : 4, timestep : 2731200, average reward : -39.5\n",
            "episode : 4, timestep : 2733600, average reward : -43.43000030517578\n",
            "episode : 4, timestep : 2736000, average reward : -44.5\n",
            "[2736128] Avg reward (last 50 episodes): -0.17903579771518707\n",
            "episode : 5, timestep : 2738400, average reward : -74.13999938964844\n",
            "episode : 4, timestep : 2740800, average reward : -66.05000305175781\n",
            "episode : 6, timestep : 2743200, average reward : -71.58999633789062\n",
            "[2744320] Avg reward (last 50 episodes): -0.057694077491760254\n",
            "episode : 5, timestep : 2745600, average reward : -74.52999877929688\n",
            "episode : 6, timestep : 2748000, average reward : -67.7699966430664\n",
            "episode : 4, timestep : 2750400, average reward : -38.91999816894531\n",
            "[2752512] Avg reward (last 50 episodes): -0.09675421565771103\n",
            "episode : 6, timestep : 2752800, average reward : -69.37999725341797\n",
            "episode : 8, timestep : 2755200, average reward : -77.66999816894531\n",
            "episode : 9, timestep : 2757600, average reward : -102.20999908447266\n",
            "episode : 7, timestep : 2760000, average reward : -73.4800033569336\n",
            "[2760704] Avg reward (last 50 episodes): -0.17244265973567963\n",
            "episode : 6, timestep : 2762400, average reward : -84.0\n",
            "episode : 5, timestep : 2764800, average reward : -52.400001525878906\n",
            "episode : 5, timestep : 2767200, average reward : -54.91999816894531\n",
            "[2768896] Avg reward (last 50 episodes): -0.05799870565533638\n",
            "episode : 4, timestep : 2769600, average reward : -63.290000915527344\n",
            "episode : 4, timestep : 2772000, average reward : -40.939998626708984\n",
            "episode : 4, timestep : 2774400, average reward : -40.810001373291016\n",
            "episode : 4, timestep : 2776800, average reward : -42.06999969482422\n",
            "[2777088] Avg reward (last 50 episodes): -0.03770079463720322\n",
            "episode : 5, timestep : 2779200, average reward : -55.400001525878906\n",
            "episode : 9, timestep : 2781600, average reward : -92.18000030517578\n",
            "episode : 11, timestep : 2784000, average reward : -96.19000244140625\n",
            "[2785280] Avg reward (last 50 episodes): -0.043744005262851715\n",
            "episode : 5, timestep : 2786400, average reward : -52.709999084472656\n",
            "episode : 4, timestep : 2788800, average reward : -39.459999084472656\n",
            "episode : 7, timestep : 2791200, average reward : -84.77999877929688\n",
            "[2793472] Avg reward (last 50 episodes): -0.06765231490135193\n",
            "episode : 4, timestep : 2793600, average reward : -36.33000183105469\n",
            "episode : 7, timestep : 2796000, average reward : -71.83999633789062\n",
            "episode : 6, timestep : 2798400, average reward : -75.37000274658203\n",
            "episode : 6, timestep : 2800800, average reward : -76.79000091552734\n",
            "[2801664] Avg reward (last 50 episodes): -0.05178306996822357\n",
            "episode : 5, timestep : 2803200, average reward : -51.790000915527344\n",
            "episode : 7, timestep : 2805600, average reward : -82.19999694824219\n",
            "setting action_std to  0.5928\n",
            "episode : 6, timestep : 2808000, average reward : -65.41000366210938\n",
            "[2809856] Avg reward (last 50 episodes): -0.1049986183643341\n",
            "episode : 4, timestep : 2810400, average reward : -38.2400016784668\n",
            "episode : 6, timestep : 2812800, average reward : -99.7699966430664\n",
            "episode : 6, timestep : 2815200, average reward : -66.83999633789062\n",
            "episode : 4, timestep : 2817600, average reward : -39.08000183105469\n",
            "[2818048] Avg reward (last 50 episodes): -0.07736876606941223\n",
            "episode : 6, timestep : 2820000, average reward : -82.18000030517578\n",
            "episode : 6, timestep : 2822400, average reward : -62.09000015258789\n",
            "episode : 5, timestep : 2824800, average reward : -67.44000244140625\n",
            "[2826240] Avg reward (last 50 episodes): -0.07249271124601364\n",
            "episode : 7, timestep : 2827200, average reward : -73.75\n",
            "episode : 7, timestep : 2829600, average reward : -100.63999938964844\n",
            "episode : 5, timestep : 2832000, average reward : -71.33999633789062\n",
            "episode : 6, timestep : 2834400, average reward : -99.20999908447266\n",
            "[2834432] Avg reward (last 50 episodes): -0.10847288370132446\n",
            "episode : 5, timestep : 2836800, average reward : -52.18000030517578\n",
            "episode : 4, timestep : 2839200, average reward : -37.2599983215332\n",
            "episode : 5, timestep : 2841600, average reward : -52.40999984741211\n",
            "[2842624] Avg reward (last 50 episodes): -0.06764097511768341\n",
            "episode : 4, timestep : 2844000, average reward : -37.56999969482422\n",
            "episode : 6, timestep : 2846400, average reward : -62.7599983215332\n",
            "episode : 4, timestep : 2848800, average reward : -40.400001525878906\n",
            "[2850816] Avg reward (last 50 episodes): -0.1025046557188034\n",
            "episode : 4, timestep : 2851200, average reward : -54.470001220703125\n",
            "episode : 4, timestep : 2853600, average reward : -32.599998474121094\n",
            "episode : 4, timestep : 2856000, average reward : -38.880001068115234\n",
            "episode : 4, timestep : 2858400, average reward : -42.459999084472656\n",
            "[2859008] Avg reward (last 50 episodes): -0.047796960920095444\n",
            "episode : 6, timestep : 2860800, average reward : -70.73999786376953\n",
            "episode : 4, timestep : 2863200, average reward : -61.709999084472656\n",
            "episode : 4, timestep : 2865600, average reward : -62.77000045776367\n",
            "[2867200] Avg reward (last 50 episodes): -0.0422934927046299\n",
            "episode : 4, timestep : 2868000, average reward : -63.29999923706055\n",
            "episode : 5, timestep : 2870400, average reward : -57.16999816894531\n",
            "episode : 5, timestep : 2872800, average reward : -54.279998779296875\n",
            "episode : 4, timestep : 2875200, average reward : -36.52000045776367\n",
            "[2875392] Avg reward (last 50 episodes): -0.09652978926897049\n",
            "episode : 4, timestep : 2877600, average reward : -34.47999954223633\n",
            "episode : 5, timestep : 2880000, average reward : -52.209999084472656\n",
            "episode : 4, timestep : 2882400, average reward : -39.279998779296875\n",
            "[2883584] Avg reward (last 50 episodes): -0.07515686750411987\n",
            "episode : 4, timestep : 2884800, average reward : -59.900001525878906\n",
            "episode : 5, timestep : 2887200, average reward : -57.54999923706055\n",
            "episode : 5, timestep : 2889600, average reward : -58.5\n",
            "[2891776] Avg reward (last 50 episodes): -0.07723011076450348\n",
            "episode : 4, timestep : 2892000, average reward : -35.56999969482422\n",
            "episode : 4, timestep : 2894400, average reward : -37.36000061035156\n",
            "episode : 4, timestep : 2896800, average reward : -55.630001068115234\n",
            "episode : 5, timestep : 2899200, average reward : -76.73999786376953\n",
            "[2899968] Avg reward (last 50 episodes): -0.03389095142483711\n",
            "episode : 6, timestep : 2901600, average reward : -92.58999633789062\n",
            "episode : 7, timestep : 2904000, average reward : -88.70999908447266\n",
            "episode : 4, timestep : 2906400, average reward : -36.459999084472656\n",
            "setting action_std to  0.5925\n",
            "[2908160] Avg reward (last 50 episodes): -0.07314161956310272\n",
            "episode : 4, timestep : 2908800, average reward : -59.099998474121094\n",
            "episode : 4, timestep : 2911200, average reward : -36.599998474121094\n",
            "episode : 4, timestep : 2913600, average reward : -58.95000076293945\n",
            "episode : 7, timestep : 2916000, average reward : -70.5999984741211\n",
            "[2916352] Avg reward (last 50 episodes): -0.07759974151849747\n",
            "episode : 4, timestep : 2918400, average reward : -41.02000045776367\n",
            "episode : 5, timestep : 2920800, average reward : -57.2599983215332\n",
            "episode : 4, timestep : 2923200, average reward : -40.54999923706055\n",
            "[2924544] Avg reward (last 50 episodes): -0.07385590672492981\n",
            "episode : 4, timestep : 2925600, average reward : -39.310001373291016\n",
            "episode : 5, timestep : 2928000, average reward : -54.83000183105469\n",
            "episode : 6, timestep : 2930400, average reward : -78.25\n",
            "[2932736] Avg reward (last 50 episodes): -0.09575559943914413\n",
            "episode : 5, timestep : 2932800, average reward : -55.41999816894531\n",
            "episode : 5, timestep : 2935200, average reward : -78.93000030517578\n",
            "episode : 4, timestep : 2937600, average reward : -60.61000061035156\n",
            "episode : 4, timestep : 2940000, average reward : -46.029998779296875\n",
            "[2940928] Avg reward (last 50 episodes): -0.0545152872800827\n",
            "episode : 5, timestep : 2942400, average reward : -50.869998931884766\n",
            "episode : 6, timestep : 2944800, average reward : -63.70000076293945\n",
            "episode : 4, timestep : 2947200, average reward : -61.470001220703125\n",
            "[2949120] Avg reward (last 50 episodes): -0.05569704994559288\n",
            "episode : 7, timestep : 2949600, average reward : -72.05999755859375\n",
            "episode : 4, timestep : 2952000, average reward : -38.130001068115234\n",
            "episode : 4, timestep : 2954400, average reward : -40.939998626708984\n",
            "episode : 4, timestep : 2956800, average reward : -38.83000183105469\n",
            "[2957312] Avg reward (last 50 episodes): -0.11706911027431488\n",
            "episode : 6, timestep : 2959200, average reward : -100.23999786376953\n",
            "episode : 5, timestep : 2961600, average reward : -121.93000030517578\n",
            "episode : 5, timestep : 2964000, average reward : -71.7699966430664\n",
            "[2965504] Avg reward (last 50 episodes): -0.053820766508579254\n",
            "episode : 6, timestep : 2966400, average reward : -62.18000030517578\n",
            "episode : 6, timestep : 2968800, average reward : -116.55000305175781\n",
            "episode : 11, timestep : 2971200, average reward : -113.06999969482422\n",
            "episode : 6, timestep : 2973600, average reward : -78.23999786376953\n",
            "[2973696] Avg reward (last 50 episodes): -0.055632997304201126\n",
            "episode : 5, timestep : 2976000, average reward : -54.79999923706055\n",
            "episode : 6, timestep : 2978400, average reward : -112.51000213623047\n",
            "episode : 5, timestep : 2980800, average reward : -66.73999786376953\n",
            "[2981888] Avg reward (last 50 episodes): -0.10052700340747833\n",
            "episode : 5, timestep : 2983200, average reward : -50.22999954223633\n",
            "episode : 5, timestep : 2985600, average reward : -77.33000183105469\n",
            "episode : 8, timestep : 2988000, average reward : -96.4800033569336\n",
            "[2990080] Avg reward (last 50 episodes): -0.07993198931217194\n",
            "episode : 6, timestep : 2990400, average reward : -99.58000183105469\n",
            "episode : 5, timestep : 2992800, average reward : -55.66999816894531\n",
            "episode : 4, timestep : 2995200, average reward : -40.41999816894531\n",
            "episode : 5, timestep : 2997600, average reward : -54.880001068115234\n",
            "[2998272] Avg reward (last 50 episodes): -2.2262312130630018\n",
            "episode : 4, timestep : 3000000, average reward : -59.40999984741211\n",
            "episode : 4, timestep : 3002400, average reward : -39.709999084472656\n",
            "episode : 7, timestep : 3004800, average reward : -86.9800033569336\n",
            "[3006464] Avg reward (last 50 episodes): -0.09441143274307251\n",
            "setting action_std to  0.5922\n",
            "episode : 4, timestep : 3007200, average reward : -42.04999923706055\n",
            "episode : 6, timestep : 3009600, average reward : -65.38999938964844\n",
            "episode : 4, timestep : 3012000, average reward : -36.869998931884766\n",
            "episode : 4, timestep : 3014400, average reward : -56.5099983215332\n",
            "[3014656] Avg reward (last 50 episodes): -0.09720198810100555\n",
            "episode : 4, timestep : 3016800, average reward : -44.279998779296875\n",
            "episode : 4, timestep : 3019200, average reward : -43.810001373291016\n",
            "episode : 4, timestep : 3021600, average reward : -45.11000061035156\n",
            "[3022848] Avg reward (last 50 episodes): -0.08700048178434372\n",
            "episode : 4, timestep : 3024000, average reward : -41.5099983215332\n",
            "episode : 5, timestep : 3026400, average reward : -54.900001525878906\n",
            "episode : 4, timestep : 3028800, average reward : -40.95000076293945\n",
            "[3031040] Avg reward (last 50 episodes): -0.06422760337591171\n",
            "episode : 4, timestep : 3031200, average reward : -44.04999923706055\n",
            "episode : 5, timestep : 3033600, average reward : -54.81999969482422\n",
            "episode : 6, timestep : 3036000, average reward : -66.22000122070312\n",
            "episode : 4, timestep : 3038400, average reward : -38.34000015258789\n",
            "[3039232] Avg reward (last 50 episodes): -0.06282804161310196\n",
            "episode : 5, timestep : 3040800, average reward : -56.45000076293945\n",
            "episode : 4, timestep : 3043200, average reward : -41.790000915527344\n",
            "episode : 5, timestep : 3045600, average reward : -55.0099983215332\n",
            "[3047424] Avg reward (last 50 episodes): -0.2208787500858307\n",
            "episode : 4, timestep : 3048000, average reward : -44.31999969482422\n",
            "episode : 5, timestep : 3050400, average reward : -57.58000183105469\n",
            "episode : 4, timestep : 3052800, average reward : -41.36000061035156\n",
            "episode : 4, timestep : 3055200, average reward : -58.58000183105469\n",
            "[3055616] Avg reward (last 50 episodes): -0.0836673378944397\n",
            "episode : 5, timestep : 3057600, average reward : -61.599998474121094\n",
            "episode : 6, timestep : 3060000, average reward : -65.86000061035156\n",
            "episode : 5, timestep : 3062400, average reward : -57.849998474121094\n",
            "[3063808] Avg reward (last 50 episodes): -0.061681509017944336\n",
            "episode : 4, timestep : 3064800, average reward : -41.18000030517578\n",
            "episode : 4, timestep : 3067200, average reward : -43.15999984741211\n",
            "episode : 4, timestep : 3069600, average reward : -62.52000045776367\n",
            "[3072000] Avg reward (last 50 episodes): -0.005031920503824949\n",
            "episode : 4, timestep : 3072000, average reward : -64.79000091552734\n",
            "episode : 6, timestep : 3074400, average reward : -63.58000183105469\n",
            "episode : 4, timestep : 3076800, average reward : -40.619998931884766\n",
            "episode : 6, timestep : 3079200, average reward : -66.41999816894531\n",
            "[3080192] Avg reward (last 50 episodes): -0.07983329892158508\n",
            "episode : 7, timestep : 3081600, average reward : -85.05999755859375\n",
            "episode : 4, timestep : 3084000, average reward : -70.86000061035156\n",
            "episode : 5, timestep : 3086400, average reward : -75.81999969482422\n",
            "[3088384] Avg reward (last 50 episodes): -0.11255352199077606\n",
            "episode : 5, timestep : 3088800, average reward : -50.099998474121094\n",
            "episode : 6, timestep : 3091200, average reward : -63.560001373291016\n",
            "episode : 7, timestep : 3093600, average reward : -71.83999633789062\n",
            "episode : 6, timestep : 3096000, average reward : -92.37999725341797\n",
            "[3096576] Avg reward (last 50 episodes): -0.04682445526123047\n",
            "episode : 6, timestep : 3098400, average reward : -65.5999984741211\n",
            "episode : 5, timestep : 3100800, average reward : -75.9800033569336\n",
            "episode : 8, timestep : 3103200, average reward : -76.91999816894531\n",
            "[3104768] Avg reward (last 50 episodes): 0.03685181587934494\n",
            "episode : 6, timestep : 3105600, average reward : -89.83999633789062\n",
            "setting action_std to  0.5919\n",
            "episode : 7, timestep : 3108000, average reward : -74.7300033569336\n",
            "episode : 5, timestep : 3110400, average reward : -54.04999923706055\n",
            "episode : 7, timestep : 3112800, average reward : -87.80000305175781\n",
            "[3112960] Avg reward (last 50 episodes): -0.06261060386896133\n",
            "episode : 4, timestep : 3115200, average reward : -36.84000015258789\n",
            "episode : 5, timestep : 3117600, average reward : -55.970001220703125\n",
            "episode : 7, timestep : 3120000, average reward : -81.51000213623047\n",
            "[3121152] Avg reward (last 50 episodes): -0.04984061419963837\n",
            "episode : 7, timestep : 3122400, average reward : -72.93000030517578\n",
            "episode : 6, timestep : 3124800, average reward : -77.45999908447266\n",
            "episode : 6, timestep : 3127200, average reward : -64.55000305175781\n",
            "[3129344] Avg reward (last 50 episodes): -0.06633810698986053\n",
            "episode : 5, timestep : 3129600, average reward : -56.15999984741211\n",
            "episode : 7, timestep : 3132000, average reward : -99.12000274658203\n",
            "episode : 7, timestep : 3134400, average reward : -86.93000030517578\n",
            "episode : 7, timestep : 3136800, average reward : -73.38999938964844\n",
            "[3137536] Avg reward (last 50 episodes): -0.07617838680744171\n",
            "episode : 5, timestep : 3139200, average reward : -73.27999877929688\n",
            "episode : 6, timestep : 3141600, average reward : -63.40999984741211\n",
            "episode : 5, timestep : 3144000, average reward : -54.060001373291016\n",
            "[3145728] Avg reward (last 50 episodes): -0.08179137855768204\n",
            "episode : 7, timestep : 3146400, average reward : -71.69999694824219\n",
            "episode : 5, timestep : 3148800, average reward : -51.38999938964844\n",
            "episode : 7, timestep : 3151200, average reward : -86.6500015258789\n",
            "episode : 5, timestep : 3153600, average reward : -56.33000183105469\n",
            "[3153920] Avg reward (last 50 episodes): -0.06433823704719543\n",
            "episode : 6, timestep : 3156000, average reward : -64.45999908447266\n",
            "episode : 5, timestep : 3158400, average reward : -53.90999984741211\n",
            "episode : 5, timestep : 3160800, average reward : -65.29000091552734\n",
            "[3162112] Avg reward (last 50 episodes): -0.12699641287326813\n",
            "episode : 4, timestep : 3163200, average reward : -37.56999969482422\n",
            "episode : 5, timestep : 3165600, average reward : -56.619998931884766\n",
            "episode : 5, timestep : 3168000, average reward : -53.72999954223633\n",
            "[3170304] Avg reward (last 50 episodes): -0.09563793241977692\n",
            "episode : 7, timestep : 3170400, average reward : -71.12000274658203\n",
            "episode : 6, timestep : 3172800, average reward : -78.69999694824219\n",
            "episode : 4, timestep : 3175200, average reward : -43.060001373291016\n",
            "episode : 4, timestep : 3177600, average reward : -41.209999084472656\n",
            "[3178496] Avg reward (last 50 episodes): -0.06164174899458885\n",
            "episode : 8, timestep : 3180000, average reward : -80.80999755859375\n",
            "episode : 9, timestep : 3182400, average reward : -94.18000030517578\n",
            "episode : 10, timestep : 3184800, average reward : -95.47000122070312\n",
            "[3186688] Avg reward (last 50 episodes): -0.08983146399259567\n",
            "episode : 9, timestep : 3187200, average reward : -89.7699966430664\n",
            "episode : 7, timestep : 3189600, average reward : -81.5199966430664\n",
            "episode : 7, timestep : 3192000, average reward : -83.54000091552734\n",
            "episode : 5, timestep : 3194400, average reward : -54.58000183105469\n",
            "[3194880] Avg reward (last 50 episodes): -2.127595705129206\n",
            "episode : 14, timestep : 3196800, average reward : -105.29000091552734\n",
            "episode : 9, timestep : 3199200, average reward : -79.9800033569336\n",
            "episode : 11, timestep : 3201600, average reward : -102.5999984741211\n",
            "[3203072] Avg reward (last 50 episodes): -2.2947003236413\n",
            "episode : 12, timestep : 3204000, average reward : -96.0\n",
            "episode : 6, timestep : 3206400, average reward : -68.76000213623047\n",
            "setting action_std to  0.5916\n",
            "episode : 4, timestep : 3208800, average reward : -59.380001068115234\n",
            "episode : 8, timestep : 3211200, average reward : -80.94999694824219\n",
            "[3211264] Avg reward (last 50 episodes): -0.09043443948030472\n",
            "episode : 16, timestep : 3213600, average reward : -105.33999633789062\n",
            "episode : 10, timestep : 3216000, average reward : -94.9800033569336\n",
            "episode : 13, timestep : 3218400, average reward : -104.86000061035156\n",
            "[3219456] Avg reward (last 50 episodes): -0.044080909341573715\n",
            "episode : 8, timestep : 3220800, average reward : -93.12000274658203\n",
            "episode : 8, timestep : 3223200, average reward : -84.31999969482422\n",
            "episode : 4, timestep : 3225600, average reward : -42.22999954223633\n",
            "[3227648] Avg reward (last 50 episodes): -0.061074331402778625\n",
            "episode : 6, timestep : 3228000, average reward : -65.54000091552734\n",
            "episode : 6, timestep : 3230400, average reward : -65.44000244140625\n",
            "episode : 4, timestep : 3232800, average reward : -41.349998474121094\n",
            "episode : 4, timestep : 3235200, average reward : -43.400001525878906\n",
            "[3235840] Avg reward (last 50 episodes): -0.21097257733345032\n",
            "episode : 6, timestep : 3237600, average reward : -76.52999877929688\n",
            "episode : 5, timestep : 3240000, average reward : -52.5\n",
            "episode : 5, timestep : 3242400, average reward : -55.2599983215332\n",
            "[3244032] Avg reward (last 50 episodes): -0.052754808217287064\n",
            "episode : 5, timestep : 3244800, average reward : -70.5199966430664\n",
            "episode : 6, timestep : 3247200, average reward : -63.59000015258789\n",
            "episode : 5, timestep : 3249600, average reward : -52.459999084472656\n",
            "episode : 5, timestep : 3252000, average reward : -53.91999816894531\n",
            "[3252224] Avg reward (last 50 episodes): -0.06814589351415634\n",
            "episode : 7, timestep : 3254400, average reward : -81.58999633789062\n",
            "episode : 6, timestep : 3256800, average reward : -67.0\n",
            "episode : 7, timestep : 3259200, average reward : -82.47000122070312\n",
            "[3260416] Avg reward (last 50 episodes): -0.01998036913573742\n",
            "episode : 6, timestep : 3261600, average reward : -66.45999908447266\n",
            "episode : 5, timestep : 3264000, average reward : -54.279998779296875\n",
            "episode : 6, timestep : 3266400, average reward : -64.26000213623047\n",
            "[3268608] Avg reward (last 50 episodes): -0.0771370679140091\n",
            "episode : 8, timestep : 3268800, average reward : -85.80000305175781\n",
            "episode : 6, timestep : 3271200, average reward : -68.48999786376953\n",
            "episode : 6, timestep : 3273600, average reward : -79.25\n",
            "episode : 6, timestep : 3276000, average reward : -63.81999969482422\n",
            "[3276800] Avg reward (last 50 episodes): -0.08222655206918716\n",
            "episode : 5, timestep : 3278400, average reward : -54.630001068115234\n",
            "episode : 5, timestep : 3280800, average reward : -66.05000305175781\n",
            "episode : 6, timestep : 3283200, average reward : -66.33000183105469\n",
            "[3284992] Avg reward (last 50 episodes): -0.09153559058904648\n",
            "episode : 5, timestep : 3285600, average reward : -58.25\n",
            "episode : 4, timestep : 3288000, average reward : -46.970001220703125\n",
            "episode : 13, timestep : 3290400, average reward : -95.55000305175781\n",
            "episode : 11, timestep : 3292800, average reward : -97.87000274658203\n",
            "[3293184] Avg reward (last 50 episodes): -0.09547778964042664\n",
            "episode : 4, timestep : 3295200, average reward : -48.83000183105469\n",
            "episode : 5, timestep : 3297600, average reward : -56.15999984741211\n",
            "episode : 6, timestep : 3300000, average reward : -66.87000274658203\n",
            "[3301376] Avg reward (last 50 episodes): -0.0575367696583271\n",
            "episode : 6, timestep : 3302400, average reward : -71.52999877929688\n",
            "episode : 4, timestep : 3304800, average reward : -64.66999816894531\n",
            "episode : 5, timestep : 3307200, average reward : -61.869998931884766\n",
            "setting action_std to  0.5913\n",
            "[3309568] Avg reward (last 50 episodes): -0.09600584954023361\n",
            "episode : 4, timestep : 3309600, average reward : -50.16999816894531\n",
            "episode : 5, timestep : 3312000, average reward : -60.95000076293945\n",
            "episode : 4, timestep : 3314400, average reward : -52.09000015258789\n",
            "episode : 5, timestep : 3316800, average reward : -60.33000183105469\n",
            "[3317760] Avg reward (last 50 episodes): 0.04671236127614975\n",
            "episode : 4, timestep : 3319200, average reward : -52.84000015258789\n",
            "episode : 7, timestep : 3321600, average reward : -74.61000061035156\n",
            "episode : 5, timestep : 3324000, average reward : -59.959999084472656\n",
            "[3325952] Avg reward (last 50 episodes): -0.08363522589206696\n",
            "episode : 4, timestep : 3326400, average reward : -61.58000183105469\n",
            "episode : 5, timestep : 3328800, average reward : -62.90999984741211\n",
            "episode : 5, timestep : 3331200, average reward : -59.2599983215332\n",
            "episode : 4, timestep : 3333600, average reward : -50.349998474121094\n",
            "[3334144] Avg reward (last 50 episodes): -0.05721167474985123\n",
            "episode : 4, timestep : 3336000, average reward : -46.29999923706055\n",
            "episode : 5, timestep : 3338400, average reward : -54.540000915527344\n",
            "episode : 6, timestep : 3340800, average reward : -67.18000030517578\n",
            "[3342336] Avg reward (last 50 episodes): -0.07836950570344925\n",
            "episode : 5, timestep : 3343200, average reward : -60.18000030517578\n",
            "episode : 4, timestep : 3345600, average reward : -65.08000183105469\n",
            "episode : 6, timestep : 3348000, average reward : -72.61000061035156\n",
            "episode : 4, timestep : 3350400, average reward : -48.16999816894531\n",
            "[3350528] Avg reward (last 50 episodes): -0.07996872812509537\n",
            "episode : 4, timestep : 3352800, average reward : -46.95000076293945\n",
            "episode : 4, timestep : 3355200, average reward : -52.709999084472656\n",
            "episode : 4, timestep : 3357600, average reward : -46.47999954223633\n",
            "[3358720] Avg reward (last 50 episodes): -0.03301377594470978\n",
            "episode : 7, timestep : 3360000, average reward : -78.44999694824219\n",
            "episode : 6, timestep : 3362400, average reward : -68.44000244140625\n",
            "episode : 5, timestep : 3364800, average reward : -61.83000183105469\n",
            "[3366912] Avg reward (last 50 episodes): -0.09491821378469467\n",
            "episode : 5, timestep : 3367200, average reward : -75.7300033569336\n",
            "episode : 4, timestep : 3369600, average reward : -50.27000045776367\n",
            "episode : 4, timestep : 3372000, average reward : -51.68000030517578\n",
            "episode : 4, timestep : 3374400, average reward : -47.52000045776367\n",
            "[3375104] Avg reward (last 50 episodes): -0.11621979624032974\n",
            "episode : 7, timestep : 3376800, average reward : -76.41999816894531\n",
            "episode : 4, timestep : 3379200, average reward : -49.380001068115234\n",
            "episode : 5, timestep : 3381600, average reward : -61.5\n",
            "[3383296] Avg reward (last 50 episodes): -0.11193113029003143\n",
            "episode : 4, timestep : 3384000, average reward : -52.400001525878906\n",
            "episode : 5, timestep : 3386400, average reward : -61.349998474121094\n",
            "episode : 6, timestep : 3388800, average reward : -82.55000305175781\n",
            "episode : 7, timestep : 3391200, average reward : -74.45999908447266\n",
            "[3391488] Avg reward (last 50 episodes): -0.1770959347486496\n",
            "episode : 6, timestep : 3393600, average reward : -73.30000305175781\n",
            "episode : 6, timestep : 3396000, average reward : -72.22000122070312\n",
            "episode : 4, timestep : 3398400, average reward : -56.56999969482422\n",
            "[3399680] Avg reward (last 50 episodes): -0.08419785648584366\n",
            "episode : 4, timestep : 3400800, average reward : -52.290000915527344\n",
            "episode : 6, timestep : 3403200, average reward : -84.91999816894531\n",
            "episode : 4, timestep : 3405600, average reward : -57.880001068115234\n",
            "setting action_std to  0.591\n",
            "[3407872] Avg reward (last 50 episodes): -0.17703299224376678\n",
            "episode : 5, timestep : 3408000, average reward : -66.5999984741211\n",
            "episode : 5, timestep : 3410400, average reward : -64.62999725341797\n",
            "episode : 4, timestep : 3412800, average reward : -51.59000015258789\n",
            "episode : 6, timestep : 3415200, average reward : -81.16999816894531\n",
            "[3416064] Avg reward (last 50 episodes): -0.056305140256881714\n",
            "episode : 7, timestep : 3417600, average reward : -76.36000061035156\n",
            "episode : 7, timestep : 3420000, average reward : -91.9000015258789\n",
            "episode : 7, timestep : 3422400, average reward : -81.18000030517578\n",
            "[3424256] Avg reward (last 50 episodes): -0.13578368723392487\n",
            "episode : 10, timestep : 3424800, average reward : -93.54000091552734\n",
            "episode : 9, timestep : 3427200, average reward : -89.70999908447266\n",
            "episode : 12, timestep : 3429600, average reward : -99.41999816894531\n",
            "episode : 7, timestep : 3432000, average reward : -106.12999725341797\n",
            "[3432448] Avg reward (last 50 episodes): -0.17681856453418732\n",
            "episode : 7, timestep : 3434400, average reward : -87.2699966430664\n",
            "episode : 10, timestep : 3436800, average reward : -94.41999816894531\n",
            "episode : 9, timestep : 3439200, average reward : -95.06999969482422\n",
            "[3440640] Avg reward (last 50 episodes): -2.3105581758916376\n",
            "episode : 7, timestep : 3441600, average reward : -100.79000091552734\n",
            "episode : 8, timestep : 3444000, average reward : -80.30000305175781\n",
            "episode : 6, timestep : 3446400, average reward : -80.58000183105469\n",
            "episode : 11, timestep : 3448800, average reward : -92.58999633789062\n",
            "[3448832] Avg reward (last 50 episodes): -0.09819826483726501\n",
            "episode : 5, timestep : 3451200, average reward : -61.290000915527344\n",
            "episode : 6, timestep : 3453600, average reward : -71.22000122070312\n",
            "episode : 5, timestep : 3456000, average reward : -85.01000213623047\n",
            "[3457024] Avg reward (last 50 episodes): -0.15603460371494293\n",
            "episode : 5, timestep : 3458400, average reward : -64.5999984741211\n",
            "episode : 4, timestep : 3460800, average reward : -49.130001068115234\n",
            "episode : 4, timestep : 3463200, average reward : -47.0\n",
            "[3465216] Avg reward (last 50 episodes): -0.10490761697292328\n",
            "episode : 6, timestep : 3465600, average reward : -68.16000366210938\n",
            "episode : 4, timestep : 3468000, average reward : -47.189998626708984\n",
            "episode : 6, timestep : 3470400, average reward : -70.69000244140625\n",
            "episode : 6, timestep : 3472800, average reward : -70.63999938964844\n",
            "[3473408] Avg reward (last 50 episodes): -0.16524595022201538\n",
            "episode : 5, timestep : 3475200, average reward : -73.66999816894531\n",
            "episode : 5, timestep : 3477600, average reward : -65.52999877929688\n",
            "episode : 6, timestep : 3480000, average reward : -71.2699966430664\n",
            "[3481600] Avg reward (last 50 episodes): -0.1285199522972107\n",
            "episode : 6, timestep : 3482400, average reward : -72.62000274658203\n",
            "episode : 4, timestep : 3484800, average reward : -47.279998779296875\n",
            "episode : 6, timestep : 3487200, average reward : -69.86000061035156\n",
            "episode : 5, timestep : 3489600, average reward : -70.54000091552734\n",
            "[3489792] Avg reward (last 50 episodes): -0.021939177066087723\n",
            "episode : 5, timestep : 3492000, average reward : -62.130001068115234\n",
            "episode : 4, timestep : 3494400, average reward : -51.5\n",
            "episode : 7, timestep : 3496800, average reward : -75.22000122070312\n",
            "[3497984] Avg reward (last 50 episodes): -0.20352692902088165\n",
            "episode : 6, timestep : 3499200, average reward : -82.44000244140625\n",
            "episode : 4, timestep : 3501600, average reward : -50.02000045776367\n",
            "episode : 4, timestep : 3504000, average reward : -48.560001373291016\n",
            "[3506176] Avg reward (last 50 episodes): -0.037833184003829956\n",
            "episode : 6, timestep : 3506400, average reward : -69.69999694824219\n",
            "setting action_std to  0.5907\n",
            "episode : 5, timestep : 3508800, average reward : -60.52000045776367\n",
            "episode : 4, timestep : 3511200, average reward : -54.470001220703125\n",
            "episode : 6, timestep : 3513600, average reward : -71.9000015258789\n",
            "[3514368] Avg reward (last 50 episodes): -0.11695215106010437\n",
            "episode : 9, timestep : 3516000, average reward : -94.7699966430664\n",
            "episode : 8, timestep : 3518400, average reward : -82.0199966430664\n",
            "episode : 9, timestep : 3520800, average reward : -93.76000213623047\n",
            "[3522560] Avg reward (last 50 episodes): -2.222651238776743\n",
            "episode : 13, timestep : 3523200, average reward : -111.87000274658203\n",
            "episode : 9, timestep : 3525600, average reward : -88.29000091552734\n",
            "episode : 17, timestep : 3528000, average reward : -100.44999694824219\n",
            "episode : 10, timestep : 3530400, average reward : -99.18000030517578\n",
            "[3530752] Avg reward (last 50 episodes): -0.044835545122623444\n",
            "episode : 11, timestep : 3532800, average reward : -94.62999725341797\n",
            "episode : 13, timestep : 3535200, average reward : -95.72000122070312\n",
            "episode : 16, timestep : 3537600, average reward : -98.30999755859375\n",
            "[3538944] Avg reward (last 50 episodes): -0.0673879086971283\n",
            "episode : 10, timestep : 3540000, average reward : -90.73999786376953\n",
            "episode : 11, timestep : 3542400, average reward : -93.9000015258789\n",
            "episode : 12, timestep : 3544800, average reward : -94.26000213623047\n",
            "[3547136] Avg reward (last 50 episodes): -0.07554009556770325\n",
            "episode : 13, timestep : 3547200, average reward : -99.31999969482422\n",
            "episode : 6, timestep : 3549600, average reward : -67.27999877929688\n",
            "episode : 15, timestep : 3552000, average reward : -99.19000244140625\n",
            "episode : 9, timestep : 3554400, average reward : -92.18000030517578\n",
            "[3555328] Avg reward (last 50 episodes): -0.017620481550693512\n",
            "episode : 16, timestep : 3556800, average reward : -98.33999633789062\n",
            "episode : 11, timestep : 3559200, average reward : -99.5999984741211\n",
            "episode : 12, timestep : 3561600, average reward : -88.94999694824219\n",
            "[3563520] Avg reward (last 50 episodes): -0.060473665595054626\n",
            "episode : 15, timestep : 3564000, average reward : -102.0999984741211\n",
            "episode : 14, timestep : 3566400, average reward : -99.88999938964844\n",
            "episode : 17, timestep : 3568800, average reward : -103.87000274658203\n",
            "episode : 9, timestep : 3571200, average reward : -87.5\n",
            "[3571712] Avg reward (last 50 episodes): -0.25855812430381775\n",
            "episode : 7, timestep : 3573600, average reward : -83.0\n",
            "episode : 9, timestep : 3576000, average reward : -79.83000183105469\n",
            "episode : 12, timestep : 3578400, average reward : -92.76000213623047\n",
            "[3579904] Avg reward (last 50 episodes): -0.053130265325307846\n",
            "episode : 5, timestep : 3580800, average reward : -72.41999816894531\n",
            "episode : 13, timestep : 3583200, average reward : -95.23999786376953\n",
            "episode : 11, timestep : 3585600, average reward : -94.79000091552734\n",
            "episode : 7, timestep : 3588000, average reward : -81.44000244140625\n",
            "[3588096] Avg reward (last 50 episodes): -0.09112667292356491\n",
            "episode : 12, timestep : 3590400, average reward : -99.87000274658203\n",
            "episode : 14, timestep : 3592800, average reward : -93.05999755859375\n",
            "episode : 10, timestep : 3595200, average reward : -91.20999908447266\n",
            "[3596288] Avg reward (last 50 episodes): -2.095093991793692\n",
            "episode : 12, timestep : 3597600, average reward : -92.22000122070312\n",
            "episode : 15, timestep : 3600000, average reward : -104.31999969482422\n",
            "episode : 10, timestep : 3602400, average reward : -90.73999786376953\n",
            "[3604480] Avg reward (last 50 episodes): -0.16670538485050201\n",
            "episode : 14, timestep : 3604800, average reward : -104.75\n",
            "episode : 20, timestep : 3607200, average reward : -108.75\n",
            "setting action_std to  0.5904\n",
            "episode : 15, timestep : 3609600, average reward : -98.58999633789062\n",
            "episode : 7, timestep : 3612000, average reward : -72.37999725341797\n",
            "[3612672] Avg reward (last 50 episodes): -2.1795422684028747\n",
            "episode : 15, timestep : 3614400, average reward : -101.66999816894531\n",
            "episode : 11, timestep : 3616800, average reward : -91.94999694824219\n",
            "episode : 11, timestep : 3619200, average reward : -95.66999816894531\n",
            "[3620864] Avg reward (last 50 episodes): -0.10750731825828552\n",
            "episode : 13, timestep : 3621600, average reward : -95.62999725341797\n",
            "episode : 10, timestep : 3624000, average reward : -88.81999969482422\n",
            "episode : 7, timestep : 3626400, average reward : -80.87999725341797\n",
            "episode : 15, timestep : 3628800, average reward : -98.1500015258789\n",
            "[3629056] Avg reward (last 50 episodes): -0.06533820182085037\n",
            "episode : 9, timestep : 3631200, average reward : -87.80999755859375\n",
            "episode : 7, timestep : 3633600, average reward : -84.18000030517578\n",
            "episode : 8, timestep : 3636000, average reward : -80.0199966430664\n",
            "[3637248] Avg reward (last 50 episodes): -0.11631374061107635\n",
            "episode : 7, timestep : 3638400, average reward : -76.68000030517578\n",
            "episode : 7, timestep : 3640800, average reward : -84.6500015258789\n",
            "episode : 12, timestep : 3643200, average reward : -96.33999633789062\n",
            "[3645440] Avg reward (last 50 episodes): -0.13053101301193237\n",
            "episode : 8, timestep : 3645600, average reward : -89.12999725341797\n",
            "episode : 6, timestep : 3648000, average reward : -69.97000122070312\n",
            "episode : 11, timestep : 3650400, average reward : -91.58000183105469\n",
            "episode : 9, timestep : 3652800, average reward : -85.75\n",
            "[3653632] Avg reward (last 50 episodes): -0.17610278725624084\n",
            "episode : 10, timestep : 3655200, average reward : -101.37999725341797\n",
            "episode : 9, timestep : 3657600, average reward : -81.66999816894531\n",
            "episode : 13, timestep : 3660000, average reward : -94.04000091552734\n",
            "[3661824] Avg reward (last 50 episodes): -2.1996541607752444\n",
            "episode : 7, timestep : 3662400, average reward : -81.51000213623047\n",
            "episode : 5, timestep : 3664800, average reward : -59.290000915527344\n",
            "episode : 6, timestep : 3667200, average reward : -68.77999877929688\n",
            "episode : 5, timestep : 3669600, average reward : -61.65999984741211\n",
            "[3670016] Avg reward (last 50 episodes): -0.012968705967068672\n",
            "episode : 6, timestep : 3672000, average reward : -79.73999786376953\n",
            "episode : 6, timestep : 3674400, average reward : -64.83000183105469\n",
            "episode : 5, timestep : 3676800, average reward : -58.130001068115234\n",
            "[3678208] Avg reward (last 50 episodes): -0.09074898064136505\n",
            "episode : 5, timestep : 3679200, average reward : -57.290000915527344\n",
            "episode : 5, timestep : 3681600, average reward : -58.47999954223633\n",
            "episode : 4, timestep : 3684000, average reward : -49.470001220703125\n",
            "[3686400] Avg reward (last 50 episodes): -0.0646505057811737\n",
            "episode : 4, timestep : 3686400, average reward : -48.02000045776367\n",
            "episode : 5, timestep : 3688800, average reward : -62.900001525878906\n",
            "episode : 5, timestep : 3691200, average reward : -59.0\n",
            "episode : 5, timestep : 3693600, average reward : -61.5099983215332\n",
            "[3694592] Avg reward (last 50 episodes): -0.09678950160741806\n",
            "episode : 6, timestep : 3696000, average reward : -79.06999969482422\n",
            "episode : 4, timestep : 3698400, average reward : -44.70000076293945\n",
            "episode : 5, timestep : 3700800, average reward : -59.349998474121094\n",
            "[3702784] Avg reward (last 50 episodes): -0.0491023063659668\n",
            "episode : 6, timestep : 3703200, average reward : -68.33000183105469\n",
            "episode : 4, timestep : 3705600, average reward : -51.619998931884766\n",
            "episode : 4, timestep : 3708000, average reward : -50.15999984741211\n",
            "setting action_std to  0.5901\n",
            "episode : 4, timestep : 3710400, average reward : -63.529998779296875\n",
            "[3710976] Avg reward (last 50 episodes): -0.1261918544769287\n",
            "episode : 5, timestep : 3712800, average reward : -58.900001525878906\n",
            "episode : 4, timestep : 3715200, average reward : -43.2400016784668\n",
            "episode : 7, timestep : 3717600, average reward : -71.9800033569336\n",
            "[3719168] Avg reward (last 50 episodes): -0.1165674701333046\n",
            "episode : 5, timestep : 3720000, average reward : -54.470001220703125\n",
            "episode : 5, timestep : 3722400, average reward : -55.09000015258789\n",
            "episode : 4, timestep : 3724800, average reward : -60.439998626708984\n",
            "episode : 5, timestep : 3727200, average reward : -57.040000915527344\n",
            "[3727360] Avg reward (last 50 episodes): -0.0671585351228714\n",
            "episode : 4, timestep : 3729600, average reward : -43.93000030517578\n",
            "episode : 5, timestep : 3732000, average reward : -52.849998474121094\n",
            "episode : 4, timestep : 3734400, average reward : -40.29999923706055\n",
            "[3735552] Avg reward (last 50 episodes): -0.08401837944984436\n",
            "episode : 4, timestep : 3736800, average reward : -42.029998779296875\n",
            "episode : 5, timestep : 3739200, average reward : -57.09000015258789\n",
            "episode : 4, timestep : 3741600, average reward : -40.790000915527344\n",
            "[3743744] Avg reward (last 50 episodes): -0.08290395885705948\n",
            "episode : 4, timestep : 3744000, average reward : -47.20000076293945\n",
            "episode : 4, timestep : 3746400, average reward : -44.45000076293945\n",
            "episode : 4, timestep : 3748800, average reward : -40.79999923706055\n",
            "episode : 5, timestep : 3751200, average reward : -55.54999923706055\n",
            "[3751936] Avg reward (last 50 episodes): -0.06131412833929062\n",
            "episode : 4, timestep : 3753600, average reward : -42.4900016784668\n",
            "episode : 4, timestep : 3756000, average reward : -45.369998931884766\n",
            "episode : 5, timestep : 3758400, average reward : -62.36000061035156\n",
            "[3760128] Avg reward (last 50 episodes): -0.135165274143219\n",
            "episode : 5, timestep : 3760800, average reward : -69.02999877929688\n",
            "episode : 4, timestep : 3763200, average reward : -43.13999938964844\n",
            "episode : 5, timestep : 3765600, average reward : -49.06999969482422\n",
            "episode : 4, timestep : 3768000, average reward : -38.47999954223633\n",
            "[3768320] Avg reward (last 50 episodes): -0.1577727347612381\n",
            "episode : 4, timestep : 3770400, average reward : -34.0099983215332\n",
            "episode : 5, timestep : 3772800, average reward : -53.45000076293945\n",
            "episode : 4, timestep : 3775200, average reward : -37.029998779296875\n",
            "[3776512] Avg reward (last 50 episodes): -0.03634560853242874\n",
            "episode : 4, timestep : 3777600, average reward : -36.15999984741211\n",
            "episode : 4, timestep : 3780000, average reward : -37.27000045776367\n",
            "episode : 4, timestep : 3782400, average reward : -57.349998474121094\n",
            "[3784704] Avg reward (last 50 episodes): -0.014703861437737942\n",
            "episode : 4, timestep : 3784800, average reward : -56.06999969482422\n",
            "episode : 5, timestep : 3787200, average reward : -48.83000183105469\n",
            "episode : 4, timestep : 3789600, average reward : -31.65999984741211\n",
            "episode : 4, timestep : 3792000, average reward : -34.06999969482422\n",
            "[3792896] Avg reward (last 50 episodes): -0.06954643875360489\n",
            "episode : 5, timestep : 3794400, average reward : -52.27000045776367\n",
            "episode : 5, timestep : 3796800, average reward : -50.970001220703125\n",
            "episode : 6, timestep : 3799200, average reward : -59.77000045776367\n",
            "[3801088] Avg reward (last 50 episodes): -0.05874588340520859\n",
            "episode : 6, timestep : 3801600, average reward : -91.80000305175781\n",
            "episode : 6, timestep : 3804000, average reward : -93.13999938964844\n",
            "episode : 7, timestep : 3806400, average reward : -71.30999755859375\n",
            "episode : 6, timestep : 3808800, average reward : -116.68000030517578\n",
            "setting action_std to  0.5898\n",
            "[3809280] Avg reward (last 50 episodes): -0.07958909124135971\n",
            "episode : 4, timestep : 3811200, average reward : -35.720001220703125\n",
            "episode : 8, timestep : 3813600, average reward : -82.08999633789062\n",
            "episode : 5, timestep : 3816000, average reward : -47.439998626708984\n",
            "[3817472] Avg reward (last 50 episodes): -0.04579376056790352\n",
            "episode : 5, timestep : 3818400, average reward : -49.650001525878906\n",
            "episode : 4, timestep : 3820800, average reward : -55.970001220703125\n",
            "episode : 4, timestep : 3823200, average reward : -52.619998931884766\n",
            "episode : 6, timestep : 3825600, average reward : -56.83000183105469\n",
            "[3825664] Avg reward (last 50 episodes): -0.04723738133907318\n",
            "episode : 5, timestep : 3828000, average reward : -69.41000366210938\n",
            "episode : 9, timestep : 3830400, average reward : -77.68000030517578\n",
            "episode : 4, timestep : 3832800, average reward : -40.349998474121094\n",
            "[3833856] Avg reward (last 50 episodes): 0.04836191236972809\n",
            "episode : 4, timestep : 3835200, average reward : -60.790000915527344\n",
            "episode : 4, timestep : 3837600, average reward : -66.25\n",
            "episode : 5, timestep : 3840000, average reward : -52.72999954223633\n",
            "[3842048] Avg reward (last 50 episodes): -0.06361109018325806\n",
            "episode : 8, timestep : 3842400, average reward : -75.52999877929688\n",
            "episode : 6, timestep : 3844800, average reward : -79.37999725341797\n",
            "episode : 5, timestep : 3847200, average reward : -52.869998931884766\n",
            "episode : 4, timestep : 3849600, average reward : -57.22999954223633\n",
            "[3850240] Avg reward (last 50 episodes): -0.016934439539909363\n",
            "episode : 6, timestep : 3852000, average reward : -64.0999984741211\n",
            "episode : 6, timestep : 3854400, average reward : -64.80999755859375\n",
            "episode : 4, timestep : 3856800, average reward : -40.84000015258789\n",
            "[3858432] Avg reward (last 50 episodes): -0.056147485971450806\n",
            "episode : 4, timestep : 3859200, average reward : -41.130001068115234\n",
            "episode : 5, timestep : 3861600, average reward : -60.849998474121094\n",
            "episode : 4, timestep : 3864000, average reward : -46.689998626708984\n",
            "episode : 4, timestep : 3866400, average reward : -45.619998931884766\n",
            "[3866624] Avg reward (last 50 episodes): -0.06390061974525452\n",
            "episode : 4, timestep : 3868800, average reward : -42.720001220703125\n",
            "episode : 5, timestep : 3871200, average reward : -59.0\n",
            "episode : 4, timestep : 3873600, average reward : -44.939998626708984\n",
            "[3874816] Avg reward (last 50 episodes): -0.0345587395131588\n",
            "episode : 4, timestep : 3876000, average reward : -62.540000915527344\n",
            "episode : 5, timestep : 3878400, average reward : -58.59000015258789\n",
            "episode : 6, timestep : 3880800, average reward : -65.22000122070312\n",
            "[3883008] Avg reward (last 50 episodes): 0.0045221541076898575\n",
            "episode : 4, timestep : 3883200, average reward : -43.279998779296875\n",
            "episode : 6, timestep : 3885600, average reward : -76.95999908447266\n",
            "episode : 4, timestep : 3888000, average reward : -43.7599983215332\n",
            "episode : 10, timestep : 3890400, average reward : -83.16999816894531\n",
            "[3891200] Avg reward (last 50 episodes): -0.05354439094662666\n",
            "episode : 4, timestep : 3892800, average reward : -58.88999938964844\n",
            "episode : 7, timestep : 3895200, average reward : -64.20999908447266\n",
            "episode : 5, timestep : 3897600, average reward : -54.97999954223633\n",
            "[3899392] Avg reward (last 50 episodes): -0.055127087980508804\n",
            "episode : 4, timestep : 3900000, average reward : -40.209999084472656\n",
            "episode : 4, timestep : 3902400, average reward : -39.7400016784668\n",
            "episode : 6, timestep : 3904800, average reward : -71.01000213623047\n",
            "episode : 8, timestep : 3907200, average reward : -98.13999938964844\n",
            "[3907584] Avg reward (last 50 episodes): -0.028244569897651672\n",
            "setting action_std to  0.5895\n",
            "episode : 7, timestep : 3909600, average reward : -72.88999938964844\n",
            "episode : 6, timestep : 3912000, average reward : -68.68000030517578\n",
            "episode : 6, timestep : 3914400, average reward : -77.36000061035156\n",
            "[3915776] Avg reward (last 50 episodes): 0.019523531198501587\n",
            "episode : 9, timestep : 3916800, average reward : -80.37999725341797\n",
            "episode : 7, timestep : 3919200, average reward : -83.12999725341797\n",
            "episode : 7, timestep : 3921600, average reward : -74.37999725341797\n",
            "[3923968] Avg reward (last 50 episodes): -0.1135077103972435\n",
            "episode : 5, timestep : 3924000, average reward : -56.290000915527344\n",
            "episode : 6, timestep : 3926400, average reward : -71.55000305175781\n",
            "episode : 4, timestep : 3928800, average reward : -57.18000030517578\n",
            "episode : 4, timestep : 3931200, average reward : -62.22999954223633\n",
            "[3932160] Avg reward (last 50 episodes): -0.08223211020231247\n",
            "episode : 5, timestep : 3933600, average reward : -64.37999725341797\n",
            "episode : 5, timestep : 3936000, average reward : -60.540000915527344\n",
            "episode : 4, timestep : 3938400, average reward : -45.52000045776367\n",
            "[3940352] Avg reward (last 50 episodes): -0.05551081523299217\n",
            "episode : 5, timestep : 3940800, average reward : -57.22999954223633\n",
            "episode : 6, timestep : 3943200, average reward : -67.43000030517578\n",
            "episode : 6, timestep : 3945600, average reward : -70.72000122070312\n",
            "episode : 6, timestep : 3948000, average reward : -78.5199966430664\n",
            "[3948544] Avg reward (last 50 episodes): -0.1245010495185852\n",
            "episode : 12, timestep : 3950400, average reward : -102.91999816894531\n",
            "episode : 8, timestep : 3952800, average reward : -73.06999969482422\n",
            "episode : 6, timestep : 3955200, average reward : -78.55999755859375\n",
            "[3956736] Avg reward (last 50 episodes): -0.04690469801425934\n",
            "episode : 6, timestep : 3957600, average reward : -64.8499984741211\n",
            "episode : 8, timestep : 3960000, average reward : -96.12999725341797\n",
            "episode : 8, timestep : 3962400, average reward : -88.6500015258789\n",
            "episode : 8, timestep : 3964800, average reward : -89.76000213623047\n",
            "[3964928] Avg reward (last 50 episodes): -0.1302984207868576\n",
            "episode : 10, timestep : 3967200, average reward : -89.27999877929688\n",
            "episode : 7, timestep : 3969600, average reward : -71.19000244140625\n",
            "episode : 9, timestep : 3972000, average reward : -90.76000213623047\n",
            "[3973120] Avg reward (last 50 episodes): -0.053552400320768356\n",
            "episode : 5, timestep : 3974400, average reward : -73.23999786376953\n",
            "episode : 7, timestep : 3976800, average reward : -75.01000213623047\n",
            "episode : 4, timestep : 3979200, average reward : -49.939998626708984\n",
            "[3981312] Avg reward (last 50 episodes): 0.004383876454085112\n",
            "episode : 4, timestep : 3981600, average reward : -51.02000045776367\n",
            "episode : 6, timestep : 3984000, average reward : -69.18000030517578\n",
            "episode : 10, timestep : 3986400, average reward : -90.19999694824219\n",
            "episode : 5, timestep : 3988800, average reward : -58.77000045776367\n",
            "[3989504] Avg reward (last 50 episodes): -0.08208931237459183\n",
            "episode : 5, timestep : 3991200, average reward : -59.68000030517578\n",
            "episode : 4, timestep : 3993600, average reward : -48.31999969482422\n",
            "episode : 4, timestep : 3996000, average reward : -64.76000213623047\n",
            "[3997696] Avg reward (last 50 episodes): -0.11083833873271942\n",
            "episode : 6, timestep : 3998400, average reward : -67.95999908447266\n",
            "episode : 4, timestep : 4000800, average reward : -41.599998474121094\n",
            "episode : 4, timestep : 4003200, average reward : -40.72999954223633\n",
            "episode : 4, timestep : 4005600, average reward : -39.380001068115234\n",
            "[4005888] Avg reward (last 50 episodes): -2.0866597946360708\n",
            "episode : 5, timestep : 4008000, average reward : -55.099998474121094\n",
            "setting action_std to  0.5892\n",
            "episode : 4, timestep : 4010400, average reward : -40.02000045776367\n",
            "episode : 5, timestep : 4012800, average reward : -51.40999984741211\n",
            "[4014080] Avg reward (last 50 episodes): -0.055001482367515564\n",
            "episode : 4, timestep : 4015200, average reward : -42.439998626708984\n",
            "episode : 4, timestep : 4017600, average reward : -42.900001525878906\n",
            "episode : 4, timestep : 4020000, average reward : -38.310001373291016\n",
            "[4022272] Avg reward (last 50 episodes): -0.04685257747769356\n",
            "episode : 4, timestep : 4022400, average reward : -42.27000045776367\n",
            "episode : 5, timestep : 4024800, average reward : -61.06999969482422\n",
            "episode : 4, timestep : 4027200, average reward : -59.869998931884766\n",
            "episode : 4, timestep : 4029600, average reward : -39.040000915527344\n",
            "[4030464] Avg reward (last 50 episodes): -0.09913353621959686\n",
            "episode : 4, timestep : 4032000, average reward : -42.880001068115234\n",
            "episode : 4, timestep : 4034400, average reward : -39.119998931884766\n",
            "episode : 5, timestep : 4036800, average reward : -57.7599983215332\n",
            "[4038656] Avg reward (last 50 episodes): -0.07052812725305557\n",
            "episode : 4, timestep : 4039200, average reward : -45.040000915527344\n",
            "episode : 4, timestep : 4041600, average reward : -54.02000045776367\n",
            "episode : 4, timestep : 4044000, average reward : -67.16000366210938\n",
            "episode : 4, timestep : 4046400, average reward : -39.540000915527344\n",
            "[4046848] Avg reward (last 50 episodes): -0.0697304755449295\n",
            "episode : 4, timestep : 4048800, average reward : -39.86000061035156\n",
            "episode : 4, timestep : 4051200, average reward : -41.540000915527344\n",
            "episode : 5, timestep : 4053600, average reward : -51.95000076293945\n",
            "[4055040] Avg reward (last 50 episodes): -0.12380436062812805\n",
            "episode : 5, timestep : 4056000, average reward : -74.9800033569336\n",
            "episode : 5, timestep : 4058400, average reward : -53.5\n",
            "episode : 4, timestep : 4060800, average reward : -61.08000183105469\n",
            "episode : 5, timestep : 4063200, average reward : -69.55000305175781\n",
            "[4063232] Avg reward (last 50 episodes): 0.09359251707792282\n",
            "episode : 4, timestep : 4065600, average reward : -63.5\n",
            "episode : 6, timestep : 4068000, average reward : -67.7300033569336\n",
            "episode : 6, timestep : 4070400, average reward : -67.47000122070312\n",
            "[4071424] Avg reward (last 50 episodes): -0.0369390994310379\n",
            "episode : 6, timestep : 4072800, average reward : -62.45000076293945\n",
            "episode : 5, timestep : 4075200, average reward : -82.93000030517578\n",
            "episode : 4, timestep : 4077600, average reward : -38.93000030517578\n",
            "[4079616] Avg reward (last 50 episodes): -0.11761770397424698\n",
            "episode : 5, timestep : 4080000, average reward : -54.7400016784668\n",
            "episode : 4, timestep : 4082400, average reward : -68.66999816894531\n",
            "episode : 4, timestep : 4084800, average reward : -46.709999084472656\n",
            "episode : 4, timestep : 4087200, average reward : -44.75\n",
            "[4087808] Avg reward (last 50 episodes): -0.05122685059905052\n",
            "episode : 5, timestep : 4089600, average reward : -62.650001525878906\n",
            "episode : 7, timestep : 4092000, average reward : -85.80000305175781\n",
            "episode : 5, timestep : 4094400, average reward : -63.369998931884766\n",
            "[4096000] Avg reward (last 50 episodes): -0.07504461705684662\n",
            "episode : 4, timestep : 4096800, average reward : -45.0\n",
            "episode : 5, timestep : 4099200, average reward : -92.83999633789062\n",
            "episode : 8, timestep : 4101600, average reward : -80.66000366210938\n",
            "episode : 8, timestep : 4104000, average reward : -88.83000183105469\n",
            "[4104192] Avg reward (last 50 episodes): -0.1319923847913742\n",
            "episode : 6, timestep : 4106400, average reward : -108.08999633789062\n",
            "episode : 4, timestep : 4108800, average reward : -46.7599983215332\n",
            "setting action_std to  0.5889\n",
            "episode : 4, timestep : 4111200, average reward : -72.7300033569336\n",
            "[4112384] Avg reward (last 50 episodes): -0.1241205707192421\n",
            "episode : 6, timestep : 4113600, average reward : -70.51000213623047\n",
            "episode : 4, timestep : 4116000, average reward : -46.279998779296875\n",
            "episode : 4, timestep : 4118400, average reward : -45.20000076293945\n",
            "[4120576] Avg reward (last 50 episodes): -0.08725431561470032\n",
            "episode : 4, timestep : 4120800, average reward : -44.9900016784668\n",
            "episode : 5, timestep : 4123200, average reward : -59.45000076293945\n",
            "episode : 6, timestep : 4125600, average reward : -78.0199966430664\n",
            "episode : 4, timestep : 4128000, average reward : -47.83000183105469\n",
            "[4128768] Avg reward (last 50 episodes): -0.07017023116350174\n",
            "episode : 5, timestep : 4130400, average reward : -55.619998931884766\n",
            "episode : 5, timestep : 4132800, average reward : -56.2400016784668\n",
            "episode : 5, timestep : 4135200, average reward : -57.209999084472656\n",
            "[4136960] Avg reward (last 50 episodes): 0.029465805739164352\n",
            "episode : 4, timestep : 4137600, average reward : -39.939998626708984\n",
            "episode : 5, timestep : 4140000, average reward : -58.68000030517578\n",
            "episode : 4, timestep : 4142400, average reward : -43.08000183105469\n",
            "episode : 4, timestep : 4144800, average reward : -38.02000045776367\n",
            "[4145152] Avg reward (last 50 episodes): -0.07406646758317947\n",
            "episode : 4, timestep : 4147200, average reward : -56.18000030517578\n",
            "episode : 5, timestep : 4149600, average reward : -52.15999984741211\n",
            "episode : 4, timestep : 4152000, average reward : -40.93000030517578\n",
            "[4153344] Avg reward (last 50 episodes): -0.07733786106109619\n",
            "episode : 5, timestep : 4154400, average reward : -57.599998474121094\n",
            "episode : 7, timestep : 4156800, average reward : -71.87000274658203\n",
            "episode : 5, timestep : 4159200, average reward : -57.15999984741211\n",
            "[4161536] Avg reward (last 50 episodes): -0.13841834664344788\n",
            "episode : 4, timestep : 4161600, average reward : -39.93000030517578\n",
            "episode : 5, timestep : 4164000, average reward : -56.65999984741211\n",
            "episode : 4, timestep : 4166400, average reward : -61.63999938964844\n",
            "episode : 5, timestep : 4168800, average reward : -57.060001373291016\n",
            "[4169728] Avg reward (last 50 episodes): -0.07299543917179108\n",
            "episode : 4, timestep : 4171200, average reward : -48.66999816894531\n",
            "episode : 4, timestep : 4173600, average reward : -44.75\n",
            "episode : 4, timestep : 4176000, average reward : -46.33000183105469\n",
            "[4177920] Avg reward (last 50 episodes): -0.09112045913934708\n",
            "episode : 4, timestep : 4178400, average reward : -45.59000015258789\n",
            "episode : 5, timestep : 4180800, average reward : -57.11000061035156\n",
            "episode : 6, timestep : 4183200, average reward : -68.2699966430664\n",
            "episode : 4, timestep : 4185600, average reward : -46.150001525878906\n",
            "[4186112] Avg reward (last 50 episodes): -0.09756866097450256\n",
            "episode : 5, timestep : 4188000, average reward : -54.7400016784668\n",
            "episode : 4, timestep : 4190400, average reward : -44.2599983215332\n",
            "episode : 4, timestep : 4192800, average reward : -41.619998931884766\n",
            "[4194304] Avg reward (last 50 episodes): -0.007107630372047424\n",
            "episode : 6, timestep : 4195200, average reward : -63.369998931884766\n",
            "episode : 6, timestep : 4197600, average reward : -64.13999938964844\n",
            "episode : 4, timestep : 4200000, average reward : -40.099998474121094\n",
            "episode : 4, timestep : 4202400, average reward : -58.88999938964844\n",
            "[4202496] Avg reward (last 50 episodes): -0.0873175784945488\n",
            "episode : 4, timestep : 4204800, average reward : -42.83000183105469\n",
            "episode : 5, timestep : 4207200, average reward : -54.439998626708984\n",
            "episode : 6, timestep : 4209600, average reward : -64.08999633789062\n",
            "setting action_std to  0.5886\n",
            "[4210688] Avg reward (last 50 episodes): -0.020686320960521698\n",
            "episode : 4, timestep : 4212000, average reward : -41.310001373291016\n",
            "episode : 5, timestep : 4214400, average reward : -59.83000183105469\n",
            "episode : 5, timestep : 4216800, average reward : -51.560001373291016\n",
            "[4218880] Avg reward (last 50 episodes): -0.09639137238264084\n",
            "episode : 5, timestep : 4219200, average reward : -56.16999816894531\n",
            "episode : 4, timestep : 4221600, average reward : -43.90999984741211\n",
            "episode : 4, timestep : 4224000, average reward : -61.439998626708984\n",
            "episode : 5, timestep : 4226400, average reward : -56.22999954223633\n",
            "[4227072] Avg reward (last 50 episodes): -0.06357328593730927\n",
            "episode : 4, timestep : 4228800, average reward : -41.90999984741211\n",
            "episode : 5, timestep : 4231200, average reward : -56.83000183105469\n",
            "episode : 5, timestep : 4233600, average reward : -62.36000061035156\n",
            "[4235264] Avg reward (last 50 episodes): -0.16271953284740448\n",
            "episode : 5, timestep : 4236000, average reward : -59.5099983215332\n",
            "episode : 6, timestep : 4238400, average reward : -64.37000274658203\n",
            "episode : 4, timestep : 4240800, average reward : -55.77000045776367\n",
            "episode : 4, timestep : 4243200, average reward : -40.77000045776367\n",
            "[4243456] Avg reward (last 50 episodes): -0.06701201945543289\n",
            "episode : 8, timestep : 4245600, average reward : -78.94000244140625\n",
            "episode : 5, timestep : 4248000, average reward : -52.099998474121094\n",
            "episode : 7, timestep : 4250400, average reward : -83.83000183105469\n",
            "[4251648] Avg reward (last 50 episodes): -0.08132444322109222\n",
            "episode : 5, timestep : 4252800, average reward : -52.220001220703125\n",
            "episode : 6, timestep : 4255200, average reward : -76.77999877929688\n",
            "episode : 6, timestep : 4257600, average reward : -81.05000305175781\n",
            "[4259840] Avg reward (last 50 episodes): -0.04415576532483101\n",
            "episode : 4, timestep : 4260000, average reward : -34.97999954223633\n",
            "episode : 4, timestep : 4262400, average reward : -43.34000015258789\n",
            "episode : 4, timestep : 4264800, average reward : -45.9900016784668\n",
            "episode : 4, timestep : 4267200, average reward : -42.06999969482422\n",
            "[4268032] Avg reward (last 50 episodes): -0.05080338940024376\n",
            "episode : 5, timestep : 4269600, average reward : -52.150001525878906\n",
            "episode : 9, timestep : 4272000, average reward : -83.73999786376953\n",
            "episode : 4, timestep : 4274400, average reward : -40.709999084472656\n",
            "[4276224] Avg reward (last 50 episodes): -0.07925499230623245\n",
            "episode : 6, timestep : 4276800, average reward : -61.31999969482422\n",
            "episode : 7, timestep : 4279200, average reward : -66.06999969482422\n",
            "episode : 6, timestep : 4281600, average reward : -72.27999877929688\n",
            "episode : 6, timestep : 4284000, average reward : -59.619998931884766\n",
            "[4284416] Avg reward (last 50 episodes): -0.053863901644945145\n",
            "episode : 7, timestep : 4286400, average reward : -81.93000030517578\n",
            "episode : 6, timestep : 4288800, average reward : -75.69000244140625\n",
            "episode : 8, timestep : 4291200, average reward : -80.83999633789062\n",
            "[4292608] Avg reward (last 50 episodes): -0.06592272967100143\n",
            "episode : 6, timestep : 4293600, average reward : -58.84000015258789\n",
            "episode : 6, timestep : 4296000, average reward : -57.630001068115234\n",
            "episode : 4, timestep : 4298400, average reward : -53.56999969482422\n",
            "[4300800] Avg reward (last 50 episodes): -0.04907950386404991\n",
            "episode : 4, timestep : 4300800, average reward : -35.79999923706055\n",
            "episode : 5, timestep : 4303200, average reward : -50.029998779296875\n",
            "episode : 7, timestep : 4305600, average reward : -65.0\n",
            "episode : 4, timestep : 4308000, average reward : -37.209999084472656\n",
            "[4308992] Avg reward (last 50 episodes): -0.08937019109725952\n",
            "episode : 6, timestep : 4310400, average reward : -72.06999969482422\n",
            "setting action_std to  0.5883\n",
            "episode : 4, timestep : 4312800, average reward : -35.41999816894531\n",
            "episode : 4, timestep : 4315200, average reward : -36.290000915527344\n",
            "[4317184] Avg reward (last 50 episodes): -0.07149838656187057\n",
            "episode : 6, timestep : 4317600, average reward : -59.45000076293945\n",
            "episode : 7, timestep : 4320000, average reward : -68.87999725341797\n",
            "episode : 9, timestep : 4322400, average reward : -83.55000305175781\n",
            "episode : 8, timestep : 4324800, average reward : -80.5199966430664\n",
            "[4325376] Avg reward (last 50 episodes): -0.035056307911872864\n",
            "episode : 6, timestep : 4327200, average reward : -74.66000366210938\n",
            "episode : 4, timestep : 4329600, average reward : -38.61000061035156\n",
            "episode : 9, timestep : 4332000, average reward : -78.94000244140625\n",
            "[4333568] Avg reward (last 50 episodes): -0.07055483013391495\n",
            "episode : 4, timestep : 4334400, average reward : -39.650001525878906\n",
            "episode : 5, timestep : 4336800, average reward : -52.56999969482422\n",
            "episode : 4, timestep : 4339200, average reward : -36.0\n",
            "episode : 4, timestep : 4341600, average reward : -39.619998931884766\n",
            "[4341760] Avg reward (last 50 episodes): -0.05561254918575287\n",
            "episode : 4, timestep : 4344000, average reward : -37.11000061035156\n",
            "episode : 4, timestep : 4346400, average reward : -37.95000076293945\n",
            "episode : 4, timestep : 4348800, average reward : -57.119998931884766\n",
            "[4349952] Avg reward (last 50 episodes): -0.06290926784276962\n",
            "episode : 4, timestep : 4351200, average reward : -43.04999923706055\n",
            "episode : 5, timestep : 4353600, average reward : -52.7599983215332\n",
            "episode : 4, timestep : 4356000, average reward : -38.869998931884766\n",
            "[4358144] Avg reward (last 50 episodes): -0.009106595069169998\n",
            "episode : 4, timestep : 4358400, average reward : -39.16999816894531\n",
            "episode : 4, timestep : 4360800, average reward : -45.63999938964844\n",
            "episode : 5, timestep : 4363200, average reward : -60.689998626708984\n",
            "episode : 4, timestep : 4365600, average reward : -46.540000915527344\n",
            "[4366336] Avg reward (last 50 episodes): -0.06639833003282547\n",
            "episode : 6, timestep : 4368000, average reward : -65.36000061035156\n",
            "episode : 5, timestep : 4370400, average reward : -58.689998626708984\n",
            "episode : 4, timestep : 4372800, average reward : -47.16999816894531\n",
            "[4374528] Avg reward (last 50 episodes): -0.04850970208644867\n",
            "episode : 4, timestep : 4375200, average reward : -45.45000076293945\n",
            "episode : 4, timestep : 4377600, average reward : -46.63999938964844\n",
            "episode : 5, timestep : 4380000, average reward : -71.66999816894531\n",
            "episode : 6, timestep : 4382400, average reward : -70.66999816894531\n",
            "[4382720] Avg reward (last 50 episodes): -0.061191365122795105\n",
            "episode : 5, timestep : 4384800, average reward : -58.83000183105469\n",
            "episode : 5, timestep : 4387200, average reward : -60.029998779296875\n",
            "episode : 5, timestep : 4389600, average reward : -57.93000030517578\n",
            "[4390912] Avg reward (last 50 episodes): 0.003681018017232418\n",
            "episode : 4, timestep : 4392000, average reward : -63.63999938964844\n",
            "episode : 6, timestep : 4394400, average reward : -69.70999908447266\n",
            "episode : 4, timestep : 4396800, average reward : -46.099998474121094\n",
            "[4399104] Avg reward (last 50 episodes): -0.08291499316692352\n",
            "episode : 4, timestep : 4399200, average reward : -49.369998931884766\n",
            "episode : 5, timestep : 4401600, average reward : -58.79999923706055\n",
            "episode : 5, timestep : 4404000, average reward : -56.779998779296875\n",
            "episode : 4, timestep : 4406400, average reward : -48.619998931884766\n",
            "[4407296] Avg reward (last 50 episodes): -0.12363007664680481\n",
            "episode : 4, timestep : 4408800, average reward : -51.939998626708984\n",
            "setting action_std to  0.588\n",
            "episode : 4, timestep : 4411200, average reward : -48.84000015258789\n",
            "episode : 4, timestep : 4413600, average reward : -48.810001373291016\n",
            "[4415488] Avg reward (last 50 episodes): -0.06546569615602493\n",
            "episode : 5, timestep : 4416000, average reward : -63.970001220703125\n",
            "episode : 4, timestep : 4418400, average reward : -44.81999969482422\n",
            "episode : 5, timestep : 4420800, average reward : -58.0099983215332\n",
            "episode : 5, timestep : 4423200, average reward : -71.94999694824219\n",
            "[4423680] Avg reward (last 50 episodes): -0.057533759623765945\n",
            "episode : 5, timestep : 4425600, average reward : -63.0099983215332\n",
            "episode : 4, timestep : 4428000, average reward : -46.08000183105469\n",
            "episode : 4, timestep : 4430400, average reward : -54.310001373291016\n",
            "[4431872] Avg reward (last 50 episodes): -0.12024730443954468\n",
            "episode : 7, timestep : 4432800, average reward : -74.38999938964844\n",
            "episode : 6, timestep : 4435200, average reward : -78.02999877929688\n",
            "episode : 4, timestep : 4437600, average reward : -43.790000915527344\n",
            "episode : 6, timestep : 4440000, average reward : -86.97000122070312\n",
            "[4440064] Avg reward (last 50 episodes): -0.06847373396158218\n",
            "episode : 7, timestep : 4442400, average reward : -72.62999725341797\n",
            "episode : 5, timestep : 4444800, average reward : -72.75\n",
            "episode : 5, timestep : 4447200, average reward : -60.189998626708984\n",
            "[4448256] Avg reward (last 50 episodes): -0.0635397881269455\n",
            "episode : 5, timestep : 4449600, average reward : -60.08000183105469\n",
            "episode : 4, timestep : 4452000, average reward : -42.5099983215332\n",
            "episode : 4, timestep : 4454400, average reward : -49.52000045776367\n",
            "[4456448] Avg reward (last 50 episodes): -0.19055965542793274\n",
            "episode : 4, timestep : 4456800, average reward : -47.4900016784668\n",
            "episode : 5, timestep : 4459200, average reward : -54.4900016784668\n",
            "episode : 6, timestep : 4461600, average reward : -66.05999755859375\n",
            "episode : 6, timestep : 4464000, average reward : -63.56999969482422\n",
            "[4464640] Avg reward (last 50 episodes): -0.05393755063414574\n",
            "episode : 4, timestep : 4466400, average reward : -58.41999816894531\n",
            "episode : 5, timestep : 4468800, average reward : -61.22999954223633\n",
            "episode : 5, timestep : 4471200, average reward : -55.97999954223633\n",
            "[4472832] Avg reward (last 50 episodes): -0.20256061851978302\n",
            "episode : 8, timestep : 4473600, average reward : -77.52999877929688\n",
            "episode : 7, timestep : 4476000, average reward : -86.12999725341797\n",
            "episode : 4, timestep : 4478400, average reward : -43.529998779296875\n",
            "episode : 5, timestep : 4480800, average reward : -56.33000183105469\n",
            "[4481024] Avg reward (last 50 episodes): -0.11978144943714142\n",
            "episode : 4, timestep : 4483200, average reward : -35.650001525878906\n",
            "episode : 4, timestep : 4485600, average reward : -55.959999084472656\n",
            "episode : 4, timestep : 4488000, average reward : -39.099998474121094\n",
            "[4489216] Avg reward (last 50 episodes): 0.020336439833045006\n",
            "episode : 7, timestep : 4490400, average reward : -83.08000183105469\n",
            "episode : 5, timestep : 4492800, average reward : -52.33000183105469\n",
            "episode : 4, timestep : 4495200, average reward : -52.2599983215332\n",
            "[4497408] Avg reward (last 50 episodes): -0.08544062823057175\n",
            "episode : 4, timestep : 4497600, average reward : -35.84000015258789\n",
            "episode : 5, timestep : 4500000, average reward : -50.689998626708984\n",
            "episode : 6, timestep : 4502400, average reward : -62.099998474121094\n",
            "episode : 5, timestep : 4504800, average reward : -54.20000076293945\n",
            "[4505600] Avg reward (last 50 episodes): -0.06534774601459503\n",
            "episode : 5, timestep : 4507200, average reward : -55.09000015258789\n",
            "episode : 6, timestep : 4509600, average reward : -64.55000305175781\n",
            "setting action_std to  0.5877\n",
            "episode : 5, timestep : 4512000, average reward : -83.94000244140625\n",
            "[4513792] Avg reward (last 50 episodes): -0.0741899162530899\n",
            "episode : 5, timestep : 4514400, average reward : -53.59000015258789\n",
            "episode : 4, timestep : 4516800, average reward : -38.18000030517578\n",
            "episode : 5, timestep : 4519200, average reward : -55.63999938964844\n",
            "episode : 5, timestep : 4521600, average reward : -54.93000030517578\n",
            "[4521984] Avg reward (last 50 episodes): -0.22291703522205353\n",
            "episode : 5, timestep : 4524000, average reward : -54.43000030517578\n",
            "episode : 5, timestep : 4526400, average reward : -53.09000015258789\n",
            "episode : 5, timestep : 4528800, average reward : -55.400001525878906\n",
            "[4530176] Avg reward (last 50 episodes): -0.08141431212425232\n",
            "episode : 4, timestep : 4531200, average reward : -40.540000915527344\n",
            "episode : 4, timestep : 4533600, average reward : -34.86000061035156\n",
            "episode : 4, timestep : 4536000, average reward : -57.65999984741211\n",
            "[4538368] Avg reward (last 50 episodes): -0.04532351344823837\n",
            "episode : 6, timestep : 4538400, average reward : -66.04000091552734\n",
            "episode : 4, timestep : 4540800, average reward : -40.529998779296875\n",
            "episode : 5, timestep : 4543200, average reward : -85.48999786376953\n",
            "episode : 5, timestep : 4545600, average reward : -63.060001373291016\n",
            "[4546560] Avg reward (last 50 episodes): -0.1390039026737213\n",
            "episode : 4, timestep : 4548000, average reward : -39.25\n",
            "episode : 4, timestep : 4550400, average reward : -43.279998779296875\n",
            "episode : 6, timestep : 4552800, average reward : -64.55999755859375\n",
            "[4554752] Avg reward (last 50 episodes): -0.10311057418584824\n",
            "episode : 5, timestep : 4555200, average reward : -55.790000915527344\n",
            "episode : 5, timestep : 4557600, average reward : -57.869998931884766\n",
            "episode : 4, timestep : 4560000, average reward : -57.65999984741211\n",
            "episode : 4, timestep : 4562400, average reward : -39.27000045776367\n",
            "[4562944] Avg reward (last 50 episodes): -0.08179508149623871\n",
            "episode : 4, timestep : 4564800, average reward : -45.2599983215332\n",
            "episode : 4, timestep : 4567200, average reward : -41.58000183105469\n",
            "episode : 6, timestep : 4569600, average reward : -66.61000061035156\n",
            "[4571136] Avg reward (last 50 episodes): -0.050752997398376465\n",
            "episode : 7, timestep : 4572000, average reward : -72.12000274658203\n",
            "episode : 6, timestep : 4574400, average reward : -65.37000274658203\n",
            "episode : 5, timestep : 4576800, average reward : -71.44000244140625\n",
            "episode : 5, timestep : 4579200, average reward : -55.189998626708984\n",
            "[4579328] Avg reward (last 50 episodes): -0.07479453086853027\n",
            "episode : 6, timestep : 4581600, average reward : -65.48999786376953\n",
            "episode : 6, timestep : 4584000, average reward : -64.86000061035156\n",
            "episode : 4, timestep : 4586400, average reward : -42.810001373291016\n",
            "[4587520] Avg reward (last 50 episodes): -0.02463393658399582\n",
            "episode : 4, timestep : 4588800, average reward : -40.349998474121094\n",
            "episode : 6, timestep : 4591200, average reward : -76.37000274658203\n",
            "episode : 6, timestep : 4593600, average reward : -63.130001068115234\n",
            "[4595712] Avg reward (last 50 episodes): -0.05292968824505806\n",
            "episode : 7, timestep : 4596000, average reward : -69.30000305175781\n",
            "episode : 5, timestep : 4598400, average reward : -84.33999633789062\n",
            "episode : 5, timestep : 4600800, average reward : -76.56999969482422\n",
            "episode : 7, timestep : 4603200, average reward : -67.0999984741211\n",
            "[4603904] Avg reward (last 50 episodes): -0.03908403217792511\n",
            "episode : 7, timestep : 4605600, average reward : -83.1500015258789\n",
            "episode : 11, timestep : 4608000, average reward : -89.62000274658203\n",
            "episode : 5, timestep : 4610400, average reward : -81.05999755859375\n",
            "setting action_std to  0.5874\n",
            "[4612096] Avg reward (last 50 episodes): -0.15429958701133728\n",
            "episode : 6, timestep : 4612800, average reward : -71.06999969482422\n",
            "episode : 9, timestep : 4615200, average reward : -107.44999694824219\n",
            "episode : 5, timestep : 4617600, average reward : -82.31999969482422\n",
            "episode : 10, timestep : 4620000, average reward : -108.87999725341797\n",
            "[4620288] Avg reward (last 50 episodes): -0.04868408292531967\n",
            "episode : 8, timestep : 4622400, average reward : -85.36000061035156\n",
            "episode : 7, timestep : 4624800, average reward : -95.41999816894531\n",
            "episode : 6, timestep : 4627200, average reward : -105.18000030517578\n",
            "[4628480] Avg reward (last 50 episodes): -0.14191238582134247\n",
            "episode : 9, timestep : 4629600, average reward : -120.83000183105469\n",
            "episode : 7, timestep : 4632000, average reward : -87.75\n",
            "episode : 11, timestep : 4634400, average reward : -99.0999984741211\n",
            "[4636672] Avg reward (last 50 episodes): -0.06666596978902817\n",
            "episode : 6, timestep : 4636800, average reward : -82.0\n",
            "episode : 6, timestep : 4639200, average reward : -75.37000274658203\n",
            "episode : 6, timestep : 4641600, average reward : -88.12999725341797\n",
            "episode : 8, timestep : 4644000, average reward : -81.37999725341797\n",
            "[4644864] Avg reward (last 50 episodes): -0.07511024177074432\n",
            "episode : 9, timestep : 4646400, average reward : -91.08000183105469\n",
            "episode : 8, timestep : 4648800, average reward : -107.2300033569336\n",
            "episode : 13, timestep : 4651200, average reward : -99.12000274658203\n",
            "[4653056] Avg reward (last 50 episodes): -0.09269427508115768\n",
            "episode : 8, timestep : 4653600, average reward : -106.37000274658203\n",
            "episode : 7, timestep : 4656000, average reward : -88.55000305175781\n",
            "episode : 11, timestep : 4658400, average reward : -100.7699966430664\n",
            "episode : 20, timestep : 4660800, average reward : -111.33999633789062\n",
            "[4661248] Avg reward (last 50 episodes): -0.09551385045051575\n",
            "episode : 15, timestep : 4663200, average reward : -101.33999633789062\n",
            "episode : 23, timestep : 4665600, average reward : -109.72000122070312\n",
            "episode : 13, timestep : 4668000, average reward : -104.37999725341797\n",
            "[4669440] Avg reward (last 50 episodes): -0.07352162152528763\n",
            "episode : 14, timestep : 4670400, average reward : -101.94000244140625\n",
            "episode : 15, timestep : 4672800, average reward : -104.48999786376953\n",
            "episode : 17, timestep : 4675200, average reward : -109.44999694824219\n",
            "episode : 16, timestep : 4677600, average reward : -107.97000122070312\n",
            "[4677632] Avg reward (last 50 episodes): -2.292483083419502\n",
            "episode : 13, timestep : 4680000, average reward : -109.97000122070312\n",
            "episode : 12, timestep : 4682400, average reward : -98.05000305175781\n",
            "episode : 12, timestep : 4684800, average reward : -105.94999694824219\n",
            "[4685824] Avg reward (last 50 episodes): -0.08768047392368317\n",
            "episode : 9, timestep : 4687200, average reward : -91.87000274658203\n",
            "episode : 13, timestep : 4689600, average reward : -100.31999969482422\n",
            "episode : 13, timestep : 4692000, average reward : -108.41000366210938\n",
            "[4694016] Avg reward (last 50 episodes): -2.296017220392823\n",
            "episode : 15, timestep : 4694400, average reward : -103.19999694824219\n",
            "episode : 9, timestep : 4696800, average reward : -100.2300033569336\n",
            "episode : 17, timestep : 4699200, average reward : -114.69999694824219\n",
            "episode : 10, timestep : 4701600, average reward : -93.91000366210938\n",
            "[4702208] Avg reward (last 50 episodes): -0.1940954178571701\n",
            "episode : 5, timestep : 4704000, average reward : -82.19000244140625\n",
            "episode : 10, timestep : 4706400, average reward : -102.0999984741211\n",
            "episode : 10, timestep : 4708800, average reward : -93.86000061035156\n",
            "[4710400] Avg reward (last 50 episodes): -0.09386521577835083\n",
            "episode : 11, timestep : 4711200, average reward : -109.88999938964844\n",
            "setting action_std to  0.5871\n",
            "episode : 8, timestep : 4713600, average reward : -102.4000015258789\n",
            "episode : 10, timestep : 4716000, average reward : -98.68000030517578\n",
            "episode : 10, timestep : 4718400, average reward : -101.45999908447266\n",
            "[4718592] Avg reward (last 50 episodes): -0.11174596101045609\n",
            "episode : 5, timestep : 4720800, average reward : -73.4000015258789\n",
            "episode : 15, timestep : 4723200, average reward : -108.27999877929688\n",
            "episode : 13, timestep : 4725600, average reward : -107.5199966430664\n",
            "[4726784] Avg reward (last 50 episodes): -0.08411013334989548\n",
            "episode : 8, timestep : 4728000, average reward : -98.91000366210938\n",
            "episode : 15, timestep : 4730400, average reward : -110.55000305175781\n",
            "episode : 12, timestep : 4732800, average reward : -106.80000305175781\n",
            "[4734976] Avg reward (last 50 episodes): -0.09386083483695984\n",
            "episode : 7, timestep : 4735200, average reward : -99.66999816894531\n",
            "episode : 8, timestep : 4737600, average reward : -112.01000213623047\n",
            "episode : 10, timestep : 4740000, average reward : -98.12000274658203\n",
            "episode : 10, timestep : 4742400, average reward : -106.88999938964844\n",
            "[4743168] Avg reward (last 50 episodes): -0.08063309639692307\n",
            "episode : 13, timestep : 4744800, average reward : -112.91000366210938\n",
            "episode : 12, timestep : 4747200, average reward : -113.87000274658203\n",
            "episode : 14, timestep : 4749600, average reward : -110.19999694824219\n",
            "[4751360] Avg reward (last 50 episodes): -0.11101953685283661\n",
            "episode : 10, timestep : 4752000, average reward : -99.26000213623047\n",
            "episode : 18, timestep : 4754400, average reward : -111.80000305175781\n",
            "episode : 11, timestep : 4756800, average reward : -107.3499984741211\n",
            "episode : 13, timestep : 4759200, average reward : -102.30000305175781\n",
            "[4759552] Avg reward (last 50 episodes): -0.10841693729162216\n",
            "episode : 10, timestep : 4761600, average reward : -111.06999969482422\n",
            "episode : 11, timestep : 4764000, average reward : -103.44000244140625\n",
            "episode : 5, timestep : 4766400, average reward : -95.98999786376953\n",
            "[4767744] Avg reward (last 50 episodes): -0.08917684853076935\n",
            "episode : 16, timestep : 4768800, average reward : -105.16000366210938\n",
            "episode : 13, timestep : 4771200, average reward : -113.33000183105469\n",
            "episode : 7, timestep : 4773600, average reward : -122.25\n",
            "[4775936] Avg reward (last 50 episodes): -0.06398482620716095\n",
            "episode : 8, timestep : 4776000, average reward : -115.2300033569336\n",
            "episode : 11, timestep : 4778400, average reward : -121.54000091552734\n",
            "episode : 12, timestep : 4780800, average reward : -121.63999938964844\n",
            "episode : 7, timestep : 4783200, average reward : -114.93000030517578\n",
            "[4784128] Avg reward (last 50 episodes): -2.145678501278162\n",
            "episode : 10, timestep : 4785600, average reward : -124.9800033569336\n",
            "episode : 6, timestep : 4788000, average reward : -100.5\n",
            "episode : 14, timestep : 4790400, average reward : -119.43000030517578\n",
            "[4792320] Avg reward (last 50 episodes): -0.15050362050533295\n",
            "episode : 11, timestep : 4792800, average reward : -107.97000122070312\n",
            "episode : 9, timestep : 4795200, average reward : -131.33999633789062\n",
            "episode : 7, timestep : 4797600, average reward : -125.94999694824219\n",
            "episode : 8, timestep : 4800000, average reward : -144.11000061035156\n",
            "[4800512] Avg reward (last 50 episodes): -0.0884118527173996\n",
            "episode : 4, timestep : 4802400, average reward : -136.0500030517578\n",
            "episode : 6, timestep : 4804800, average reward : -121.69000244140625\n",
            "episode : 7, timestep : 4807200, average reward : -129.60000610351562\n",
            "[4808704] Avg reward (last 50 episodes): -0.093356654047966\n",
            "episode : 11, timestep : 4809600, average reward : -120.05999755859375\n",
            "episode : 10, timestep : 4812000, average reward : -126.4800033569336\n",
            "setting action_std to  0.5868\n",
            "episode : 6, timestep : 4814400, average reward : -129.22000122070312\n",
            "episode : 5, timestep : 4816800, average reward : -96.69999694824219\n",
            "[4816896] Avg reward (last 50 episodes): -0.11483679711818695\n",
            "episode : 12, timestep : 4819200, average reward : -128.67999267578125\n",
            "episode : 6, timestep : 4821600, average reward : -151.22999572753906\n",
            "episode : 7, timestep : 4824000, average reward : -130.5\n",
            "[4825088] Avg reward (last 50 episodes): -0.15976880490779877\n",
            "episode : 10, timestep : 4826400, average reward : -134.55999755859375\n",
            "episode : 9, timestep : 4828800, average reward : -115.95999908447266\n",
            "episode : 7, timestep : 4831200, average reward : -142.38999938964844\n",
            "[4833280] Avg reward (last 50 episodes): -2.3955349949747324\n",
            "episode : 14, timestep : 4833600, average reward : -128.1999969482422\n",
            "episode : 8, timestep : 4836000, average reward : -127.75\n",
            "episode : 8, timestep : 4838400, average reward : -140.27000427246094\n",
            "episode : 5, timestep : 4840800, average reward : -131.72999572753906\n",
            "[4841472] Avg reward (last 50 episodes): -0.11757262051105499\n",
            "episode : 9, timestep : 4843200, average reward : -130.32000732421875\n",
            "episode : 7, timestep : 4845600, average reward : -124.62000274658203\n",
            "episode : 8, timestep : 4848000, average reward : -146.17999267578125\n",
            "[4849664] Avg reward (last 50 episodes): -0.07864806056022644\n",
            "episode : 7, timestep : 4850400, average reward : -114.37999725341797\n",
            "episode : 10, timestep : 4852800, average reward : -113.02999877929688\n",
            "episode : 9, timestep : 4855200, average reward : -123.73999786376953\n",
            "episode : 10, timestep : 4857600, average reward : -115.29000091552734\n",
            "[4857856] Avg reward (last 50 episodes): -0.14952030777931213\n",
            "episode : 10, timestep : 4860000, average reward : -110.0\n",
            "episode : 21, timestep : 4862400, average reward : -112.19000244140625\n",
            "episode : 9, timestep : 4864800, average reward : -97.6500015258789\n",
            "[4866048] Avg reward (last 50 episodes): -2.086329905204475\n",
            "episode : 16, timestep : 4867200, average reward : -111.88999938964844\n",
            "episode : 14, timestep : 4869600, average reward : -111.44999694824219\n",
            "episode : 15, timestep : 4872000, average reward : -110.1500015258789\n",
            "[4874240] Avg reward (last 50 episodes): -0.09741918742656708\n",
            "episode : 21, timestep : 4874400, average reward : -111.33999633789062\n",
            "episode : 21, timestep : 4876800, average reward : -114.05000305175781\n",
            "episode : 10, timestep : 4879200, average reward : -103.37000274658203\n",
            "episode : 9, timestep : 4881600, average reward : -96.4000015258789\n",
            "[4882432] Avg reward (last 50 episodes): -0.1204010546207428\n",
            "episode : 12, timestep : 4884000, average reward : -104.06999969482422\n",
            "episode : 9, timestep : 4886400, average reward : -102.33999633789062\n",
            "episode : 18, timestep : 4888800, average reward : -115.18000030517578\n",
            "[4890624] Avg reward (last 50 episodes): -0.09789161384105682\n",
            "episode : 16, timestep : 4891200, average reward : -106.29000091552734\n",
            "episode : 9, timestep : 4893600, average reward : -106.6500015258789\n",
            "episode : 13, timestep : 4896000, average reward : -106.87999725341797\n",
            "episode : 10, timestep : 4898400, average reward : -99.5\n",
            "[4898816] Avg reward (last 50 episodes): -0.18086880445480347\n",
            "episode : 16, timestep : 4900800, average reward : -111.80999755859375\n",
            "episode : 9, timestep : 4903200, average reward : -101.7699966430664\n",
            "episode : 11, timestep : 4905600, average reward : -102.58000183105469\n",
            "[4907008] Avg reward (last 50 episodes): -2.332406002879143\n",
            "episode : 12, timestep : 4908000, average reward : -111.73999786376953\n",
            "episode : 12, timestep : 4910400, average reward : -99.44000244140625\n",
            "setting action_std to  0.5865\n",
            "episode : 18, timestep : 4912800, average reward : -111.4000015258789\n",
            "[4915200] Avg reward (last 50 episodes): -0.08340280503034592\n",
            "episode : 23, timestep : 4915200, average reward : -113.58999633789062\n",
            "episode : 10, timestep : 4917600, average reward : -97.36000061035156\n",
            "episode : 15, timestep : 4920000, average reward : -112.5999984741211\n",
            "episode : 11, timestep : 4922400, average reward : -106.45999908447266\n",
            "[4923392] Avg reward (last 50 episodes): -0.1765473335981369\n",
            "episode : 20, timestep : 4924800, average reward : -114.91000366210938\n",
            "episode : 10, timestep : 4927200, average reward : -92.62999725341797\n",
            "episode : 10, timestep : 4929600, average reward : -98.19999694824219\n",
            "[4931584] Avg reward (last 50 episodes): -2.2036114358901977\n",
            "episode : 8, timestep : 4932000, average reward : -105.44999694824219\n",
            "episode : 22, timestep : 4934400, average reward : -111.58000183105469\n",
            "episode : 21, timestep : 4936800, average reward : -115.6500015258789\n",
            "episode : 16, timestep : 4939200, average reward : -108.55000305175781\n",
            "[4939776] Avg reward (last 50 episodes): -0.14958858489990234\n",
            "episode : 25, timestep : 4941600, average reward : -118.55999755859375\n",
            "episode : 20, timestep : 4944000, average reward : -117.18000030517578\n",
            "episode : 24, timestep : 4946400, average reward : -119.5199966430664\n",
            "[4947968] Avg reward (last 50 episodes): -2.310277312733233\n",
            "episode : 23, timestep : 4948800, average reward : -120.55000305175781\n",
            "episode : 26, timestep : 4951200, average reward : -118.55999755859375\n",
            "episode : 28, timestep : 4953600, average reward : -118.88999938964844\n",
            "episode : 23, timestep : 4956000, average reward : -121.19000244140625\n",
            "[4956160] Avg reward (last 50 episodes): -2.1703221922367812\n",
            "episode : 28, timestep : 4958400, average reward : -118.51000213623047\n",
            "episode : 21, timestep : 4960800, average reward : -120.81999969482422\n",
            "episode : 32, timestep : 4963200, average reward : -118.37000274658203\n",
            "[4964352] Avg reward (last 50 episodes): -2.2305056488700212\n",
            "episode : 28, timestep : 4965600, average reward : -117.18000030517578\n",
            "episode : 32, timestep : 4968000, average reward : -117.11000061035156\n",
            "episode : 23, timestep : 4970400, average reward : -120.58000183105469\n",
            "[4972544] Avg reward (last 50 episodes): -2.136808792995289\n",
            "episode : 26, timestep : 4972800, average reward : -119.48999786376953\n",
            "episode : 28, timestep : 4975200, average reward : -117.75\n",
            "episode : 25, timestep : 4977600, average reward : -118.83000183105469\n",
            "episode : 17, timestep : 4980000, average reward : -115.66000366210938\n",
            "[4980736] Avg reward (last 50 episodes): -0.08617445081472397\n",
            "episode : 24, timestep : 4982400, average reward : -115.66999816894531\n",
            "episode : 14, timestep : 4984800, average reward : -112.0999984741211\n",
            "episode : 16, timestep : 4987200, average reward : -110.83000183105469\n",
            "[4988928] Avg reward (last 50 episodes): -0.0848265290260315\n",
            "episode : 16, timestep : 4989600, average reward : -117.05000305175781\n",
            "episode : 20, timestep : 4992000, average reward : -116.83000183105469\n",
            "episode : 19, timestep : 4994400, average reward : -116.38999938964844\n",
            "episode : 17, timestep : 4996800, average reward : -111.69000244140625\n",
            "[4997120] Avg reward (last 50 episodes): -0.31760820746421814\n",
            "episode : 14, timestep : 4999200, average reward : -116.91000366210938\n",
            "episode : 14, timestep : 5001600, average reward : -105.12000274658203\n",
            "episode : 28, timestep : 5004000, average reward : -119.22000122070312\n",
            "[5005312] Avg reward (last 50 episodes): -2.3117121338844298\n",
            "episode : 20, timestep : 5006400, average reward : -117.91999816894531\n",
            "episode : 29, timestep : 5008800, average reward : -118.6500015258789\n",
            "episode : 22, timestep : 5011200, average reward : -114.5999984741211\n",
            "setting action_std to  0.5862\n",
            "[5013504] Avg reward (last 50 episodes): -0.1616375893354416\n",
            "episode : 20, timestep : 5013600, average reward : -118.18000030517578\n",
            "episode : 22, timestep : 5016000, average reward : -115.27999877929688\n",
            "episode : 18, timestep : 5018400, average reward : -115.95999908447266\n",
            "episode : 23, timestep : 5020800, average reward : -115.55999755859375\n",
            "[5021696] Avg reward (last 50 episodes): -0.11446207761764526\n",
            "episode : 19, timestep : 5023200, average reward : -124.26000213623047\n",
            "episode : 26, timestep : 5025600, average reward : -120.88999938964844\n",
            "episode : 24, timestep : 5028000, average reward : -120.26000213623047\n",
            "[5029888] Avg reward (last 50 episodes): -0.22285433113574982\n",
            "episode : 22, timestep : 5030400, average reward : -121.30000305175781\n",
            "episode : 17, timestep : 5032800, average reward : -117.13999938964844\n",
            "episode : 27, timestep : 5035200, average reward : -119.70999908447266\n",
            "episode : 17, timestep : 5037600, average reward : -116.02999877929688\n",
            "[5038080] Avg reward (last 50 episodes): -2.339138468801975\n",
            "episode : 27, timestep : 5040000, average reward : -119.8499984741211\n",
            "episode : 28, timestep : 5042400, average reward : -119.76000213623047\n",
            "episode : 28, timestep : 5044800, average reward : -119.33000183105469\n",
            "[5046272] Avg reward (last 50 episodes): -2.2008712359517815\n",
            "episode : 27, timestep : 5047200, average reward : -119.95999908447266\n",
            "episode : 26, timestep : 5049600, average reward : -119.56999969482422\n",
            "episode : 23, timestep : 5052000, average reward : -120.62999725341797\n",
            "episode : 25, timestep : 5054400, average reward : -119.01000213623047\n",
            "[5054464] Avg reward (last 50 episodes): -2.200548485182226\n",
            "episode : 23, timestep : 5056800, average reward : -120.33000183105469\n",
            "episode : 27, timestep : 5059200, average reward : -119.44999694824219\n",
            "episode : 26, timestep : 5061600, average reward : -118.29000091552734\n",
            "[5062656] Avg reward (last 50 episodes): -0.08745098859071732\n",
            "episode : 29, timestep : 5064000, average reward : -118.1500015258789\n",
            "episode : 28, timestep : 5066400, average reward : -117.80000305175781\n",
            "episode : 28, timestep : 5068800, average reward : -117.4000015258789\n",
            "[5070848] Avg reward (last 50 episodes): -2.192458617836237\n",
            "episode : 26, timestep : 5071200, average reward : -119.30999755859375\n",
            "episode : 32, timestep : 5073600, average reward : -118.4000015258789\n",
            "episode : 26, timestep : 5076000, average reward : -120.12999725341797\n",
            "episode : 26, timestep : 5078400, average reward : -118.19999694824219\n",
            "[5079040] Avg reward (last 50 episodes): -2.2943275175616145\n",
            "episode : 26, timestep : 5080800, average reward : -119.4800033569336\n",
            "episode : 23, timestep : 5083200, average reward : -118.29000091552734\n",
            "episode : 26, timestep : 5085600, average reward : -119.13999938964844\n",
            "[5087232] Avg reward (last 50 episodes): -0.08882706612348557\n",
            "episode : 27, timestep : 5088000, average reward : -118.9800033569336\n",
            "episode : 29, timestep : 5090400, average reward : -117.5999984741211\n",
            "episode : 25, timestep : 5092800, average reward : -118.4800033569336\n",
            "episode : 24, timestep : 5095200, average reward : -118.63999938964844\n",
            "[5095424] Avg reward (last 50 episodes): -0.05086062103509903\n",
            "episode : 25, timestep : 5097600, average reward : -119.29000091552734\n",
            "episode : 24, timestep : 5100000, average reward : -118.05000305175781\n",
            "episode : 26, timestep : 5102400, average reward : -116.75\n",
            "[5103616] Avg reward (last 50 episodes): -0.0959291085600853\n",
            "episode : 30, timestep : 5104800, average reward : -119.06999969482422\n",
            "episode : 33, timestep : 5107200, average reward : -116.93000030517578\n",
            "episode : 29, timestep : 5109600, average reward : -117.77999877929688\n",
            "[5111808] Avg reward (last 50 episodes): -2.271358845978975\n",
            "episode : 23, timestep : 5112000, average reward : -121.06999969482422\n",
            "setting action_std to  0.5859\n",
            "episode : 26, timestep : 5114400, average reward : -117.55999755859375\n",
            "episode : 29, timestep : 5116800, average reward : -116.08000183105469\n",
            "episode : 30, timestep : 5119200, average reward : -118.4000015258789\n",
            "[5120000] Avg reward (last 50 episodes): -2.319473508372903\n",
            "episode : 24, timestep : 5121600, average reward : -119.93000030517578\n",
            "episode : 28, timestep : 5124000, average reward : -118.27999877929688\n",
            "episode : 30, timestep : 5126400, average reward : -119.01000213623047\n",
            "[5128192] Avg reward (last 50 episodes): -2.2537254547700285\n",
            "episode : 27, timestep : 5128800, average reward : -119.5199966430664\n",
            "episode : 25, timestep : 5131200, average reward : -118.93000030517578\n",
            "episode : 25, timestep : 5133600, average reward : -119.45999908447266\n",
            "episode : 25, timestep : 5136000, average reward : -118.66999816894531\n",
            "[5136384] Avg reward (last 50 episodes): -2.0293014929210766\n",
            "episode : 25, timestep : 5138400, average reward : -118.48999786376953\n",
            "episode : 29, timestep : 5140800, average reward : -117.79000091552734\n",
            "episode : 24, timestep : 5143200, average reward : -116.13999938964844\n",
            "[5144576] Avg reward (last 50 episodes): -0.11897266656160355\n",
            "episode : 28, timestep : 5145600, average reward : -118.2699966430664\n",
            "episode : 28, timestep : 5148000, average reward : -118.29000091552734\n",
            "episode : 26, timestep : 5150400, average reward : -118.05000305175781\n",
            "[5152768] Avg reward (last 50 episodes): -2.295047578513622\n",
            "episode : 28, timestep : 5152800, average reward : -120.02999877929688\n",
            "episode : 28, timestep : 5155200, average reward : -118.44999694824219\n",
            "episode : 25, timestep : 5157600, average reward : -119.22000122070312\n",
            "episode : 23, timestep : 5160000, average reward : -118.37000274658203\n",
            "[5160960] Avg reward (last 50 episodes): -0.28436774015426636\n",
            "episode : 29, timestep : 5162400, average reward : -117.80000305175781\n",
            "episode : 29, timestep : 5164800, average reward : -117.36000061035156\n",
            "episode : 27, timestep : 5167200, average reward : -118.95999908447266\n",
            "[5169152] Avg reward (last 50 episodes): -2.2807037016004323\n",
            "episode : 29, timestep : 5169600, average reward : -116.87999725341797\n",
            "episode : 28, timestep : 5172000, average reward : -118.7300033569336\n",
            "episode : 22, timestep : 5174400, average reward : -117.98999786376953\n",
            "episode : 26, timestep : 5176800, average reward : -116.33000183105469\n",
            "[5177344] Avg reward (last 50 episodes): -2.2678602835536004\n",
            "episode : 27, timestep : 5179200, average reward : -118.6500015258789\n",
            "episode : 17, timestep : 5181600, average reward : -116.9000015258789\n",
            "episode : 25, timestep : 5184000, average reward : -118.05000305175781\n",
            "[5185536] Avg reward (last 50 episodes): -0.13271234929561615\n",
            "episode : 24, timestep : 5186400, average reward : -115.69000244140625\n",
            "episode : 25, timestep : 5188800, average reward : -118.43000030517578\n",
            "episode : 30, timestep : 5191200, average reward : -116.66999816894531\n",
            "episode : 20, timestep : 5193600, average reward : -116.58000183105469\n",
            "[5193728] Avg reward (last 50 episodes): -2.2425598916970193\n",
            "episode : 22, timestep : 5196000, average reward : -119.5999984741211\n",
            "episode : 24, timestep : 5198400, average reward : -119.66999816894531\n",
            "episode : 24, timestep : 5200800, average reward : -119.06999969482422\n",
            "[5201920] Avg reward (last 50 episodes): -0.0875028520822525\n",
            "episode : 23, timestep : 5203200, average reward : -114.29000091552734\n",
            "episode : 27, timestep : 5205600, average reward : -119.55999755859375\n",
            "episode : 13, timestep : 5208000, average reward : -115.80999755859375\n",
            "[5210112] Avg reward (last 50 episodes): -2.215772267319262\n",
            "episode : 27, timestep : 5210400, average reward : -118.0199966430664\n",
            "episode : 24, timestep : 5212800, average reward : -117.87000274658203\n",
            "setting action_std to  0.5856\n",
            "episode : 23, timestep : 5215200, average reward : -117.45999908447266\n",
            "episode : 22, timestep : 5217600, average reward : -116.83000183105469\n",
            "[5218304] Avg reward (last 50 episodes): -2.3622677578032016\n",
            "episode : 28, timestep : 5220000, average reward : -118.58000183105469\n",
            "episode : 23, timestep : 5222400, average reward : -116.02999877929688\n",
            "episode : 19, timestep : 5224800, average reward : -115.2699966430664\n",
            "[5226496] Avg reward (last 50 episodes): -0.08035008609294891\n",
            "episode : 11, timestep : 5227200, average reward : -100.01000213623047\n",
            "episode : 15, timestep : 5229600, average reward : -111.80999755859375\n",
            "episode : 14, timestep : 5232000, average reward : -106.69000244140625\n",
            "episode : 14, timestep : 5234400, average reward : -105.31999969482422\n",
            "[5234688] Avg reward (last 50 episodes): -0.15513291954994202\n",
            "episode : 15, timestep : 5236800, average reward : -114.37000274658203\n",
            "episode : 21, timestep : 5239200, average reward : -114.83999633789062\n",
            "episode : 14, timestep : 5241600, average reward : -110.51000213623047\n",
            "[5242880] Avg reward (last 50 episodes): -0.21425464749336243\n",
            "episode : 26, timestep : 5244000, average reward : -116.27999877929688\n",
            "episode : 15, timestep : 5246400, average reward : -114.87999725341797\n",
            "episode : 24, timestep : 5248800, average reward : -112.69000244140625\n",
            "[5251072] Avg reward (last 50 episodes): -0.14713154733181\n",
            "episode : 23, timestep : 5251200, average reward : -119.72000122070312\n",
            "episode : 14, timestep : 5253600, average reward : -107.61000061035156\n",
            "episode : 17, timestep : 5256000, average reward : -111.83999633789062\n",
            "episode : 15, timestep : 5258400, average reward : -114.88999938964844\n",
            "[5259264] Avg reward (last 50 episodes): -0.08941307663917542\n",
            "episode : 22, timestep : 5260800, average reward : -111.97000122070312\n",
            "episode : 23, timestep : 5263200, average reward : -113.56999969482422\n",
            "episode : 27, timestep : 5265600, average reward : -118.72000122070312\n",
            "[5267456] Avg reward (last 50 episodes): -2.3399883882701396\n",
            "episode : 24, timestep : 5268000, average reward : -115.44999694824219\n",
            "episode : 27, timestep : 5270400, average reward : -118.98999786376953\n",
            "episode : 21, timestep : 5272800, average reward : -115.30000305175781\n",
            "episode : 16, timestep : 5275200, average reward : -116.33999633789062\n",
            "[5275648] Avg reward (last 50 episodes): -2.2732490628957747\n",
            "episode : 14, timestep : 5277600, average reward : -103.01000213623047\n",
            "episode : 12, timestep : 5280000, average reward : -107.08000183105469\n",
            "episode : 17, timestep : 5282400, average reward : -106.37000274658203\n",
            "[5283840] Avg reward (last 50 episodes): -2.1720429173856974\n",
            "episode : 12, timestep : 5284800, average reward : -106.97000122070312\n",
            "episode : 14, timestep : 5287200, average reward : -106.79000091552734\n",
            "episode : 22, timestep : 5289600, average reward : -118.27999877929688\n",
            "episode : 17, timestep : 5292000, average reward : -113.08000183105469\n",
            "[5292032] Avg reward (last 50 episodes): -0.24640685319900513\n",
            "episode : 23, timestep : 5294400, average reward : -115.4000015258789\n",
            "episode : 21, timestep : 5296800, average reward : -112.55999755859375\n",
            "episode : 14, timestep : 5299200, average reward : -109.91999816894531\n",
            "[5300224] Avg reward (last 50 episodes): -2.30883831191808\n",
            "episode : 23, timestep : 5301600, average reward : -116.29000091552734\n",
            "episode : 27, timestep : 5304000, average reward : -118.41999816894531\n",
            "episode : 29, timestep : 5306400, average reward : -117.79000091552734\n",
            "[5308416] Avg reward (last 50 episodes): -2.373964423537254\n",
            "episode : 26, timestep : 5308800, average reward : -118.62999725341797\n",
            "episode : 24, timestep : 5311200, average reward : -118.52999877929688\n",
            "setting action_std to  0.5853\n",
            "episode : 28, timestep : 5313600, average reward : -119.56999969482422\n",
            "episode : 27, timestep : 5316000, average reward : -118.70999908447266\n",
            "[5316608] Avg reward (last 50 episodes): -2.364935919046402\n",
            "episode : 30, timestep : 5318400, average reward : -117.69000244140625\n",
            "episode : 24, timestep : 5320800, average reward : -119.41999816894531\n",
            "episode : 23, timestep : 5323200, average reward : -121.02999877929688\n",
            "[5324800] Avg reward (last 50 episodes): -0.06505556404590607\n",
            "episode : 26, timestep : 5325600, average reward : -119.54000091552734\n",
            "episode : 22, timestep : 5328000, average reward : -114.04000091552734\n",
            "episode : 27, timestep : 5330400, average reward : -118.2699966430664\n",
            "episode : 27, timestep : 5332800, average reward : -118.76000213623047\n",
            "[5332992] Avg reward (last 50 episodes): -0.1897691935300827\n",
            "episode : 30, timestep : 5335200, average reward : -118.23999786376953\n",
            "episode : 30, timestep : 5337600, average reward : -116.9800033569336\n",
            "episode : 27, timestep : 5340000, average reward : -117.30000305175781\n",
            "[5341184] Avg reward (last 50 episodes): -0.07427068054676056\n",
            "episode : 29, timestep : 5342400, average reward : -118.26000213623047\n",
            "episode : 22, timestep : 5344800, average reward : -118.70999908447266\n",
            "episode : 28, timestep : 5347200, average reward : -113.87000274658203\n",
            "[5349376] Avg reward (last 50 episodes): -0.08117787539958954\n",
            "episode : 21, timestep : 5349600, average reward : -113.6500015258789\n",
            "episode : 9, timestep : 5352000, average reward : -95.61000061035156\n",
            "episode : 12, timestep : 5354400, average reward : -99.37000274658203\n",
            "episode : 7, timestep : 5356800, average reward : -89.4000015258789\n",
            "[5357568] Avg reward (last 50 episodes): -2.319970189332962\n",
            "episode : 12, timestep : 5359200, average reward : -102.1500015258789\n",
            "episode : 11, timestep : 5361600, average reward : -106.01000213623047\n",
            "episode : 7, timestep : 5364000, average reward : -82.95999908447266\n",
            "[5365760] Avg reward (last 50 episodes): -2.2766388197615743\n",
            "episode : 15, timestep : 5366400, average reward : -103.6500015258789\n",
            "episode : 15, timestep : 5368800, average reward : -110.20999908447266\n",
            "episode : 10, timestep : 5371200, average reward : -98.83000183105469\n",
            "episode : 8, timestep : 5373600, average reward : -107.36000061035156\n",
            "[5373952] Avg reward (last 50 episodes): 0.0067985630594193935\n",
            "episode : 10, timestep : 5376000, average reward : -91.30999755859375\n",
            "episode : 10, timestep : 5378400, average reward : -98.43000030517578\n",
            "episode : 5, timestep : 5380800, average reward : -78.54000091552734\n",
            "[5382144] Avg reward (last 50 episodes): -0.08055325597524643\n",
            "episode : 9, timestep : 5383200, average reward : -99.19999694824219\n",
            "episode : 16, timestep : 5385600, average reward : -108.83999633789062\n",
            "episode : 14, timestep : 5388000, average reward : -103.5\n",
            "[5390336] Avg reward (last 50 episodes): -0.10683274269104004\n",
            "episode : 12, timestep : 5390400, average reward : -107.3499984741211\n",
            "episode : 7, timestep : 5392800, average reward : -81.30000305175781\n",
            "episode : 11, timestep : 5395200, average reward : -108.33999633789062\n",
            "episode : 13, timestep : 5397600, average reward : -106.7300033569336\n",
            "[5398528] Avg reward (last 50 episodes): -0.08352841436862946\n",
            "episode : 16, timestep : 5400000, average reward : -105.93000030517578\n",
            "episode : 26, timestep : 5402400, average reward : -117.91000366210938\n",
            "episode : 23, timestep : 5404800, average reward : -112.86000061035156\n",
            "[5406720] Avg reward (last 50 episodes): -0.1674136519432068\n",
            "episode : 23, timestep : 5407200, average reward : -112.37000274658203\n",
            "episode : 29, timestep : 5409600, average reward : -115.73999786376953\n",
            "episode : 29, timestep : 5412000, average reward : -114.37999725341797\n",
            "setting action_std to  0.585\n",
            "episode : 25, timestep : 5414400, average reward : -111.91999816894531\n",
            "[5414912] Avg reward (last 50 episodes): -2.2422141819819807\n",
            "episode : 19, timestep : 5416800, average reward : -112.02999877929688\n",
            "episode : 13, timestep : 5419200, average reward : -102.52999877929688\n",
            "episode : 22, timestep : 5421600, average reward : -111.6500015258789\n",
            "[5423104] Avg reward (last 50 episodes): -2.250602672025561\n",
            "episode : 22, timestep : 5424000, average reward : -112.37000274658203\n",
            "episode : 10, timestep : 5426400, average reward : -98.63999938964844\n",
            "episode : 9, timestep : 5428800, average reward : -104.7699966430664\n",
            "episode : 16, timestep : 5431200, average reward : -113.4800033569336\n",
            "[5431296] Avg reward (last 50 episodes): -2.2064189559221266\n",
            "episode : 19, timestep : 5433600, average reward : -113.19000244140625\n",
            "episode : 9, timestep : 5436000, average reward : -95.94999694824219\n",
            "episode : 18, timestep : 5438400, average reward : -111.54000091552734\n",
            "[5439488] Avg reward (last 50 episodes): -2.1880856892466545\n",
            "episode : 21, timestep : 5440800, average reward : -114.2699966430664\n",
            "episode : 29, timestep : 5443200, average reward : -116.61000061035156\n",
            "episode : 24, timestep : 5445600, average reward : -111.04000091552734\n",
            "[5447680] Avg reward (last 50 episodes): -2.2566744095832107\n",
            "episode : 24, timestep : 5448000, average reward : -112.9000015258789\n",
            "episode : 30, timestep : 5450400, average reward : -113.94999694824219\n",
            "episode : 31, timestep : 5452800, average reward : -115.80999755859375\n",
            "episode : 20, timestep : 5455200, average reward : -113.69000244140625\n",
            "[5455872] Avg reward (last 50 episodes): -2.2206600134819747\n",
            "episode : 23, timestep : 5457600, average reward : -112.33999633789062\n",
            "episode : 24, timestep : 5460000, average reward : -116.22000122070312\n",
            "episode : 22, timestep : 5462400, average reward : -115.73999786376953\n",
            "[5464064] Avg reward (last 50 episodes): -2.249016354419291\n",
            "episode : 23, timestep : 5464800, average reward : -113.22000122070312\n",
            "episode : 17, timestep : 5467200, average reward : -104.43000030517578\n",
            "episode : 17, timestep : 5469600, average reward : -108.80999755859375\n",
            "episode : 24, timestep : 5472000, average reward : -111.06999969482422\n",
            "[5472256] Avg reward (last 50 episodes): -0.0009008151246234775\n",
            "episode : 15, timestep : 5474400, average reward : -108.08999633789062\n",
            "episode : 17, timestep : 5476800, average reward : -107.69000244140625\n",
            "episode : 23, timestep : 5479200, average reward : -117.66999816894531\n",
            "[5480448] Avg reward (last 50 episodes): -0.06652063131332397\n",
            "episode : 27, timestep : 5481600, average reward : -115.6500015258789\n",
            "episode : 23, timestep : 5484000, average reward : -112.5\n",
            "episode : 21, timestep : 5486400, average reward : -113.83000183105469\n",
            "[5488640] Avg reward (last 50 episodes): -0.17672643065452576\n",
            "episode : 22, timestep : 5488800, average reward : -112.16000366210938\n",
            "episode : 12, timestep : 5491200, average reward : -106.11000061035156\n",
            "episode : 17, timestep : 5493600, average reward : -101.12999725341797\n",
            "episode : 18, timestep : 5496000, average reward : -111.23999786376953\n",
            "[5496832] Avg reward (last 50 episodes): -0.08648069202899933\n",
            "episode : 12, timestep : 5498400, average reward : -101.94999694824219\n",
            "episode : 21, timestep : 5500800, average reward : -113.79000091552734\n",
            "episode : 21, timestep : 5503200, average reward : -113.61000061035156\n",
            "[5505024] Avg reward (last 50 episodes): -0.07584168761968613\n",
            "episode : 20, timestep : 5505600, average reward : -109.86000061035156\n",
            "episode : 12, timestep : 5508000, average reward : -108.16999816894531\n",
            "episode : 14, timestep : 5510400, average reward : -108.33999633789062\n",
            "episode : 11, timestep : 5512800, average reward : -115.6500015258789\n",
            "setting action_std to  0.5847\n",
            "[5513216] Avg reward (last 50 episodes): -0.16664648056030273\n",
            "episode : 23, timestep : 5515200, average reward : -110.41000366210938\n",
            "episode : 18, timestep : 5517600, average reward : -113.62999725341797\n",
            "episode : 21, timestep : 5520000, average reward : -113.12000274658203\n",
            "[5521408] Avg reward (last 50 episodes): -0.11441896110773087\n",
            "episode : 17, timestep : 5522400, average reward : -109.79000091552734\n",
            "episode : 19, timestep : 5524800, average reward : -108.41000366210938\n",
            "episode : 22, timestep : 5527200, average reward : -113.94000244140625\n",
            "[5529600] Avg reward (last 50 episodes): -0.04815112054347992\n",
            "episode : 16, timestep : 5529600, average reward : -112.5199966430664\n",
            "episode : 15, timestep : 5532000, average reward : -108.80999755859375\n",
            "episode : 16, timestep : 5534400, average reward : -107.44999694824219\n",
            "episode : 23, timestep : 5536800, average reward : -120.43000030517578\n",
            "[5537792] Avg reward (last 50 episodes): -0.0819878876209259\n",
            "episode : 15, timestep : 5539200, average reward : -115.26000213623047\n",
            "episode : 7, timestep : 5541600, average reward : -77.13999938964844\n",
            "episode : 13, timestep : 5544000, average reward : -106.66000366210938\n",
            "[5545984] Avg reward (last 50 episodes): -0.09023189544677734\n",
            "episode : 12, timestep : 5546400, average reward : -101.72000122070312\n",
            "episode : 5, timestep : 5548800, average reward : -91.4000015258789\n",
            "episode : 5, timestep : 5551200, average reward : -86.20999908447266\n",
            "episode : 6, timestep : 5553600, average reward : -97.54000091552734\n",
            "[5554176] Avg reward (last 50 episodes): -0.12547381222248077\n",
            "episode : 7, timestep : 5556000, average reward : -84.58000183105469\n",
            "episode : 4, timestep : 5558400, average reward : -67.48999786376953\n",
            "episode : 9, timestep : 5560800, average reward : -87.33999633789062\n",
            "[5562368] Avg reward (last 50 episodes): -0.14291247725486755\n",
            "episode : 6, timestep : 5563200, average reward : -87.87999725341797\n",
            "episode : 5, timestep : 5565600, average reward : -72.58999633789062\n",
            "episode : 4, timestep : 5568000, average reward : -57.27000045776367\n",
            "episode : 4, timestep : 5570400, average reward : -53.84000015258789\n",
            "[5570560] Avg reward (last 50 episodes): -2.1288366711139677\n",
            "episode : 4, timestep : 5572800, average reward : -81.86000061035156\n",
            "episode : 6, timestep : 5575200, average reward : -74.29000091552734\n",
            "episode : 5, timestep : 5577600, average reward : -67.33000183105469\n",
            "[5578752] Avg reward (last 50 episodes): -0.11035585403442383\n",
            "episode : 6, timestep : 5580000, average reward : -82.47000122070312\n",
            "episode : 8, timestep : 5582400, average reward : -82.66000366210938\n",
            "episode : 5, timestep : 5584800, average reward : -58.43000030517578\n",
            "[5586944] Avg reward (last 50 episodes): -0.048214368522167206\n",
            "episode : 4, timestep : 5587200, average reward : -66.29000091552734\n",
            "episode : 5, timestep : 5589600, average reward : -60.970001220703125\n",
            "episode : 8, timestep : 5592000, average reward : -83.95999908447266\n",
            "episode : 8, timestep : 5594400, average reward : -90.94999694824219\n",
            "[5595136] Avg reward (last 50 episodes): 0.015766534954309464\n",
            "episode : 6, timestep : 5596800, average reward : -86.61000061035156\n",
            "episode : 4, timestep : 5599200, average reward : -48.189998626708984\n",
            "episode : 4, timestep : 5601600, average reward : -48.63999938964844\n",
            "[5603328] Avg reward (last 50 episodes): -2.2890102215111257\n",
            "episode : 10, timestep : 5604000, average reward : -91.33999633789062\n",
            "episode : 4, timestep : 5606400, average reward : -51.119998931884766\n",
            "episode : 7, timestep : 5608800, average reward : -85.98999786376953\n",
            "episode : 7, timestep : 5611200, average reward : -81.5\n",
            "[5611520] Avg reward (last 50 episodes): -0.17577636241912842\n",
            "episode : 5, timestep : 5613600, average reward : -81.04000091552734\n",
            "setting action_std to  0.5844\n",
            "episode : 8, timestep : 5616000, average reward : -85.5999984741211\n",
            "episode : 6, timestep : 5618400, average reward : -83.1500015258789\n",
            "[5619712] Avg reward (last 50 episodes): -0.052365560084581375\n",
            "episode : 5, timestep : 5620800, average reward : -66.58999633789062\n",
            "episode : 5, timestep : 5623200, average reward : -63.369998931884766\n",
            "episode : 4, timestep : 5625600, average reward : -46.779998779296875\n",
            "[5627904] Avg reward (last 50 episodes): -0.11760128289461136\n",
            "episode : 5, timestep : 5628000, average reward : -63.939998626708984\n",
            "episode : 4, timestep : 5630400, average reward : -55.209999084472656\n",
            "episode : 5, timestep : 5632800, average reward : -65.52999877929688\n",
            "episode : 4, timestep : 5635200, average reward : -51.150001525878906\n",
            "[5636096] Avg reward (last 50 episodes): -0.08045447617769241\n",
            "episode : 5, timestep : 5637600, average reward : -65.30999755859375\n",
            "episode : 5, timestep : 5640000, average reward : -76.81999969482422\n",
            "episode : 4, timestep : 5642400, average reward : -48.849998474121094\n",
            "[5644288] Avg reward (last 50 episodes): -0.02973964437842369\n",
            "episode : 5, timestep : 5644800, average reward : -59.33000183105469\n",
            "episode : 5, timestep : 5647200, average reward : -85.2300033569336\n",
            "episode : 6, timestep : 5649600, average reward : -82.36000061035156\n",
            "episode : 4, timestep : 5652000, average reward : -56.34000015258789\n",
            "[5652480] Avg reward (last 50 episodes): -0.07967731356620789\n",
            "episode : 4, timestep : 5654400, average reward : -51.63999938964844\n",
            "episode : 5, timestep : 5656800, average reward : -68.37000274658203\n",
            "episode : 5, timestep : 5659200, average reward : -87.62999725341797\n",
            "[5660672] Avg reward (last 50 episodes): -0.06795865297317505\n",
            "episode : 4, timestep : 5661600, average reward : -55.84000015258789\n",
            "episode : 5, timestep : 5664000, average reward : -82.30999755859375\n",
            "episode : 4, timestep : 5666400, average reward : -47.72999954223633\n",
            "episode : 4, timestep : 5668800, average reward : -53.95000076293945\n",
            "[5668864] Avg reward (last 50 episodes): -0.12379533797502518\n",
            "episode : 7, timestep : 5671200, average reward : -95.69999694824219\n",
            "episode : 4, timestep : 5673600, average reward : -76.26000213623047\n",
            "episode : 5, timestep : 5676000, average reward : -88.12999725341797\n",
            "[5677056] Avg reward (last 50 episodes): -0.1103670671582222\n",
            "episode : 7, timestep : 5678400, average reward : -83.47000122070312\n",
            "episode : 6, timestep : 5680800, average reward : -88.94999694824219\n",
            "episode : 4, timestep : 5683200, average reward : -68.4000015258789\n",
            "[5685248] Avg reward (last 50 episodes): -0.10441052168607712\n",
            "episode : 7, timestep : 5685600, average reward : -116.7699966430664\n",
            "episode : 6, timestep : 5688000, average reward : -73.22000122070312\n",
            "episode : 4, timestep : 5690400, average reward : -51.5\n",
            "episode : 5, timestep : 5692800, average reward : -84.33000183105469\n",
            "[5693440] Avg reward (last 50 episodes): -0.0675942450761795\n",
            "episode : 4, timestep : 5695200, average reward : -51.29999923706055\n",
            "episode : 4, timestep : 5697600, average reward : -42.869998931884766\n",
            "episode : 5, timestep : 5700000, average reward : -61.619998931884766\n",
            "[5701632] Avg reward (last 50 episodes): -0.02687978558242321\n",
            "episode : 5, timestep : 5702400, average reward : -66.55999755859375\n",
            "episode : 4, timestep : 5704800, average reward : -51.2599983215332\n",
            "episode : 4, timestep : 5707200, average reward : -49.0099983215332\n",
            "episode : 5, timestep : 5709600, average reward : -72.1500015258789\n",
            "[5709824] Avg reward (last 50 episodes): -0.16135719418525696\n",
            "episode : 4, timestep : 5712000, average reward : -70.25\n",
            "setting action_std to  0.5841\n",
            "episode : 5, timestep : 5714400, average reward : -73.66000366210938\n",
            "episode : 4, timestep : 5716800, average reward : -63.88999938964844\n",
            "[5718016] Avg reward (last 50 episodes): -0.06983131170272827\n",
            "episode : 6, timestep : 5719200, average reward : -76.01000213623047\n",
            "episode : 4, timestep : 5721600, average reward : -48.06999969482422\n",
            "episode : 4, timestep : 5724000, average reward : -44.650001525878906\n",
            "[5726208] Avg reward (last 50 episodes): -0.032809481024742126\n",
            "episode : 6, timestep : 5726400, average reward : -73.79000091552734\n",
            "episode : 4, timestep : 5728800, average reward : -63.91999816894531\n",
            "episode : 4, timestep : 5731200, average reward : -47.25\n",
            "episode : 5, timestep : 5733600, average reward : -64.45999908447266\n",
            "[5734400] Avg reward (last 50 episodes): -0.2283533811569214\n",
            "episode : 5, timestep : 5736000, average reward : -86.0999984741211\n",
            "episode : 4, timestep : 5738400, average reward : -50.06999969482422\n",
            "episode : 4, timestep : 5740800, average reward : -48.84000015258789\n",
            "[5742592] Avg reward (last 50 episodes): -0.147058367729187\n",
            "episode : 4, timestep : 5743200, average reward : -48.720001220703125\n",
            "episode : 5, timestep : 5745600, average reward : -63.33000183105469\n",
            "episode : 6, timestep : 5748000, average reward : -67.51000213623047\n",
            "episode : 4, timestep : 5750400, average reward : -52.099998474121094\n",
            "[5750784] Avg reward (last 50 episodes): -0.17923516035079956\n",
            "episode : 4, timestep : 5752800, average reward : -47.58000183105469\n",
            "episode : 4, timestep : 5755200, average reward : -52.95000076293945\n",
            "episode : 5, timestep : 5757600, average reward : -62.29999923706055\n",
            "[5758976] Avg reward (last 50 episodes): -0.05412667617201805\n",
            "episode : 4, timestep : 5760000, average reward : -48.709999084472656\n",
            "episode : 5, timestep : 5762400, average reward : -69.68000030517578\n",
            "episode : 4, timestep : 5764800, average reward : -63.709999084472656\n",
            "[5767168] Avg reward (last 50 episodes): -0.12174609303474426\n",
            "episode : 4, timestep : 5767200, average reward : -51.560001373291016\n",
            "episode : 4, timestep : 5769600, average reward : -49.849998474121094\n",
            "episode : 4, timestep : 5772000, average reward : -50.279998779296875\n",
            "episode : 4, timestep : 5774400, average reward : -48.84000015258789\n",
            "[5775360] Avg reward (last 50 episodes): -0.1277676522731781\n",
            "episode : 4, timestep : 5776800, average reward : -53.36000061035156\n",
            "episode : 4, timestep : 5779200, average reward : -50.18000030517578\n",
            "episode : 5, timestep : 5781600, average reward : -63.9900016784668\n",
            "[5783552] Avg reward (last 50 episodes): -0.06542372703552246\n",
            "episode : 4, timestep : 5784000, average reward : -48.720001220703125\n",
            "episode : 4, timestep : 5786400, average reward : -44.75\n",
            "episode : 4, timestep : 5788800, average reward : -46.63999938964844\n",
            "episode : 4, timestep : 5791200, average reward : -50.529998779296875\n",
            "[5791744] Avg reward (last 50 episodes): -0.13064222037792206\n",
            "episode : 5, timestep : 5793600, average reward : -60.66999816894531\n",
            "episode : 4, timestep : 5796000, average reward : -47.439998626708984\n",
            "episode : 5, timestep : 5798400, average reward : -65.11000061035156\n",
            "[5799936] Avg reward (last 50 episodes): -0.05561146140098572\n",
            "episode : 5, timestep : 5800800, average reward : -80.5\n",
            "episode : 4, timestep : 5803200, average reward : -49.619998931884766\n",
            "episode : 6, timestep : 5805600, average reward : -91.54000091552734\n",
            "episode : 6, timestep : 5808000, average reward : -70.63999938964844\n",
            "[5808128] Avg reward (last 50 episodes): -0.055900756269693375\n",
            "episode : 4, timestep : 5810400, average reward : -46.4900016784668\n",
            "episode : 5, timestep : 5812800, average reward : -65.93000030517578\n",
            "setting action_std to  0.5838\n",
            "episode : 4, timestep : 5815200, average reward : -45.13999938964844\n",
            "[5816320] Avg reward (last 50 episodes): -0.003385215997695923\n",
            "episode : 4, timestep : 5817600, average reward : -65.37999725341797\n",
            "episode : 4, timestep : 5820000, average reward : -46.279998779296875\n",
            "episode : 4, timestep : 5822400, average reward : -45.79999923706055\n",
            "[5824512] Avg reward (last 50 episodes): -0.08139333873987198\n",
            "episode : 4, timestep : 5824800, average reward : -49.15999984741211\n",
            "episode : 4, timestep : 5827200, average reward : -44.45000076293945\n",
            "episode : 4, timestep : 5829600, average reward : -53.869998931884766\n",
            "episode : 6, timestep : 5832000, average reward : -68.0199966430664\n",
            "[5832704] Avg reward (last 50 episodes): -0.07803268730640411\n",
            "episode : 6, timestep : 5834400, average reward : -86.19000244140625\n",
            "episode : 6, timestep : 5836800, average reward : -88.41999816894531\n",
            "episode : 4, timestep : 5839200, average reward : -64.29000091552734\n",
            "[5840896] Avg reward (last 50 episodes): -0.010954187251627445\n",
            "episode : 7, timestep : 5841600, average reward : -76.62000274658203\n",
            "episode : 6, timestep : 5844000, average reward : -69.86000061035156\n",
            "episode : 5, timestep : 5846400, average reward : -71.62999725341797\n",
            "episode : 6, timestep : 5848800, average reward : -68.5199966430664\n",
            "[5849088] Avg reward (last 50 episodes): -0.021690161898732185\n",
            "episode : 10, timestep : 5851200, average reward : -92.70999908447266\n",
            "episode : 5, timestep : 5853600, average reward : -73.41999816894531\n",
            "episode : 6, timestep : 5856000, average reward : -85.79000091552734\n",
            "[5857280] Avg reward (last 50 episodes): -0.0802137553691864\n",
            "episode : 9, timestep : 5858400, average reward : -85.51000213623047\n",
            "episode : 7, timestep : 5860800, average reward : -89.5199966430664\n",
            "episode : 8, timestep : 5863200, average reward : -79.62999725341797\n",
            "[5865472] Avg reward (last 50 episodes): -0.1635321080684662\n",
            "episode : 11, timestep : 5865600, average reward : -107.12999725341797\n",
            "episode : 11, timestep : 5868000, average reward : -97.88999938964844\n",
            "episode : 5, timestep : 5870400, average reward : -72.37999725341797\n",
            "episode : 9, timestep : 5872800, average reward : -95.11000061035156\n",
            "[5873664] Avg reward (last 50 episodes): -0.06964502483606339\n",
            "episode : 8, timestep : 5875200, average reward : -80.1500015258789\n",
            "episode : 6, timestep : 5877600, average reward : -69.80000305175781\n",
            "episode : 5, timestep : 5880000, average reward : -73.30000305175781\n",
            "[5881856] Avg reward (last 50 episodes): -0.0854284018278122\n",
            "episode : 6, timestep : 5882400, average reward : -69.37000274658203\n",
            "episode : 6, timestep : 5884800, average reward : -70.23999786376953\n",
            "episode : 4, timestep : 5887200, average reward : -66.66000366210938\n",
            "episode : 5, timestep : 5889600, average reward : -53.349998474121094\n",
            "[5890048] Avg reward (last 50 episodes): 0.003921299707144499\n",
            "episode : 9, timestep : 5892000, average reward : -84.58999633789062\n",
            "episode : 4, timestep : 5894400, average reward : -44.0\n",
            "episode : 6, timestep : 5896800, average reward : -84.1500015258789\n",
            "[5898240] Avg reward (last 50 episodes): -0.10836432129144669\n",
            "episode : 7, timestep : 5899200, average reward : -76.38999938964844\n",
            "episode : 8, timestep : 5901600, average reward : -89.66000366210938\n",
            "episode : 6, timestep : 5904000, average reward : -64.51000213623047\n",
            "episode : 8, timestep : 5906400, average reward : -88.12000274658203\n",
            "[5906432] Avg reward (last 50 episodes): -0.06525823473930359\n",
            "episode : 13, timestep : 5908800, average reward : -107.16000366210938\n",
            "episode : 5, timestep : 5911200, average reward : -71.47000122070312\n",
            "episode : 21, timestep : 5913600, average reward : -107.66999816894531\n",
            "setting action_std to  0.5835\n",
            "[5914624] Avg reward (last 50 episodes): -0.06410541385412216\n",
            "episode : 16, timestep : 5916000, average reward : -109.41999816894531\n",
            "episode : 24, timestep : 5918400, average reward : -116.12000274658203\n",
            "episode : 12, timestep : 5920800, average reward : -97.44000244140625\n",
            "[5922816] Avg reward (last 50 episodes): -0.27780449390411377\n",
            "episode : 14, timestep : 5923200, average reward : -106.76000213623047\n",
            "episode : 15, timestep : 5925600, average reward : -105.91999816894531\n",
            "episode : 14, timestep : 5928000, average reward : -105.4800033569336\n",
            "episode : 14, timestep : 5930400, average reward : -108.52999877929688\n",
            "[5931008] Avg reward (last 50 episodes): -2.1946289706788957\n",
            "episode : 18, timestep : 5932800, average reward : -109.38999938964844\n",
            "episode : 11, timestep : 5935200, average reward : -95.8499984741211\n",
            "episode : 20, timestep : 5937600, average reward : -114.19000244140625\n",
            "[5939200] Avg reward (last 50 episodes): -2.362296259626746\n",
            "episode : 18, timestep : 5940000, average reward : -108.88999938964844\n",
            "episode : 15, timestep : 5942400, average reward : -109.5\n",
            "episode : 13, timestep : 5944800, average reward : -98.41000366210938\n",
            "episode : 16, timestep : 5947200, average reward : -107.86000061035156\n",
            "[5947392] Avg reward (last 50 episodes): -0.04233613982796669\n",
            "episode : 19, timestep : 5949600, average reward : -113.80999755859375\n",
            "episode : 22, timestep : 5952000, average reward : -118.3499984741211\n",
            "episode : 29, timestep : 5954400, average reward : -117.4800033569336\n",
            "[5955584] Avg reward (last 50 episodes): -0.11194346100091934\n",
            "episode : 25, timestep : 5956800, average reward : -118.44000244140625\n",
            "episode : 19, timestep : 5959200, average reward : -113.88999938964844\n",
            "episode : 27, timestep : 5961600, average reward : -116.30000305175781\n",
            "[5963776] Avg reward (last 50 episodes): -2.2640476974099872\n",
            "episode : 27, timestep : 5964000, average reward : -116.16000366210938\n",
            "episode : 28, timestep : 5966400, average reward : -117.41000366210938\n",
            "episode : 25, timestep : 5968800, average reward : -116.1500015258789\n",
            "episode : 28, timestep : 5971200, average reward : -115.5\n",
            "[5971968] Avg reward (last 50 episodes): -2.2502935219556095\n",
            "episode : 30, timestep : 5973600, average reward : -116.94999694824219\n",
            "episode : 15, timestep : 5976000, average reward : -105.62000274658203\n",
            "episode : 25, timestep : 5978400, average reward : -119.94000244140625\n",
            "[5980160] Avg reward (last 50 episodes): -2.2842497300356626\n",
            "episode : 22, timestep : 5980800, average reward : -113.51000213623047\n",
            "episode : 18, timestep : 5983200, average reward : -122.33000183105469\n",
            "episode : 24, timestep : 5985600, average reward : -112.70999908447266\n",
            "episode : 28, timestep : 5988000, average reward : -118.44000244140625\n",
            "[5988352] Avg reward (last 50 episodes): -0.08684244006872177\n",
            "episode : 15, timestep : 5990400, average reward : -108.66999816894531\n",
            "episode : 15, timestep : 5992800, average reward : -107.76000213623047\n",
            "episode : 28, timestep : 5995200, average reward : -118.69999694824219\n",
            "[5996544] Avg reward (last 50 episodes): -0.12029006332159042\n",
            "episode : 23, timestep : 5997600, average reward : -112.8499984741211\n",
            "episode : 18, timestep : 6000000, average reward : -106.88999938964844\n",
            "episode : 11, timestep : 6002400, average reward : -95.16000366210938\n",
            "[6004736] Avg reward (last 50 episodes): -2.260519119091332\n",
            "episode : 22, timestep : 6004800, average reward : -114.55000305175781\n",
            "episode : 20, timestep : 6007200, average reward : -114.56999969482422\n",
            "episode : 28, timestep : 6009600, average reward : -117.44999694824219\n",
            "episode : 21, timestep : 6012000, average reward : -115.13999938964844\n",
            "[6012928] Avg reward (last 50 episodes): -2.2531385306455194\n",
            "setting action_std to  0.5832\n",
            "episode : 26, timestep : 6014400, average reward : -117.94000244140625\n",
            "episode : 23, timestep : 6016800, average reward : -118.37999725341797\n",
            "episode : 19, timestep : 6019200, average reward : -116.58999633789062\n",
            "[6021120] Avg reward (last 50 episodes): -0.1520303189754486\n",
            "episode : 26, timestep : 6021600, average reward : -118.66999816894531\n",
            "episode : 22, timestep : 6024000, average reward : -120.48999786376953\n",
            "episode : 28, timestep : 6026400, average reward : -118.41000366210938\n",
            "episode : 24, timestep : 6028800, average reward : -120.97000122070312\n",
            "[6029312] Avg reward (last 50 episodes): -0.19121108949184418\n",
            "episode : 28, timestep : 6031200, average reward : -119.23999786376953\n",
            "episode : 26, timestep : 6033600, average reward : -118.41000366210938\n",
            "episode : 23, timestep : 6036000, average reward : -121.23999786376953\n",
            "[6037504] Avg reward (last 50 episodes): -2.208685321751982\n",
            "episode : 19, timestep : 6038400, average reward : -117.27999877929688\n",
            "episode : 11, timestep : 6040800, average reward : -109.68000030517578\n",
            "episode : 18, timestep : 6043200, average reward : -114.29000091552734\n",
            "episode : 16, timestep : 6045600, average reward : -112.27999877929688\n",
            "[6045696] Avg reward (last 50 episodes): -2.310221084319055\n",
            "episode : 19, timestep : 6048000, average reward : -118.7300033569336\n",
            "episode : 19, timestep : 6050400, average reward : -116.5\n",
            "episode : 19, timestep : 6052800, average reward : -117.06999969482422\n",
            "[6053888] Avg reward (last 50 episodes): -0.09303279966115952\n",
            "episode : 15, timestep : 6055200, average reward : -119.0\n",
            "episode : 28, timestep : 6057600, average reward : -118.66999816894531\n",
            "episode : 16, timestep : 6060000, average reward : -118.66999816894531\n",
            "[6062080] Avg reward (last 50 episodes): -0.10482124239206314\n",
            "episode : 20, timestep : 6062400, average reward : -121.98999786376953\n",
            "episode : 28, timestep : 6064800, average reward : -118.12999725341797\n",
            "episode : 24, timestep : 6067200, average reward : -119.75\n",
            "episode : 23, timestep : 6069600, average reward : -117.69000244140625\n",
            "[6070272] Avg reward (last 50 episodes): -2.3107435285300015\n",
            "episode : 23, timestep : 6072000, average reward : -116.05999755859375\n",
            "episode : 18, timestep : 6074400, average reward : -125.13999938964844\n",
            "episode : 26, timestep : 6076800, average reward : -119.94999694824219\n",
            "[6078464] Avg reward (last 50 episodes): -0.059691786766052246\n",
            "episode : 20, timestep : 6079200, average reward : -122.5999984741211\n",
            "episode : 21, timestep : 6081600, average reward : -117.23999786376953\n",
            "episode : 20, timestep : 6084000, average reward : -117.43000030517578\n",
            "episode : 24, timestep : 6086400, average reward : -121.91999816894531\n",
            "[6086656] Avg reward (last 50 episodes): -2.141162166260183\n",
            "episode : 20, timestep : 6088800, average reward : -117.38999938964844\n",
            "episode : 21, timestep : 6091200, average reward : -117.02999877929688\n",
            "episode : 21, timestep : 6093600, average reward : -117.1500015258789\n",
            "[6094848] Avg reward (last 50 episodes): -0.07080671191215515\n",
            "episode : 16, timestep : 6096000, average reward : -119.52999877929688\n",
            "episode : 21, timestep : 6098400, average reward : -124.12000274658203\n",
            "episode : 19, timestep : 6100800, average reward : -123.70999908447266\n",
            "[6103040] Avg reward (last 50 episodes): -0.2566779553890228\n",
            "episode : 19, timestep : 6103200, average reward : -124.75\n",
            "episode : 29, timestep : 6105600, average reward : -118.12000274658203\n",
            "episode : 26, timestep : 6108000, average reward : -120.08999633789062\n",
            "episode : 24, timestep : 6110400, average reward : -115.62000274658203\n",
            "[6111232] Avg reward (last 50 episodes): -2.2831797770410778\n",
            "episode : 26, timestep : 6112800, average reward : -118.69999694824219\n",
            "setting action_std to  0.5829\n",
            "episode : 20, timestep : 6115200, average reward : -123.7300033569336\n",
            "episode : 23, timestep : 6117600, average reward : -118.80999755859375\n",
            "[6119424] Avg reward (last 50 episodes): -2.309446180425584\n",
            "episode : 28, timestep : 6120000, average reward : -119.5199966430664\n",
            "episode : 16, timestep : 6122400, average reward : -109.08000183105469\n",
            "episode : 25, timestep : 6124800, average reward : -118.63999938964844\n",
            "episode : 23, timestep : 6127200, average reward : -121.62000274658203\n",
            "[6127616] Avg reward (last 50 episodes): -0.25545334815979004\n",
            "episode : 25, timestep : 6129600, average reward : -119.2300033569336\n",
            "episode : 22, timestep : 6132000, average reward : -121.54000091552734\n",
            "episode : 20, timestep : 6134400, average reward : -115.86000061035156\n",
            "[6135808] Avg reward (last 50 episodes): -2.2482423427700997\n",
            "episode : 25, timestep : 6136800, average reward : -118.75\n",
            "episode : 14, timestep : 6139200, average reward : -107.08000183105469\n",
            "episode : 20, timestep : 6141600, average reward : -113.69999694824219\n",
            "[6144000] Avg reward (last 50 episodes): -0.09318187832832336\n",
            "episode : 19, timestep : 6144000, average reward : -118.76000213623047\n",
            "episode : 24, timestep : 6146400, average reward : -110.22000122070312\n",
            "episode : 25, timestep : 6148800, average reward : -117.31999969482422\n",
            "episode : 19, timestep : 6151200, average reward : -110.7699966430664\n",
            "[6152192] Avg reward (last 50 episodes): -0.16643400490283966\n",
            "episode : 21, timestep : 6153600, average reward : -114.31999969482422\n",
            "episode : 14, timestep : 6156000, average reward : -108.4000015258789\n",
            "episode : 19, timestep : 6158400, average reward : -113.30999755859375\n",
            "[6160384] Avg reward (last 50 episodes): -2.2614485605806114\n",
            "episode : 22, timestep : 6160800, average reward : -119.01000213623047\n",
            "episode : 16, timestep : 6163200, average reward : -107.7300033569336\n",
            "episode : 17, timestep : 6165600, average reward : -113.23999786376953\n",
            "episode : 24, timestep : 6168000, average reward : -114.66000366210938\n",
            "[6168576] Avg reward (last 50 episodes): -0.05675845593214035\n",
            "episode : 10, timestep : 6170400, average reward : -93.91999816894531\n",
            "episode : 5, timestep : 6172800, average reward : -64.41000366210938\n",
            "episode : 10, timestep : 6175200, average reward : -97.43000030517578\n",
            "[6176768] Avg reward (last 50 episodes): -0.2571112811565399\n",
            "episode : 12, timestep : 6177600, average reward : -97.5999984741211\n",
            "episode : 10, timestep : 6180000, average reward : -96.41000366210938\n",
            "episode : 4, timestep : 6182400, average reward : -71.93000030517578\n",
            "episode : 10, timestep : 6184800, average reward : -91.63999938964844\n",
            "[6184960] Avg reward (last 50 episodes): -0.05576806887984276\n",
            "episode : 6, timestep : 6187200, average reward : -85.69000244140625\n",
            "episode : 9, timestep : 6189600, average reward : -98.08000183105469\n",
            "episode : 6, timestep : 6192000, average reward : -73.58000183105469\n",
            "[6193152] Avg reward (last 50 episodes): -0.08577904850244522\n",
            "episode : 6, timestep : 6194400, average reward : -89.31999969482422\n",
            "episode : 10, timestep : 6196800, average reward : -100.05000305175781\n",
            "episode : 7, timestep : 6199200, average reward : -79.25\n",
            "[6201344] Avg reward (last 50 episodes): -0.07311229407787323\n",
            "episode : 4, timestep : 6201600, average reward : -70.75\n",
            "episode : 6, timestep : 6204000, average reward : -75.38999938964844\n",
            "episode : 4, timestep : 6206400, average reward : -59.16999816894531\n",
            "episode : 7, timestep : 6208800, average reward : -97.58999633789062\n",
            "[6209536] Avg reward (last 50 episodes): -0.10546939820051193\n",
            "episode : 5, timestep : 6211200, average reward : -89.75\n",
            "episode : 4, timestep : 6213600, average reward : -62.369998931884766\n",
            "setting action_std to  0.5826\n",
            "episode : 4, timestep : 6216000, average reward : -138.52999877929688\n",
            "[6217728] Avg reward (last 50 episodes): -0.11258911341428757\n",
            "episode : 7, timestep : 6218400, average reward : -98.75\n",
            "episode : 5, timestep : 6220800, average reward : -91.06999969482422\n",
            "episode : 5, timestep : 6223200, average reward : -85.22000122070312\n",
            "episode : 6, timestep : 6225600, average reward : -81.63999938964844\n",
            "[6225920] Avg reward (last 50 episodes): -0.10018614679574966\n",
            "episode : 4, timestep : 6228000, average reward : -85.87000274658203\n",
            "episode : 5, timestep : 6230400, average reward : -110.33000183105469\n",
            "episode : 5, timestep : 6232800, average reward : -73.45999908447266\n",
            "[6234112] Avg reward (last 50 episodes): -0.10159988701343536\n",
            "episode : 5, timestep : 6235200, average reward : -72.29000091552734\n",
            "episode : 4, timestep : 6237600, average reward : -113.72000122070312\n",
            "episode : 6, timestep : 6240000, average reward : -78.61000061035156\n",
            "[6242304] Avg reward (last 50 episodes): -0.1091001033782959\n",
            "episode : 6, timestep : 6242400, average reward : -79.4000015258789\n",
            "episode : 5, timestep : 6244800, average reward : -89.12999725341797\n",
            "episode : 4, timestep : 6247200, average reward : -111.22000122070312\n",
            "episode : 7, timestep : 6249600, average reward : -99.25\n",
            "[6250496] Avg reward (last 50 episodes): -0.10762235522270203\n",
            "episode : 5, timestep : 6252000, average reward : -82.88999938964844\n",
            "episode : 6, timestep : 6254400, average reward : -74.29000091552734\n",
            "episode : 6, timestep : 6256800, average reward : -81.54000091552734\n",
            "[6258688] Avg reward (last 50 episodes): -0.09605976194143295\n",
            "episode : 5, timestep : 6259200, average reward : -96.16999816894531\n",
            "episode : 4, timestep : 6261600, average reward : -63.869998931884766\n",
            "episode : 5, timestep : 6264000, average reward : -91.95999908447266\n",
            "episode : 6, timestep : 6266400, average reward : -80.26000213623047\n",
            "[6266880] Avg reward (last 50 episodes): -0.1134260967373848\n",
            "episode : 5, timestep : 6268800, average reward : -87.94000244140625\n",
            "episode : 6, timestep : 6271200, average reward : -80.37999725341797\n",
            "episode : 7, timestep : 6273600, average reward : -107.13999938964844\n",
            "[6275072] Avg reward (last 50 episodes): -0.07188043743371964\n",
            "episode : 7, timestep : 6276000, average reward : -86.7300033569336\n",
            "episode : 7, timestep : 6278400, average reward : -111.37999725341797\n",
            "episode : 4, timestep : 6280800, average reward : -63.45000076293945\n",
            "episode : 4, timestep : 6283200, average reward : -58.779998779296875\n",
            "[6283264] Avg reward (last 50 episodes): -0.10965079069137573\n",
            "episode : 5, timestep : 6285600, average reward : -93.08000183105469\n",
            "episode : 4, timestep : 6288000, average reward : -62.2400016784668\n",
            "episode : 6, timestep : 6290400, average reward : -78.62000274658203\n",
            "[6291456] Avg reward (last 50 episodes): -0.12281179428100586\n",
            "episode : 4, timestep : 6292800, average reward : -63.130001068115234\n",
            "episode : 7, timestep : 6295200, average reward : -95.76000213623047\n",
            "episode : 4, timestep : 6297600, average reward : -58.790000915527344\n",
            "[6299648] Avg reward (last 50 episodes): -0.1404947191476822\n",
            "episode : 5, timestep : 6300000, average reward : -89.0999984741211\n",
            "episode : 6, timestep : 6302400, average reward : -91.54000091552734\n",
            "episode : 4, timestep : 6304800, average reward : -62.97999954223633\n",
            "episode : 8, timestep : 6307200, average reward : -115.16000366210938\n",
            "[6307840] Avg reward (last 50 episodes): -0.11727837473154068\n",
            "episode : 4, timestep : 6309600, average reward : -89.12000274658203\n",
            "episode : 7, timestep : 6312000, average reward : -92.83000183105469\n",
            "episode : 5, timestep : 6314400, average reward : -73.55000305175781\n",
            "setting action_std to  0.5823\n",
            "[6316032] Avg reward (last 50 episodes): -0.08678589016199112\n",
            "episode : 5, timestep : 6316800, average reward : -71.69000244140625\n",
            "episode : 11, timestep : 6319200, average reward : -121.91999816894531\n",
            "episode : 4, timestep : 6321600, average reward : -85.61000061035156\n",
            "episode : 7, timestep : 6324000, average reward : -93.38999938964844\n",
            "[6324224] Avg reward (last 50 episodes): -0.06321045011281967\n",
            "episode : 4, timestep : 6326400, average reward : -63.41999816894531\n",
            "episode : 4, timestep : 6328800, average reward : -113.75\n",
            "episode : 4, timestep : 6331200, average reward : -87.44000244140625\n",
            "[6332416] Avg reward (last 50 episodes): -0.12068340927362442\n",
            "episode : 5, timestep : 6333600, average reward : -70.66000366210938\n",
            "episode : 8, timestep : 6336000, average reward : -107.19000244140625\n",
            "episode : 7, timestep : 6338400, average reward : -92.94000244140625\n",
            "[6340608] Avg reward (last 50 episodes): -0.09465912729501724\n",
            "episode : 5, timestep : 6340800, average reward : -92.05000305175781\n",
            "episode : 5, timestep : 6343200, average reward : -89.41000366210938\n",
            "episode : 4, timestep : 6345600, average reward : -60.38999938964844\n",
            "episode : 6, timestep : 6348000, average reward : -81.16000366210938\n",
            "[6348800] Avg reward (last 50 episodes): -0.08610191941261292\n",
            "episode : 5, timestep : 6350400, average reward : -71.05999755859375\n",
            "episode : 7, timestep : 6352800, average reward : -101.6500015258789\n",
            "episode : 4, timestep : 6355200, average reward : -61.77000045776367\n",
            "[6356992] Avg reward (last 50 episodes): -0.11398252844810486\n",
            "episode : 5, timestep : 6357600, average reward : -106.7699966430664\n",
            "episode : 7, timestep : 6360000, average reward : -84.26000213623047\n",
            "episode : 6, timestep : 6362400, average reward : -97.44000244140625\n",
            "episode : 6, timestep : 6364800, average reward : -83.33999633789062\n",
            "[6365184] Avg reward (last 50 episodes): -0.10280214250087738\n",
            "episode : 6, timestep : 6367200, average reward : -88.63999938964844\n",
            "episode : 5, timestep : 6369600, average reward : -94.04000091552734\n",
            "episode : 6, timestep : 6372000, average reward : -80.97000122070312\n",
            "[6373376] Avg reward (last 50 episodes): -0.11027348786592484\n",
            "episode : 4, timestep : 6374400, average reward : -61.31999969482422\n",
            "episode : 6, timestep : 6376800, average reward : -79.61000061035156\n",
            "episode : 5, timestep : 6379200, average reward : -82.62000274658203\n",
            "[6381568] Avg reward (last 50 episodes): -0.11308252066373825\n",
            "episode : 7, timestep : 6381600, average reward : -116.27999877929688\n",
            "episode : 6, timestep : 6384000, average reward : -78.43000030517578\n",
            "episode : 5, timestep : 6386400, average reward : -105.44000244140625\n",
            "episode : 9, timestep : 6388800, average reward : -94.0\n",
            "[6389760] Avg reward (last 50 episodes): -0.10981149971485138\n",
            "episode : 5, timestep : 6391200, average reward : -72.37999725341797\n",
            "episode : 5, timestep : 6393600, average reward : -73.9000015258789\n",
            "episode : 6, timestep : 6396000, average reward : -92.0999984741211\n",
            "[6397952] Avg reward (last 50 episodes): -0.09134261310100555\n",
            "episode : 5, timestep : 6398400, average reward : -77.48999786376953\n",
            "episode : 5, timestep : 6400800, average reward : -82.87999725341797\n",
            "episode : 7, timestep : 6403200, average reward : -86.19999694824219\n",
            "episode : 5, timestep : 6405600, average reward : -73.38999938964844\n",
            "[6406144] Avg reward (last 50 episodes): -0.10814875364303589\n",
            "episode : 5, timestep : 6408000, average reward : -90.5199966430664\n",
            "episode : 5, timestep : 6410400, average reward : -88.97000122070312\n",
            "episode : 4, timestep : 6412800, average reward : -64.29000091552734\n",
            "[6414336] Avg reward (last 50 episodes): -0.11319538205862045\n",
            "setting action_std to  0.582\n",
            "episode : 5, timestep : 6415200, average reward : -72.26000213623047\n",
            "episode : 4, timestep : 6417600, average reward : -64.27999877929688\n",
            "episode : 4, timestep : 6420000, average reward : -61.34000015258789\n",
            "episode : 5, timestep : 6422400, average reward : -74.63999938964844\n",
            "[6422528] Avg reward (last 50 episodes): -0.12822283804416656\n",
            "episode : 5, timestep : 6424800, average reward : -73.16999816894531\n",
            "episode : 6, timestep : 6427200, average reward : -96.41000366210938\n",
            "episode : 5, timestep : 6429600, average reward : -84.70999908447266\n",
            "[6430720] Avg reward (last 50 episodes): -0.10209562629461288\n",
            "episode : 4, timestep : 6432000, average reward : -62.27000045776367\n",
            "episode : 4, timestep : 6434400, average reward : -61.290000915527344\n",
            "episode : 7, timestep : 6436800, average reward : -82.04000091552734\n",
            "[6438912] Avg reward (last 50 episodes): -0.12346920371055603\n",
            "episode : 5, timestep : 6439200, average reward : -75.72000122070312\n",
            "episode : 4, timestep : 6441600, average reward : -60.9900016784668\n",
            "episode : 5, timestep : 6444000, average reward : -90.1500015258789\n",
            "episode : 5, timestep : 6446400, average reward : -71.45999908447266\n",
            "[6447104] Avg reward (last 50 episodes): -0.09231709688901901\n",
            "episode : 4, timestep : 6448800, average reward : -63.16999816894531\n",
            "episode : 5, timestep : 6451200, average reward : -71.48999786376953\n",
            "episode : 5, timestep : 6453600, average reward : -75.16000366210938\n",
            "[6455296] Avg reward (last 50 episodes): -0.08538621664047241\n",
            "episode : 4, timestep : 6456000, average reward : -90.87999725341797\n",
            "episode : 5, timestep : 6458400, average reward : -74.16000366210938\n",
            "episode : 4, timestep : 6460800, average reward : -61.90999984741211\n",
            "episode : 4, timestep : 6463200, average reward : -106.08000183105469\n",
            "[6463488] Avg reward (last 50 episodes): -0.1141800805926323\n",
            "episode : 5, timestep : 6465600, average reward : -93.20999908447266\n",
            "episode : 4, timestep : 6468000, average reward : -62.150001525878906\n",
            "episode : 5, timestep : 6470400, average reward : -74.87999725341797\n",
            "[6471680] Avg reward (last 50 episodes): -0.1875389814376831\n",
            "episode : 5, timestep : 6472800, average reward : -97.80999755859375\n",
            "episode : 4, timestep : 6475200, average reward : -76.91999816894531\n",
            "episode : 6, timestep : 6477600, average reward : -80.93000030517578\n",
            "[6479872] Avg reward (last 50 episodes): -0.09247244894504547\n",
            "episode : 5, timestep : 6480000, average reward : -74.29000091552734\n",
            "episode : 6, timestep : 6482400, average reward : -80.70999908447266\n",
            "episode : 4, timestep : 6484800, average reward : -82.91999816894531\n",
            "episode : 5, timestep : 6487200, average reward : -96.23999786376953\n",
            "[6488064] Avg reward (last 50 episodes): -0.07146323472261429\n",
            "episode : 4, timestep : 6489600, average reward : -62.939998626708984\n",
            "episode : 5, timestep : 6492000, average reward : -96.27999877929688\n",
            "episode : 5, timestep : 6494400, average reward : -80.4000015258789\n",
            "[6496256] Avg reward (last 50 episodes): -0.11036214232444763\n",
            "episode : 8, timestep : 6496800, average reward : -92.05000305175781\n",
            "episode : 5, timestep : 6499200, average reward : -90.33999633789062\n",
            "episode : 6, timestep : 6501600, average reward : -81.44999694824219\n",
            "episode : 6, timestep : 6504000, average reward : -96.44000244140625\n",
            "[6504448] Avg reward (last 50 episodes): -0.12556061148643494\n",
            "episode : 6, timestep : 6506400, average reward : -90.31999969482422\n",
            "episode : 5, timestep : 6508800, average reward : -91.33000183105469\n",
            "episode : 4, timestep : 6511200, average reward : -63.70000076293945\n",
            "[6512640] Avg reward (last 50 episodes): -0.11761979013681412\n",
            "episode : 4, timestep : 6513600, average reward : -61.880001068115234\n",
            "setting action_std to  0.5817\n",
            "episode : 4, timestep : 6516000, average reward : -63.7599983215332\n",
            "episode : 6, timestep : 6518400, average reward : -100.26000213623047\n",
            "episode : 4, timestep : 6520800, average reward : -61.45000076293945\n",
            "[6520832] Avg reward (last 50 episodes): -0.08971361070871353\n",
            "episode : 4, timestep : 6523200, average reward : -64.08000183105469\n",
            "episode : 5, timestep : 6525600, average reward : -73.87000274658203\n",
            "episode : 4, timestep : 6528000, average reward : -88.63999938964844\n",
            "[6529024] Avg reward (last 50 episodes): -0.09334614127874374\n",
            "episode : 5, timestep : 6530400, average reward : -73.51000213623047\n",
            "episode : 5, timestep : 6532800, average reward : -69.04000091552734\n",
            "episode : 8, timestep : 6535200, average reward : -95.95999908447266\n",
            "[6537216] Avg reward (last 50 episodes): -0.08087359368801117\n",
            "episode : 7, timestep : 6537600, average reward : -85.0999984741211\n",
            "episode : 6, timestep : 6540000, average reward : -100.37999725341797\n",
            "episode : 10, timestep : 6542400, average reward : -104.33999633789062\n",
            "episode : 7, timestep : 6544800, average reward : -95.61000061035156\n",
            "[6545408] Avg reward (last 50 episodes): -0.28696390986442566\n",
            "episode : 4, timestep : 6547200, average reward : -77.4000015258789\n",
            "episode : 11, timestep : 6549600, average reward : -97.3499984741211\n",
            "episode : 10, timestep : 6552000, average reward : -99.8499984741211\n",
            "[6553600] Avg reward (last 50 episodes): -0.07510547339916229\n",
            "episode : 6, timestep : 6554400, average reward : -87.08000183105469\n",
            "episode : 9, timestep : 6556800, average reward : -99.37999725341797\n",
            "episode : 6, timestep : 6559200, average reward : -92.63999938964844\n",
            "episode : 12, timestep : 6561600, average reward : -99.33000183105469\n",
            "[6561792] Avg reward (last 50 episodes): -0.08004589378833771\n",
            "episode : 6, timestep : 6564000, average reward : -86.77999877929688\n",
            "episode : 7, timestep : 6566400, average reward : -85.29000091552734\n",
            "episode : 9, timestep : 6568800, average reward : -99.0999984741211\n",
            "[6569984] Avg reward (last 50 episodes): -0.07450198382139206\n",
            "episode : 8, timestep : 6571200, average reward : -95.45999908447266\n",
            "episode : 5, timestep : 6573600, average reward : -70.2300033569336\n",
            "episode : 4, timestep : 6576000, average reward : -55.58000183105469\n",
            "[6578176] Avg reward (last 50 episodes): -0.0816061869263649\n",
            "episode : 7, timestep : 6578400, average reward : -94.72000122070312\n",
            "episode : 8, timestep : 6580800, average reward : -88.5199966430664\n",
            "episode : 7, timestep : 6583200, average reward : -93.73999786376953\n",
            "episode : 10, timestep : 6585600, average reward : -98.6500015258789\n",
            "[6586368] Avg reward (last 50 episodes): -0.10115070641040802\n",
            "episode : 6, timestep : 6588000, average reward : -80.54000091552734\n",
            "episode : 5, timestep : 6590400, average reward : -85.2300033569336\n",
            "episode : 11, timestep : 6592800, average reward : -96.87000274658203\n",
            "[6594560] Avg reward (last 50 episodes): -0.10969790816307068\n",
            "episode : 8, timestep : 6595200, average reward : -96.3499984741211\n",
            "episode : 11, timestep : 6597600, average reward : -106.06999969482422\n",
            "episode : 10, timestep : 6600000, average reward : -101.05999755859375\n",
            "episode : 9, timestep : 6602400, average reward : -98.2699966430664\n",
            "[6602752] Avg reward (last 50 episodes): -0.11583906412124634\n",
            "episode : 7, timestep : 6604800, average reward : -94.5\n",
            "episode : 12, timestep : 6607200, average reward : -103.75\n",
            "episode : 8, timestep : 6609600, average reward : -90.12999725341797\n",
            "[6610944] Avg reward (last 50 episodes): -0.07832860946655273\n",
            "episode : 14, timestep : 6612000, average reward : -111.69999694824219\n",
            "episode : 27, timestep : 6614400, average reward : -117.91999816894531\n",
            "setting action_std to  0.5814\n",
            "episode : 26, timestep : 6616800, average reward : -118.58000183105469\n",
            "[6619136] Avg reward (last 50 episodes): -0.09312501549720764\n",
            "episode : 28, timestep : 6619200, average reward : -118.36000061035156\n",
            "episode : 26, timestep : 6621600, average reward : -119.70999908447266\n",
            "episode : 28, timestep : 6624000, average reward : -118.55999755859375\n",
            "episode : 25, timestep : 6626400, average reward : -119.05999755859375\n",
            "[6627328] Avg reward (last 50 episodes): -2.213535443879664\n",
            "episode : 12, timestep : 6628800, average reward : -106.31999969482422\n",
            "episode : 4, timestep : 6631200, average reward : -47.650001525878906\n",
            "episode : 4, timestep : 6633600, average reward : -47.34000015258789\n",
            "[6635520] Avg reward (last 50 episodes): -0.12882165610790253\n",
            "episode : 5, timestep : 6636000, average reward : -59.2599983215332\n",
            "episode : 6, timestep : 6638400, average reward : -68.2300033569336\n",
            "episode : 4, timestep : 6640800, average reward : -47.7400016784668\n",
            "episode : 5, timestep : 6643200, average reward : -73.79000091552734\n",
            "[6643712] Avg reward (last 50 episodes): -0.09788112342357635\n",
            "episode : 4, timestep : 6645600, average reward : -50.279998779296875\n",
            "episode : 4, timestep : 6648000, average reward : -49.400001525878906\n",
            "episode : 4, timestep : 6650400, average reward : -46.86000061035156\n",
            "[6651904] Avg reward (last 50 episodes): -0.068474180996418\n",
            "episode : 4, timestep : 6652800, average reward : -47.45000076293945\n",
            "episode : 5, timestep : 6655200, average reward : -60.189998626708984\n",
            "episode : 5, timestep : 6657600, average reward : -57.95000076293945\n",
            "episode : 5, timestep : 6660000, average reward : -57.79999923706055\n",
            "[6660096] Avg reward (last 50 episodes): -0.03252039849758148\n",
            "episode : 4, timestep : 6662400, average reward : -42.959999084472656\n",
            "episode : 5, timestep : 6664800, average reward : -59.25\n",
            "episode : 6, timestep : 6667200, average reward : -69.33000183105469\n",
            "[6668288] Avg reward (last 50 episodes): -0.0747637152671814\n",
            "episode : 4, timestep : 6669600, average reward : -71.44999694824219\n",
            "episode : 5, timestep : 6672000, average reward : -61.40999984741211\n",
            "episode : 5, timestep : 6674400, average reward : -61.45000076293945\n",
            "[6676480] Avg reward (last 50 episodes): -0.06368070095777512\n",
            "episode : 5, timestep : 6676800, average reward : -61.90999984741211\n",
            "episode : 4, timestep : 6679200, average reward : -46.7400016784668\n",
            "episode : 4, timestep : 6681600, average reward : -45.70000076293945\n",
            "episode : 5, timestep : 6684000, average reward : -60.34000015258789\n",
            "[6684672] Avg reward (last 50 episodes): -0.07739238440990448\n",
            "episode : 5, timestep : 6686400, average reward : -59.95000076293945\n",
            "episode : 4, timestep : 6688800, average reward : -52.439998626708984\n",
            "episode : 4, timestep : 6691200, average reward : -45.54999923706055\n",
            "[6692864] Avg reward (last 50 episodes): -0.09280224144458771\n",
            "episode : 4, timestep : 6693600, average reward : -66.41999816894531\n",
            "episode : 4, timestep : 6696000, average reward : -45.540000915527344\n",
            "episode : 4, timestep : 6698400, average reward : -43.7599983215332\n",
            "episode : 5, timestep : 6700800, average reward : -60.66999816894531\n",
            "[6701056] Avg reward (last 50 episodes): -0.12234668433666229\n",
            "episode : 5, timestep : 6703200, average reward : -61.459999084472656\n",
            "episode : 5, timestep : 6705600, average reward : -61.38999938964844\n",
            "episode : 5, timestep : 6708000, average reward : -63.560001373291016\n",
            "[6709248] Avg reward (last 50 episodes): -0.03891386836767197\n",
            "episode : 4, timestep : 6710400, average reward : -43.459999084472656\n",
            "episode : 5, timestep : 6712800, average reward : -60.2400016784668\n",
            "setting action_std to  0.5811\n",
            "episode : 4, timestep : 6715200, average reward : -44.9900016784668\n",
            "[6717440] Avg reward (last 50 episodes): -0.04364370182156563\n",
            "episode : 4, timestep : 6717600, average reward : -47.75\n",
            "episode : 5, timestep : 6720000, average reward : -63.5\n",
            "episode : 5, timestep : 6722400, average reward : -79.61000061035156\n",
            "episode : 4, timestep : 6724800, average reward : -39.29999923706055\n",
            "[6725632] Avg reward (last 50 episodes): -0.15626531839370728\n",
            "episode : 5, timestep : 6727200, average reward : -57.59000015258789\n",
            "episode : 4, timestep : 6729600, average reward : -45.4900016784668\n",
            "episode : 4, timestep : 6732000, average reward : -48.119998931884766\n",
            "[6733824] Avg reward (last 50 episodes): -0.1164662092924118\n",
            "episode : 5, timestep : 6734400, average reward : -61.459999084472656\n",
            "episode : 6, timestep : 6736800, average reward : -76.7300033569336\n",
            "episode : 5, timestep : 6739200, average reward : -66.5999984741211\n",
            "episode : 5, timestep : 6741600, average reward : -78.8499984741211\n",
            "[6742016] Avg reward (last 50 episodes): -0.08865043520927429\n",
            "episode : 4, timestep : 6744000, average reward : -54.0\n",
            "episode : 6, timestep : 6746400, average reward : -72.43000030517578\n",
            "episode : 4, timestep : 6748800, average reward : -50.2400016784668\n",
            "[6750208] Avg reward (last 50 episodes): -0.0754980519413948\n",
            "episode : 4, timestep : 6751200, average reward : -54.09000015258789\n",
            "episode : 5, timestep : 6753600, average reward : -62.220001220703125\n",
            "episode : 5, timestep : 6756000, average reward : -59.36000061035156\n",
            "[6758400] Avg reward (last 50 episodes): -0.014356404542922974\n",
            "episode : 4, timestep : 6758400, average reward : -45.060001373291016\n",
            "episode : 7, timestep : 6760800, average reward : -85.73999786376953\n",
            "episode : 7, timestep : 6763200, average reward : -89.06999969482422\n",
            "episode : 10, timestep : 6765600, average reward : -109.02999877929688\n",
            "[6766592] Avg reward (last 50 episodes): -0.13410069048404694\n",
            "episode : 7, timestep : 6768000, average reward : -71.79000091552734\n",
            "episode : 7, timestep : 6770400, average reward : -83.37999725341797\n",
            "episode : 4, timestep : 6772800, average reward : -41.029998779296875\n",
            "[6774784] Avg reward (last 50 episodes): -0.06551948189735413\n",
            "episode : 5, timestep : 6775200, average reward : -54.709999084472656\n",
            "episode : 4, timestep : 6777600, average reward : -45.029998779296875\n",
            "episode : 6, timestep : 6780000, average reward : -68.22000122070312\n",
            "episode : 4, timestep : 6782400, average reward : -61.43000030517578\n",
            "[6782976] Avg reward (last 50 episodes): -0.04286402836441994\n",
            "episode : 6, timestep : 6784800, average reward : -69.87999725341797\n",
            "episode : 6, timestep : 6787200, average reward : -88.0\n",
            "episode : 4, timestep : 6789600, average reward : -48.97999954223633\n",
            "[6791168] Avg reward (last 50 episodes): -0.11180873215198517\n",
            "episode : 5, timestep : 6792000, average reward : -71.26000213623047\n",
            "episode : 6, timestep : 6794400, average reward : -71.05000305175781\n",
            "episode : 5, timestep : 6796800, average reward : -60.619998931884766\n",
            "episode : 6, timestep : 6799200, average reward : -65.87000274658203\n",
            "[6799360] Avg reward (last 50 episodes): -0.026870371773838997\n",
            "episode : 8, timestep : 6801600, average reward : -87.5999984741211\n",
            "episode : 6, timestep : 6804000, average reward : -69.4800033569336\n",
            "episode : 6, timestep : 6806400, average reward : -70.98999786376953\n",
            "[6807552] Avg reward (last 50 episodes): -0.08464808762073517\n",
            "episode : 6, timestep : 6808800, average reward : -81.06999969482422\n",
            "episode : 6, timestep : 6811200, average reward : -69.91999816894531\n",
            "episode : 8, timestep : 6813600, average reward : -83.2699966430664\n",
            "setting action_std to  0.5808\n",
            "[6815744] Avg reward (last 50 episodes): -0.03384843096137047\n",
            "episode : 6, timestep : 6816000, average reward : -81.87000274658203\n",
            "episode : 6, timestep : 6818400, average reward : -71.70999908447266\n",
            "episode : 5, timestep : 6820800, average reward : -63.77000045776367\n",
            "episode : 5, timestep : 6823200, average reward : -64.33999633789062\n",
            "[6823936] Avg reward (last 50 episodes): -0.11064192652702332\n",
            "episode : 5, timestep : 6825600, average reward : -66.87000274658203\n",
            "episode : 4, timestep : 6828000, average reward : -45.81999969482422\n",
            "episode : 5, timestep : 6830400, average reward : -74.88999938964844\n",
            "[6832128] Avg reward (last 50 episodes): -0.13282842934131622\n",
            "episode : 4, timestep : 6832800, average reward : -81.52999877929688\n",
            "episode : 5, timestep : 6835200, average reward : -60.08000183105469\n",
            "episode : 6, timestep : 6837600, average reward : -69.41999816894531\n",
            "episode : 5, timestep : 6840000, average reward : -61.81999969482422\n",
            "[6840320] Avg reward (last 50 episodes): -0.03146287798881531\n",
            "episode : 7, timestep : 6842400, average reward : -73.44000244140625\n",
            "episode : 4, timestep : 6844800, average reward : -61.90999984741211\n",
            "episode : 4, timestep : 6847200, average reward : -45.77000045776367\n",
            "[6848512] Avg reward (last 50 episodes): 0.08369177579879761\n",
            "episode : 4, timestep : 6849600, average reward : -67.25\n",
            "episode : 4, timestep : 6852000, average reward : -44.7400016784668\n",
            "episode : 4, timestep : 6854400, average reward : -47.25\n",
            "[6856704] Avg reward (last 50 episodes): -0.09635438770055771\n",
            "episode : 6, timestep : 6856800, average reward : -68.48999786376953\n",
            "episode : 4, timestep : 6859200, average reward : -45.459999084472656\n",
            "episode : 4, timestep : 6861600, average reward : -42.27000045776367\n",
            "episode : 4, timestep : 6864000, average reward : -42.650001525878906\n",
            "[6864896] Avg reward (last 50 episodes): -0.20024724304676056\n",
            "episode : 6, timestep : 6866400, average reward : -71.4800033569336\n",
            "episode : 4, timestep : 6868800, average reward : -44.29999923706055\n",
            "episode : 7, timestep : 6871200, average reward : -72.22000122070312\n",
            "[6873088] Avg reward (last 50 episodes): -0.07333391159772873\n",
            "episode : 4, timestep : 6873600, average reward : -46.7599983215332\n",
            "episode : 4, timestep : 6876000, average reward : -85.06999969482422\n",
            "episode : 5, timestep : 6878400, average reward : -58.41999816894531\n",
            "episode : 4, timestep : 6880800, average reward : -44.459999084472656\n",
            "[6881280] Avg reward (last 50 episodes): -2.105821576770395\n",
            "episode : 6, timestep : 6883200, average reward : -70.88999938964844\n",
            "episode : 5, timestep : 6885600, average reward : -61.599998474121094\n",
            "episode : 6, timestep : 6888000, average reward : -78.76000213623047\n",
            "[6889472] Avg reward (last 50 episodes): -0.10878834128379822\n",
            "episode : 6, timestep : 6890400, average reward : -70.12000274658203\n",
            "episode : 4, timestep : 6892800, average reward : -46.029998779296875\n",
            "episode : 6, timestep : 6895200, average reward : -75.62999725341797\n",
            "episode : 5, timestep : 6897600, average reward : -75.63999938964844\n",
            "[6897664] Avg reward (last 50 episodes): -0.10352195799350739\n",
            "episode : 4, timestep : 6900000, average reward : -68.29000091552734\n",
            "episode : 4, timestep : 6902400, average reward : -43.95000076293945\n",
            "episode : 6, timestep : 6904800, average reward : -71.91000366210938\n",
            "[6905856] Avg reward (last 50 episodes): -0.06155610457062721\n",
            "episode : 4, timestep : 6907200, average reward : -41.06999969482422\n",
            "episode : 5, timestep : 6909600, average reward : -63.720001220703125\n",
            "episode : 5, timestep : 6912000, average reward : -61.220001220703125\n",
            "[6914048] Avg reward (last 50 episodes): -0.14476513862609863\n",
            "episode : 4, timestep : 6914400, average reward : -63.02000045776367\n",
            "setting action_std to  0.5805\n",
            "episode : 5, timestep : 6916800, average reward : -62.41999816894531\n",
            "episode : 4, timestep : 6919200, average reward : -48.650001525878906\n",
            "episode : 4, timestep : 6921600, average reward : -44.369998931884766\n",
            "[6922240] Avg reward (last 50 episodes): -0.17930610477924347\n",
            "episode : 4, timestep : 6924000, average reward : -47.40999984741211\n",
            "episode : 4, timestep : 6926400, average reward : -48.58000183105469\n",
            "episode : 6, timestep : 6928800, average reward : -79.87999725341797\n",
            "[6930432] Avg reward (last 50 episodes): -2.247107975296676\n",
            "episode : 6, timestep : 6931200, average reward : -65.88999938964844\n",
            "episode : 4, timestep : 6933600, average reward : -46.56999969482422\n",
            "episode : 5, timestep : 6936000, average reward : -62.529998779296875\n",
            "episode : 4, timestep : 6938400, average reward : -46.11000061035156\n",
            "[6938624] Avg reward (last 50 episodes): 0.023198461160063744\n",
            "episode : 4, timestep : 6940800, average reward : -59.310001373291016\n",
            "episode : 5, timestep : 6943200, average reward : -58.63999938964844\n",
            "episode : 5, timestep : 6945600, average reward : -60.65999984741211\n",
            "[6946816] Avg reward (last 50 episodes): -0.17573875188827515\n",
            "episode : 5, timestep : 6948000, average reward : -60.0099983215332\n",
            "episode : 5, timestep : 6950400, average reward : -57.58000183105469\n",
            "episode : 5, timestep : 6952800, average reward : -60.459999084472656\n",
            "[6955008] Avg reward (last 50 episodes): -0.01232204120606184\n",
            "episode : 6, timestep : 6955200, average reward : -67.01000213623047\n",
            "episode : 7, timestep : 6957600, average reward : -83.05000305175781\n",
            "episode : 8, timestep : 6960000, average reward : -80.69999694824219\n",
            "episode : 4, timestep : 6962400, average reward : -43.16999816894531\n",
            "[6963200] Avg reward (last 50 episodes): -0.10181242227554321\n",
            "episode : 4, timestep : 6964800, average reward : -44.68000030517578\n",
            "episode : 4, timestep : 6967200, average reward : -60.869998931884766\n",
            "episode : 5, timestep : 6969600, average reward : -59.02000045776367\n",
            "[6971392] Avg reward (last 50 episodes): -0.05056622996926308\n",
            "episode : 4, timestep : 6972000, average reward : -48.099998474121094\n",
            "episode : 5, timestep : 6974400, average reward : -62.380001068115234\n",
            "episode : 4, timestep : 6976800, average reward : -49.060001373291016\n",
            "episode : 4, timestep : 6979200, average reward : -45.4900016784668\n",
            "[6979584] Avg reward (last 50 episodes): -0.09102950990200043\n",
            "episode : 5, timestep : 6981600, average reward : -69.11000061035156\n",
            "episode : 6, timestep : 6984000, average reward : -75.0199966430664\n",
            "episode : 4, timestep : 6986400, average reward : -48.560001373291016\n",
            "[6987776] Avg reward (last 50 episodes): -0.13033932447433472\n",
            "episode : 5, timestep : 6988800, average reward : -68.81999969482422\n",
            "episode : 4, timestep : 6991200, average reward : -84.79000091552734\n",
            "episode : 4, timestep : 6993600, average reward : -59.0099983215332\n",
            "[6995968] Avg reward (last 50 episodes): -0.041649047285318375\n",
            "episode : 4, timestep : 6996000, average reward : -57.650001525878906\n",
            "episode : 4, timestep : 6998400, average reward : -55.06999969482422\n",
            "episode : 4, timestep : 7000800, average reward : -84.45999908447266\n",
            "episode : 4, timestep : 7003200, average reward : -52.279998779296875\n",
            "[7004160] Avg reward (last 50 episodes): -0.10319271683692932\n",
            "episode : 4, timestep : 7005600, average reward : -52.61000061035156\n",
            "episode : 4, timestep : 7008000, average reward : -52.06999969482422\n",
            "episode : 4, timestep : 7010400, average reward : -50.310001373291016\n",
            "[7012352] Avg reward (last 50 episodes): -0.030426936224102974\n",
            "episode : 4, timestep : 7012800, average reward : -53.2400016784668\n",
            "episode : 6, timestep : 7015200, average reward : -85.31999969482422\n",
            "setting action_std to  0.5802\n",
            "episode : 5, timestep : 7017600, average reward : -83.58999633789062\n",
            "episode : 7, timestep : 7020000, average reward : -91.98999786376953\n",
            "[7020544] Avg reward (last 50 episodes): -0.10854517668485641\n",
            "episode : 5, timestep : 7022400, average reward : -60.119998931884766\n",
            "episode : 4, timestep : 7024800, average reward : -67.4800033569336\n",
            "episode : 4, timestep : 7027200, average reward : -47.59000015258789\n",
            "[7028736] Avg reward (last 50 episodes): -0.1125674843788147\n",
            "episode : 4, timestep : 7029600, average reward : -42.79999923706055\n",
            "episode : 4, timestep : 7032000, average reward : -42.709999084472656\n",
            "episode : 5, timestep : 7034400, average reward : -58.0\n",
            "episode : 4, timestep : 7036800, average reward : -50.130001068115234\n",
            "[7036928] Avg reward (last 50 episodes): -0.11672063171863556\n",
            "episode : 4, timestep : 7039200, average reward : -45.459999084472656\n",
            "episode : 4, timestep : 7041600, average reward : -48.66999816894531\n",
            "episode : 6, timestep : 7044000, average reward : -80.30000305175781\n",
            "[7045120] Avg reward (last 50 episodes): -0.08424563705921173\n",
            "episode : 4, timestep : 7046400, average reward : -69.12999725341797\n",
            "episode : 4, timestep : 7048800, average reward : -51.4900016784668\n",
            "episode : 4, timestep : 7051200, average reward : -55.31999969482422\n",
            "[7053312] Avg reward (last 50 episodes): -0.0671178475022316\n",
            "episode : 4, timestep : 7053600, average reward : -52.43000030517578\n",
            "episode : 4, timestep : 7056000, average reward : -47.650001525878906\n",
            "episode : 4, timestep : 7058400, average reward : -52.52000045776367\n",
            "episode : 4, timestep : 7060800, average reward : -45.97999954223633\n",
            "[7061504] Avg reward (last 50 episodes): -0.0882733166217804\n",
            "episode : 4, timestep : 7063200, average reward : -46.88999938964844\n",
            "episode : 4, timestep : 7065600, average reward : -46.209999084472656\n",
            "episode : 4, timestep : 7068000, average reward : -47.40999984741211\n",
            "[7069696] Avg reward (last 50 episodes): -0.1447206437587738\n",
            "episode : 4, timestep : 7070400, average reward : -42.70000076293945\n",
            "episode : 5, timestep : 7072800, average reward : -77.02999877929688\n",
            "episode : 4, timestep : 7075200, average reward : -43.65999984741211\n",
            "episode : 4, timestep : 7077600, average reward : -37.779998779296875\n",
            "[7077888] Avg reward (last 50 episodes): -0.13144218921661377\n",
            "episode : 4, timestep : 7080000, average reward : -42.20000076293945\n",
            "episode : 4, timestep : 7082400, average reward : -42.459999084472656\n",
            "episode : 4, timestep : 7084800, average reward : -37.72999954223633\n",
            "[7086080] Avg reward (last 50 episodes): -0.04130370169878006\n",
            "episode : 4, timestep : 7087200, average reward : -36.029998779296875\n",
            "episode : 5, timestep : 7089600, average reward : -55.150001525878906\n",
            "episode : 4, timestep : 7092000, average reward : -39.119998931884766\n",
            "[7094272] Avg reward (last 50 episodes): 0.018479466438293457\n",
            "episode : 5, timestep : 7094400, average reward : -48.95000076293945\n",
            "episode : 5, timestep : 7096800, average reward : -50.7400016784668\n",
            "episode : 5, timestep : 7099200, average reward : -50.43000030517578\n",
            "episode : 4, timestep : 7101600, average reward : -56.119998931884766\n",
            "[7102464] Avg reward (last 50 episodes): -0.02169112116098404\n",
            "episode : 4, timestep : 7104000, average reward : -32.86000061035156\n",
            "episode : 4, timestep : 7106400, average reward : -32.2599983215332\n",
            "episode : 6, timestep : 7108800, average reward : -60.099998474121094\n",
            "[7110656] Avg reward (last 50 episodes): 0.018214654177427292\n",
            "episode : 4, timestep : 7111200, average reward : -56.20000076293945\n",
            "episode : 4, timestep : 7113600, average reward : -42.06999969482422\n",
            "episode : 4, timestep : 7116000, average reward : -38.45000076293945\n",
            "setting action_std to  0.5799\n",
            "episode : 4, timestep : 7118400, average reward : -39.70000076293945\n",
            "[7118848] Avg reward (last 50 episodes): -0.02924867905676365\n",
            "episode : 5, timestep : 7120800, average reward : -54.470001220703125\n",
            "episode : 4, timestep : 7123200, average reward : -41.70000076293945\n",
            "episode : 4, timestep : 7125600, average reward : -39.97999954223633\n",
            "[7127040] Avg reward (last 50 episodes): -0.07070856541395187\n",
            "episode : 4, timestep : 7128000, average reward : -42.349998474121094\n",
            "episode : 4, timestep : 7130400, average reward : -52.540000915527344\n",
            "episode : 4, timestep : 7132800, average reward : -38.88999938964844\n",
            "episode : 4, timestep : 7135200, average reward : -39.04999923706055\n",
            "[7135232] Avg reward (last 50 episodes): -0.09459954500198364\n",
            "episode : 4, timestep : 7137600, average reward : -41.290000915527344\n",
            "episode : 4, timestep : 7140000, average reward : -47.36000061035156\n",
            "episode : 6, timestep : 7142400, average reward : -62.220001220703125\n",
            "[7143424] Avg reward (last 50 episodes): 0.05666870251297951\n",
            "episode : 4, timestep : 7144800, average reward : -40.599998474121094\n",
            "episode : 4, timestep : 7147200, average reward : -48.31999969482422\n",
            "episode : 4, timestep : 7149600, average reward : -44.7599983215332\n",
            "[7151616] Avg reward (last 50 episodes): -0.04923464357852936\n",
            "episode : 5, timestep : 7152000, average reward : -53.58000183105469\n",
            "episode : 4, timestep : 7154400, average reward : -42.77000045776367\n",
            "episode : 4, timestep : 7156800, average reward : -46.52000045776367\n",
            "episode : 4, timestep : 7159200, average reward : -61.43000030517578\n",
            "[7159808] Avg reward (last 50 episodes): -0.07246885448694229\n",
            "episode : 4, timestep : 7161600, average reward : -50.459999084472656\n",
            "episode : 4, timestep : 7164000, average reward : -38.599998474121094\n",
            "episode : 4, timestep : 7166400, average reward : -40.11000061035156\n",
            "[7168000] Avg reward (last 50 episodes): -0.13174402713775635\n",
            "episode : 4, timestep : 7168800, average reward : -43.970001220703125\n",
            "episode : 4, timestep : 7171200, average reward : -45.58000183105469\n",
            "episode : 4, timestep : 7173600, average reward : -46.869998931884766\n",
            "episode : 4, timestep : 7176000, average reward : -47.400001525878906\n",
            "[7176192] Avg reward (last 50 episodes): -0.11481904238462448\n",
            "episode : 4, timestep : 7178400, average reward : -50.470001220703125\n",
            "episode : 5, timestep : 7180800, average reward : -62.18000030517578\n",
            "episode : 4, timestep : 7183200, average reward : -51.880001068115234\n",
            "[7184384] Avg reward (last 50 episodes): 0.09002024680376053\n",
            "episode : 5, timestep : 7185600, average reward : -58.59000015258789\n",
            "episode : 6, timestep : 7188000, average reward : -90.4000015258789\n",
            "episode : 5, timestep : 7190400, average reward : -77.94999694824219\n",
            "[7192576] Avg reward (last 50 episodes): -0.03542265668511391\n",
            "episode : 5, timestep : 7192800, average reward : -65.5199966430664\n",
            "episode : 4, timestep : 7195200, average reward : -45.790000915527344\n",
            "episode : 7, timestep : 7197600, average reward : -119.88999938964844\n",
            "episode : 4, timestep : 7200000, average reward : -72.55000305175781\n",
            "[7200768] Avg reward (last 50 episodes): -0.05872568488121033\n",
            "episode : 5, timestep : 7202400, average reward : -60.2599983215332\n",
            "episode : 4, timestep : 7204800, average reward : -42.939998626708984\n",
            "episode : 4, timestep : 7207200, average reward : -50.689998626708984\n",
            "[7208960] Avg reward (last 50 episodes): -0.0957881361246109\n",
            "episode : 4, timestep : 7209600, average reward : -50.38999938964844\n",
            "episode : 4, timestep : 7212000, average reward : -45.4900016784668\n",
            "episode : 4, timestep : 7214400, average reward : -41.4900016784668\n",
            "episode : 4, timestep : 7216800, average reward : -62.59000015258789\n",
            "setting action_std to  0.5796\n",
            "[7217152] Avg reward (last 50 episodes): -0.05806511268019676\n",
            "episode : 4, timestep : 7219200, average reward : -45.810001373291016\n",
            "episode : 5, timestep : 7221600, average reward : -53.540000915527344\n",
            "episode : 5, timestep : 7224000, average reward : -62.63999938964844\n",
            "[7225344] Avg reward (last 50 episodes): -0.017901837825775146\n",
            "episode : 5, timestep : 7226400, average reward : -53.540000915527344\n",
            "episode : 4, timestep : 7228800, average reward : -37.099998474121094\n",
            "episode : 4, timestep : 7231200, average reward : -41.86000061035156\n",
            "[7233536] Avg reward (last 50 episodes): -0.01954936794936657\n",
            "episode : 4, timestep : 7233600, average reward : -40.02000045776367\n",
            "episode : 4, timestep : 7236000, average reward : -69.54000091552734\n",
            "episode : 5, timestep : 7238400, average reward : -74.12000274658203\n",
            "episode : 8, timestep : 7240800, average reward : -93.51000213623047\n",
            "[7241728] Avg reward (last 50 episodes): 0.06977193802595139\n",
            "episode : 4, timestep : 7243200, average reward : -43.310001373291016\n",
            "episode : 5, timestep : 7245600, average reward : -58.70000076293945\n",
            "episode : 4, timestep : 7248000, average reward : -41.939998626708984\n",
            "[7249920] Avg reward (last 50 episodes): -0.1739838570356369\n",
            "episode : 5, timestep : 7250400, average reward : -54.869998931884766\n",
            "episode : 4, timestep : 7252800, average reward : -43.380001068115234\n",
            "episode : 4, timestep : 7255200, average reward : -43.709999084472656\n",
            "episode : 5, timestep : 7257600, average reward : -59.81999969482422\n",
            "[7258112] Avg reward (last 50 episodes): -0.12218955904245377\n",
            "episode : 5, timestep : 7260000, average reward : -62.04999923706055\n",
            "episode : 4, timestep : 7262400, average reward : -39.970001220703125\n",
            "episode : 4, timestep : 7264800, average reward : -45.939998626708984\n",
            "[7266304] Avg reward (last 50 episodes): 0.004285134840756655\n",
            "episode : 4, timestep : 7267200, average reward : -94.62999725341797\n",
            "episode : 4, timestep : 7269600, average reward : -43.970001220703125\n",
            "episode : 5, timestep : 7272000, average reward : -82.13999938964844\n",
            "episode : 7, timestep : 7274400, average reward : -96.19999694824219\n",
            "[7274496] Avg reward (last 50 episodes): -0.1133284643292427\n",
            "episode : 6, timestep : 7276800, average reward : -93.9000015258789\n",
            "episode : 6, timestep : 7279200, average reward : -92.27999877929688\n",
            "episode : 4, timestep : 7281600, average reward : -65.5\n",
            "[7282688] Avg reward (last 50 episodes): -0.09681021422147751\n",
            "episode : 7, timestep : 7284000, average reward : -83.80000305175781\n",
            "episode : 6, timestep : 7286400, average reward : -87.94999694824219\n",
            "episode : 4, timestep : 7288800, average reward : -79.87999725341797\n",
            "[7290880] Avg reward (last 50 episodes): -0.1421806365251541\n",
            "episode : 4, timestep : 7291200, average reward : -49.33000183105469\n",
            "episode : 5, timestep : 7293600, average reward : -62.90999984741211\n",
            "episode : 4, timestep : 7296000, average reward : -48.619998931884766\n",
            "episode : 5, timestep : 7298400, average reward : -63.689998626708984\n",
            "[7299072] Avg reward (last 50 episodes): -0.03863447904586792\n",
            "episode : 4, timestep : 7300800, average reward : -46.27000045776367\n",
            "episode : 4, timestep : 7303200, average reward : -67.68000030517578\n",
            "episode : 4, timestep : 7305600, average reward : -75.91999816894531\n",
            "[7307264] Avg reward (last 50 episodes): -0.03941696509718895\n",
            "episode : 5, timestep : 7308000, average reward : -65.37999725341797\n",
            "episode : 4, timestep : 7310400, average reward : -43.22999954223633\n",
            "episode : 4, timestep : 7312800, average reward : -62.810001373291016\n",
            "episode : 4, timestep : 7315200, average reward : -65.33000183105469\n",
            "[7315456] Avg reward (last 50 episodes): -0.23723450303077698\n",
            "setting action_std to  0.5793\n",
            "episode : 6, timestep : 7317600, average reward : -70.5\n",
            "episode : 4, timestep : 7320000, average reward : -67.2699966430664\n",
            "episode : 4, timestep : 7322400, average reward : -45.52000045776367\n",
            "[7323648] Avg reward (last 50 episodes): -0.1075015738606453\n",
            "episode : 4, timestep : 7324800, average reward : -48.91999816894531\n",
            "episode : 4, timestep : 7327200, average reward : -44.16999816894531\n",
            "episode : 6, timestep : 7329600, average reward : -70.2300033569336\n",
            "[7331840] Avg reward (last 50 episodes): -0.04707628861069679\n",
            "episode : 4, timestep : 7332000, average reward : -47.459999084472656\n",
            "episode : 5, timestep : 7334400, average reward : -71.7699966430664\n",
            "episode : 4, timestep : 7336800, average reward : -43.880001068115234\n",
            "episode : 4, timestep : 7339200, average reward : -44.939998626708984\n",
            "[7340032] Avg reward (last 50 episodes): -0.16981378197669983\n",
            "episode : 5, timestep : 7341600, average reward : -58.349998474121094\n",
            "episode : 4, timestep : 7344000, average reward : -50.779998779296875\n",
            "episode : 7, timestep : 7346400, average reward : -78.43000030517578\n",
            "[7348224] Avg reward (last 50 episodes): -0.08725462853908539\n",
            "episode : 5, timestep : 7348800, average reward : -56.54999923706055\n",
            "episode : 4, timestep : 7351200, average reward : -46.099998474121094\n",
            "episode : 5, timestep : 7353600, average reward : -85.62999725341797\n",
            "episode : 4, timestep : 7356000, average reward : -71.66000366210938\n",
            "[7356416] Avg reward (last 50 episodes): -0.02573336660861969\n",
            "episode : 4, timestep : 7358400, average reward : -41.9900016784668\n",
            "episode : 4, timestep : 7360800, average reward : -45.33000183105469\n",
            "episode : 4, timestep : 7363200, average reward : -50.880001068115234\n",
            "[7364608] Avg reward (last 50 episodes): -0.09978131949901581\n",
            "episode : 4, timestep : 7365600, average reward : -42.220001220703125\n",
            "episode : 5, timestep : 7368000, average reward : -55.13999938964844\n",
            "episode : 6, timestep : 7370400, average reward : -70.5\n",
            "[7372800] Avg reward (last 50 episodes): 0.0014176961267367005\n",
            "episode : 6, timestep : 7372800, average reward : -84.44000244140625\n",
            "episode : 4, timestep : 7375200, average reward : -44.790000915527344\n",
            "episode : 5, timestep : 7377600, average reward : -60.58000183105469\n",
            "episode : 4, timestep : 7380000, average reward : -42.38999938964844\n",
            "[7380992] Avg reward (last 50 episodes): -0.17405132949352264\n",
            "episode : 4, timestep : 7382400, average reward : -62.11000061035156\n",
            "episode : 4, timestep : 7384800, average reward : -47.630001068115234\n",
            "episode : 4, timestep : 7387200, average reward : -35.20000076293945\n",
            "[7389184] Avg reward (last 50 episodes): -0.11810874193906784\n",
            "episode : 5, timestep : 7389600, average reward : -59.93000030517578\n",
            "episode : 4, timestep : 7392000, average reward : -56.31999969482422\n",
            "episode : 4, timestep : 7394400, average reward : -40.470001220703125\n",
            "episode : 4, timestep : 7396800, average reward : -45.81999969482422\n",
            "[7397376] Avg reward (last 50 episodes): -0.004457323346287012\n",
            "episode : 4, timestep : 7399200, average reward : -46.709999084472656\n",
            "episode : 5, timestep : 7401600, average reward : -57.29999923706055\n",
            "episode : 4, timestep : 7404000, average reward : -43.439998626708984\n",
            "[7405568] Avg reward (last 50 episodes): -0.05507916584610939\n",
            "episode : 4, timestep : 7406400, average reward : -50.880001068115234\n",
            "episode : 5, timestep : 7408800, average reward : -76.55000305175781\n",
            "episode : 5, timestep : 7411200, average reward : -59.33000183105469\n",
            "episode : 4, timestep : 7413600, average reward : -47.720001220703125\n",
            "[7413760] Avg reward (last 50 episodes): -0.1513248234987259\n",
            "episode : 4, timestep : 7416000, average reward : -44.47999954223633\n",
            "setting action_std to  0.579\n",
            "episode : 4, timestep : 7418400, average reward : -40.369998931884766\n",
            "episode : 4, timestep : 7420800, average reward : -46.43000030517578\n",
            "[7421952] Avg reward (last 50 episodes): -0.08811711519956589\n",
            "episode : 5, timestep : 7423200, average reward : -60.9900016784668\n",
            "episode : 4, timestep : 7425600, average reward : -60.970001220703125\n",
            "episode : 6, timestep : 7428000, average reward : -67.36000061035156\n",
            "[7430144] Avg reward (last 50 episodes): -0.00939952116459608\n",
            "episode : 6, timestep : 7430400, average reward : -64.7699966430664\n",
            "episode : 4, timestep : 7432800, average reward : -58.36000061035156\n",
            "episode : 4, timestep : 7435200, average reward : -43.45000076293945\n",
            "episode : 5, timestep : 7437600, average reward : -73.66999816894531\n",
            "[7438336] Avg reward (last 50 episodes): -0.056722525507211685\n",
            "episode : 4, timestep : 7440000, average reward : -43.5\n",
            "episode : 4, timestep : 7442400, average reward : -39.18000030517578\n",
            "episode : 4, timestep : 7444800, average reward : -43.540000915527344\n",
            "[7446528] Avg reward (last 50 episodes): -0.10861057043075562\n",
            "episode : 4, timestep : 7447200, average reward : -38.79999923706055\n",
            "episode : 4, timestep : 7449600, average reward : -57.86000061035156\n",
            "episode : 4, timestep : 7452000, average reward : -37.9900016784668\n",
            "episode : 4, timestep : 7454400, average reward : -35.369998931884766\n",
            "[7454720] Avg reward (last 50 episodes): 0.050660375505685806\n",
            "episode : 6, timestep : 7456800, average reward : -61.540000915527344\n",
            "episode : 4, timestep : 7459200, average reward : -45.119998931884766\n",
            "episode : 4, timestep : 7461600, average reward : -42.2599983215332\n",
            "[7462912] Avg reward (last 50 episodes): -0.06178603693842888\n",
            "episode : 4, timestep : 7464000, average reward : -61.84000015258789\n",
            "episode : 4, timestep : 7466400, average reward : -40.95000076293945\n",
            "episode : 4, timestep : 7468800, average reward : -63.689998626708984\n",
            "[7471104] Avg reward (last 50 episodes): -0.13769549131393433\n",
            "episode : 4, timestep : 7471200, average reward : -42.599998474121094\n",
            "episode : 5, timestep : 7473600, average reward : -56.7599983215332\n",
            "episode : 4, timestep : 7476000, average reward : -44.02000045776367\n",
            "episode : 4, timestep : 7478400, average reward : -64.83999633789062\n",
            "[7479296] Avg reward (last 50 episodes): -0.08239402621984482\n",
            "episode : 4, timestep : 7480800, average reward : -38.279998779296875\n",
            "episode : 4, timestep : 7483200, average reward : -41.27000045776367\n",
            "episode : 5, timestep : 7485600, average reward : -52.33000183105469\n",
            "[7487488] Avg reward (last 50 episodes): -0.06809208542108536\n",
            "episode : 5, timestep : 7488000, average reward : -71.58000183105469\n",
            "episode : 5, timestep : 7490400, average reward : -60.619998931884766\n",
            "episode : 4, timestep : 7492800, average reward : -58.41999816894531\n",
            "episode : 5, timestep : 7495200, average reward : -77.29000091552734\n",
            "[7495680] Avg reward (last 50 episodes): 0.013889838010072708\n",
            "episode : 5, timestep : 7497600, average reward : -57.09000015258789\n",
            "episode : 4, timestep : 7500000, average reward : -41.88999938964844\n",
            "episode : 4, timestep : 7502400, average reward : -37.79999923706055\n",
            "[7503872] Avg reward (last 50 episodes): -0.1614292711019516\n",
            "episode : 6, timestep : 7504800, average reward : -67.98999786376953\n",
            "episode : 4, timestep : 7507200, average reward : -42.58000183105469\n",
            "episode : 4, timestep : 7509600, average reward : -42.790000915527344\n",
            "episode : 4, timestep : 7512000, average reward : -39.16999816894531\n",
            "[7512064] Avg reward (last 50 episodes): -0.16999314725399017\n",
            "episode : 4, timestep : 7514400, average reward : -38.709999084472656\n",
            "episode : 4, timestep : 7516800, average reward : -41.47999954223633\n",
            "setting action_std to  0.5787\n",
            "episode : 4, timestep : 7519200, average reward : -39.970001220703125\n",
            "[7520256] Avg reward (last 50 episodes): -0.04161215201020241\n",
            "episode : 5, timestep : 7521600, average reward : -55.58000183105469\n",
            "episode : 4, timestep : 7524000, average reward : -67.1500015258789\n",
            "episode : 5, timestep : 7526400, average reward : -54.619998931884766\n",
            "[7528448] Avg reward (last 50 episodes): -0.0863109901547432\n",
            "episode : 4, timestep : 7528800, average reward : -37.560001373291016\n",
            "episode : 5, timestep : 7531200, average reward : -58.45000076293945\n",
            "episode : 4, timestep : 7533600, average reward : -47.54999923706055\n",
            "episode : 5, timestep : 7536000, average reward : -57.959999084472656\n",
            "[7536640] Avg reward (last 50 episodes): -0.03780587017536163\n",
            "episode : 6, timestep : 7538400, average reward : -82.76000213623047\n",
            "episode : 4, timestep : 7540800, average reward : -39.77000045776367\n",
            "episode : 5, timestep : 7543200, average reward : -57.93000030517578\n",
            "[7544832] Avg reward (last 50 episodes): -0.029691476374864578\n",
            "episode : 6, timestep : 7545600, average reward : -69.48999786376953\n",
            "episode : 4, timestep : 7548000, average reward : -48.5\n",
            "episode : 5, timestep : 7550400, average reward : -81.91999816894531\n",
            "episode : 5, timestep : 7552800, average reward : -103.22000122070312\n",
            "[7553024] Avg reward (last 50 episodes): -0.038941897451877594\n",
            "episode : 6, timestep : 7555200, average reward : -69.44999694824219\n",
            "episode : 6, timestep : 7557600, average reward : -82.95999908447266\n",
            "episode : 6, timestep : 7560000, average reward : -85.68000030517578\n",
            "[7561216] Avg reward (last 50 episodes): -0.04934142529964447\n",
            "episode : 7, timestep : 7562400, average reward : -73.68000030517578\n",
            "episode : 5, timestep : 7564800, average reward : -58.970001220703125\n",
            "episode : 4, timestep : 7567200, average reward : -43.0\n",
            "[7569408] Avg reward (last 50 episodes): -0.19595474004745483\n",
            "episode : 4, timestep : 7569600, average reward : -39.29999923706055\n",
            "episode : 4, timestep : 7572000, average reward : -38.29999923706055\n",
            "episode : 5, timestep : 7574400, average reward : -60.439998626708984\n",
            "episode : 4, timestep : 7576800, average reward : -43.77000045776367\n",
            "[7577600] Avg reward (last 50 episodes): -0.008931644260883331\n",
            "episode : 4, timestep : 7579200, average reward : -47.20000076293945\n",
            "episode : 5, timestep : 7581600, average reward : -60.13999938964844\n",
            "episode : 4, timestep : 7584000, average reward : -44.16999816894531\n",
            "[7585792] Avg reward (last 50 episodes): -0.17033319175243378\n",
            "episode : 4, timestep : 7586400, average reward : -39.56999969482422\n",
            "episode : 4, timestep : 7588800, average reward : -46.13999938964844\n",
            "episode : 4, timestep : 7591200, average reward : -63.91999816894531\n",
            "episode : 5, timestep : 7593600, average reward : -59.5\n",
            "[7593984] Avg reward (last 50 episodes): -2.2758339931070806\n",
            "episode : 5, timestep : 7596000, average reward : -62.38999938964844\n",
            "episode : 5, timestep : 7598400, average reward : -57.43000030517578\n",
            "episode : 4, timestep : 7600800, average reward : -44.04999923706055\n",
            "[7602176] Avg reward (last 50 episodes): -0.09626790881156921\n",
            "episode : 4, timestep : 7603200, average reward : -43.08000183105469\n",
            "episode : 4, timestep : 7605600, average reward : -52.97999954223633\n",
            "episode : 4, timestep : 7608000, average reward : -40.849998474121094\n",
            "[7610368] Avg reward (last 50 episodes): -0.00040201604133471847\n",
            "episode : 6, timestep : 7610400, average reward : -69.47000122070312\n",
            "episode : 5, timestep : 7612800, average reward : -75.12000274658203\n",
            "episode : 4, timestep : 7615200, average reward : -43.119998931884766\n",
            "episode : 5, timestep : 7617600, average reward : -59.95000076293945\n",
            "setting action_std to  0.5784\n",
            "[7618560] Avg reward (last 50 episodes): -0.14010348916053772\n",
            "episode : 4, timestep : 7620000, average reward : -44.369998931884766\n",
            "episode : 4, timestep : 7622400, average reward : -41.84000015258789\n",
            "episode : 4, timestep : 7624800, average reward : -46.18000030517578\n",
            "[7626752] Avg reward (last 50 episodes): -0.03696705028414726\n",
            "episode : 5, timestep : 7627200, average reward : -63.150001525878906\n",
            "episode : 5, timestep : 7629600, average reward : -63.20000076293945\n",
            "episode : 4, timestep : 7632000, average reward : -44.65999984741211\n",
            "episode : 4, timestep : 7634400, average reward : -45.630001068115234\n",
            "[7634944] Avg reward (last 50 episodes): -0.19862967729568481\n",
            "episode : 4, timestep : 7636800, average reward : -47.560001373291016\n",
            "episode : 4, timestep : 7639200, average reward : -46.279998779296875\n",
            "episode : 4, timestep : 7641600, average reward : -44.119998931884766\n",
            "[7643136] Avg reward (last 50 episodes): -0.056414246559143066\n",
            "episode : 4, timestep : 7644000, average reward : -46.720001220703125\n",
            "episode : 4, timestep : 7646400, average reward : -48.91999816894531\n",
            "episode : 4, timestep : 7648800, average reward : -47.40999984741211\n",
            "episode : 4, timestep : 7651200, average reward : -49.310001373291016\n",
            "[7651328] Avg reward (last 50 episodes): -0.09154781699180603\n",
            "episode : 4, timestep : 7653600, average reward : -47.099998474121094\n",
            "episode : 4, timestep : 7656000, average reward : -49.13999938964844\n",
            "episode : 4, timestep : 7658400, average reward : -45.72999954223633\n",
            "[7659520] Avg reward (last 50 episodes): -0.11396533995866776\n",
            "episode : 4, timestep : 7660800, average reward : -48.279998779296875\n",
            "episode : 4, timestep : 7663200, average reward : -47.40999984741211\n",
            "episode : 4, timestep : 7665600, average reward : -46.4900016784668\n",
            "[7667712] Avg reward (last 50 episodes): -0.06889206171035767\n",
            "episode : 4, timestep : 7668000, average reward : -47.36000061035156\n",
            "episode : 4, timestep : 7670400, average reward : -44.02000045776367\n",
            "episode : 4, timestep : 7672800, average reward : -40.93000030517578\n",
            "episode : 4, timestep : 7675200, average reward : -45.36000061035156\n",
            "[7675904] Avg reward (last 50 episodes): -0.06428976356983185\n",
            "episode : 4, timestep : 7677600, average reward : -46.849998474121094\n",
            "episode : 4, timestep : 7680000, average reward : -48.709999084472656\n",
            "episode : 5, timestep : 7682400, average reward : -63.77000045776367\n",
            "[7684096] Avg reward (last 50 episodes): -0.09234826266765594\n",
            "episode : 4, timestep : 7684800, average reward : -56.41999816894531\n",
            "episode : 4, timestep : 7687200, average reward : -55.58000183105469\n",
            "episode : 4, timestep : 7689600, average reward : -53.59000015258789\n",
            "episode : 4, timestep : 7692000, average reward : -53.40999984741211\n",
            "[7692288] Avg reward (last 50 episodes): -0.1764020472764969\n",
            "episode : 4, timestep : 7694400, average reward : -53.75\n",
            "episode : 4, timestep : 7696800, average reward : -54.0099983215332\n",
            "episode : 4, timestep : 7699200, average reward : -52.16999816894531\n",
            "[7700480] Avg reward (last 50 episodes): -0.06093275919556618\n",
            "episode : 4, timestep : 7701600, average reward : -74.41000366210938\n",
            "episode : 4, timestep : 7704000, average reward : -70.4000015258789\n",
            "episode : 4, timestep : 7706400, average reward : -53.47999954223633\n",
            "[7708672] Avg reward (last 50 episodes): -0.06306078284978867\n",
            "episode : 4, timestep : 7708800, average reward : -52.52000045776367\n",
            "episode : 5, timestep : 7711200, average reward : -67.02999877929688\n",
            "episode : 4, timestep : 7713600, average reward : -75.91000366210938\n",
            "episode : 5, timestep : 7716000, average reward : -90.94000244140625\n",
            "[7716864] Avg reward (last 50 episodes): -0.0713890790939331\n",
            "episode : 4, timestep : 7718400, average reward : -49.5099983215332\n",
            "setting action_std to  0.5781\n",
            "episode : 4, timestep : 7720800, average reward : -48.7599983215332\n",
            "episode : 4, timestep : 7723200, average reward : -47.11000061035156\n",
            "[7725056] Avg reward (last 50 episodes): -0.19714608788490295\n",
            "episode : 4, timestep : 7725600, average reward : -47.970001220703125\n",
            "episode : 5, timestep : 7728000, average reward : -65.13999938964844\n",
            "episode : 4, timestep : 7730400, average reward : -47.279998779296875\n",
            "episode : 4, timestep : 7732800, average reward : -48.0099983215332\n",
            "[7733248] Avg reward (last 50 episodes): -0.06858879327774048\n",
            "episode : 4, timestep : 7735200, average reward : -51.08000183105469\n",
            "episode : 4, timestep : 7737600, average reward : -46.939998626708984\n",
            "episode : 4, timestep : 7740000, average reward : -72.37999725341797\n",
            "[7741440] Avg reward (last 50 episodes): -0.10371515154838562\n",
            "episode : 4, timestep : 7742400, average reward : -53.56999969482422\n",
            "episode : 4, timestep : 7744800, average reward : -53.189998626708984\n",
            "episode : 5, timestep : 7747200, average reward : -73.30999755859375\n",
            "episode : 4, timestep : 7749600, average reward : -73.44000244140625\n",
            "[7749632] Avg reward (last 50 episodes): -0.03995411470532417\n",
            "episode : 4, timestep : 7752000, average reward : -50.470001220703125\n",
            "episode : 4, timestep : 7754400, average reward : -46.630001068115234\n",
            "episode : 4, timestep : 7756800, average reward : -58.13999938964844\n",
            "[7757824] Avg reward (last 50 episodes): -0.09720867872238159\n",
            "episode : 5, timestep : 7759200, average reward : -66.55000305175781\n",
            "episode : 4, timestep : 7761600, average reward : -51.060001373291016\n",
            "episode : 4, timestep : 7764000, average reward : -50.599998474121094\n",
            "[7766016] Avg reward (last 50 episodes): -0.12450583279132843\n",
            "episode : 5, timestep : 7766400, average reward : -68.18000030517578\n",
            "episode : 4, timestep : 7768800, average reward : -52.619998931884766\n",
            "episode : 4, timestep : 7771200, average reward : -55.02000045776367\n",
            "episode : 4, timestep : 7773600, average reward : -52.540000915527344\n",
            "[7774208] Avg reward (last 50 episodes): -0.14220520853996277\n",
            "episode : 5, timestep : 7776000, average reward : -84.7699966430664\n",
            "episode : 4, timestep : 7778400, average reward : -53.529998779296875\n",
            "episode : 4, timestep : 7780800, average reward : -51.810001373291016\n",
            "[7782400] Avg reward (last 50 episodes): 0.006666133180260658\n",
            "episode : 4, timestep : 7783200, average reward : -84.52999877929688\n",
            "episode : 4, timestep : 7785600, average reward : -56.849998474121094\n",
            "episode : 4, timestep : 7788000, average reward : -50.36000061035156\n",
            "episode : 4, timestep : 7790400, average reward : -50.70000076293945\n",
            "[7790592] Avg reward (last 50 episodes): -0.21014265716075897\n",
            "episode : 4, timestep : 7792800, average reward : -51.900001525878906\n",
            "episode : 4, timestep : 7795200, average reward : -50.86000061035156\n",
            "episode : 4, timestep : 7797600, average reward : -53.08000183105469\n",
            "[7798784] Avg reward (last 50 episodes): -0.07748697698116302\n",
            "episode : 4, timestep : 7800000, average reward : -48.16999816894531\n",
            "episode : 4, timestep : 7802400, average reward : -56.61000061035156\n",
            "episode : 4, timestep : 7804800, average reward : -52.65999984741211\n",
            "[7806976] Avg reward (last 50 episodes): -0.11181943118572235\n",
            "episode : 4, timestep : 7807200, average reward : -55.34000015258789\n",
            "episode : 4, timestep : 7809600, average reward : -60.86000061035156\n",
            "episode : 4, timestep : 7812000, average reward : -65.43000030517578\n",
            "episode : 4, timestep : 7814400, average reward : -59.810001373291016\n",
            "[7815168] Avg reward (last 50 episodes): -0.13079403340816498\n",
            "episode : 4, timestep : 7816800, average reward : -63.18000030517578\n",
            "episode : 4, timestep : 7819200, average reward : -65.0999984741211\n",
            "setting action_std to  0.5778\n",
            "episode : 4, timestep : 7821600, average reward : -61.040000915527344\n",
            "[7823360] Avg reward (last 50 episodes): -0.09175155311822891\n",
            "episode : 4, timestep : 7824000, average reward : -68.98999786376953\n",
            "episode : 6, timestep : 7826400, average reward : -121.5999984741211\n",
            "episode : 4, timestep : 7828800, average reward : -109.68000030517578\n",
            "episode : 6, timestep : 7831200, average reward : -124.79000091552734\n",
            "[7831552] Avg reward (last 50 episodes): -0.09363549947738647\n",
            "episode : 5, timestep : 7833600, average reward : -120.77999877929688\n",
            "episode : 4, timestep : 7836000, average reward : -112.87000274658203\n",
            "episode : 6, timestep : 7838400, average reward : -124.72000122070312\n",
            "[7839744] Avg reward (last 50 episodes): -0.09507357329130173\n",
            "episode : 4, timestep : 7840800, average reward : -112.68000030517578\n",
            "episode : 4, timestep : 7843200, average reward : -91.08000183105469\n",
            "episode : 4, timestep : 7845600, average reward : -58.9900016784668\n",
            "[7847936] Avg reward (last 50 episodes): -0.08981706947088242\n",
            "episode : 4, timestep : 7848000, average reward : -58.619998931884766\n",
            "episode : 4, timestep : 7850400, average reward : -58.290000915527344\n",
            "episode : 4, timestep : 7852800, average reward : -60.58000183105469\n",
            "episode : 4, timestep : 7855200, average reward : -56.720001220703125\n",
            "[7856128] Avg reward (last 50 episodes): -0.21175970137119293\n",
            "episode : 4, timestep : 7857600, average reward : -59.959999084472656\n",
            "episode : 4, timestep : 7860000, average reward : -62.689998626708984\n",
            "episode : 4, timestep : 7862400, average reward : -65.37000274658203\n",
            "[7864320] Avg reward (last 50 episodes): -0.11699124425649643\n",
            "episode : 4, timestep : 7864800, average reward : -58.29999923706055\n",
            "episode : 4, timestep : 7867200, average reward : -58.619998931884766\n",
            "episode : 4, timestep : 7869600, average reward : -58.7400016784668\n",
            "episode : 4, timestep : 7872000, average reward : -58.119998931884766\n",
            "[7872512] Avg reward (last 50 episodes): -0.10100570321083069\n",
            "episode : 4, timestep : 7874400, average reward : -56.279998779296875\n",
            "episode : 4, timestep : 7876800, average reward : -58.11000061035156\n",
            "episode : 4, timestep : 7879200, average reward : -60.130001068115234\n",
            "[7880704] Avg reward (last 50 episodes): -0.20470808446407318\n",
            "episode : 5, timestep : 7881600, average reward : -71.45999908447266\n",
            "episode : 4, timestep : 7884000, average reward : -56.560001373291016\n",
            "episode : 4, timestep : 7886400, average reward : -53.7400016784668\n",
            "episode : 4, timestep : 7888800, average reward : -55.63999938964844\n",
            "[7888896] Avg reward (last 50 episodes): -0.09328686445951462\n",
            "episode : 4, timestep : 7891200, average reward : -56.68000030517578\n",
            "episode : 5, timestep : 7893600, average reward : -67.41000366210938\n",
            "episode : 4, timestep : 7896000, average reward : -53.619998931884766\n",
            "[7897088] Avg reward (last 50 episodes): -0.10278314352035522\n",
            "episode : 4, timestep : 7898400, average reward : -56.5099983215332\n",
            "episode : 4, timestep : 7900800, average reward : -52.540000915527344\n",
            "episode : 4, timestep : 7903200, average reward : -53.5\n",
            "[7905280] Avg reward (last 50 episodes): -0.11007142066955566\n",
            "episode : 4, timestep : 7905600, average reward : -57.11000061035156\n",
            "episode : 4, timestep : 7908000, average reward : -55.869998931884766\n",
            "episode : 4, timestep : 7910400, average reward : -56.09000015258789\n",
            "episode : 4, timestep : 7912800, average reward : -57.970001220703125\n",
            "[7913472] Avg reward (last 50 episodes): -0.08398737013339996\n",
            "episode : 4, timestep : 7915200, average reward : -54.65999984741211\n",
            "episode : 4, timestep : 7917600, average reward : -54.90999984741211\n",
            "setting action_std to  0.5775\n",
            "episode : 4, timestep : 7920000, average reward : -81.47000122070312\n",
            "[7921664] Avg reward (last 50 episodes): -0.09100900590419769\n",
            "episode : 5, timestep : 7922400, average reward : -72.9000015258789\n",
            "episode : 5, timestep : 7924800, average reward : -67.55999755859375\n",
            "episode : 4, timestep : 7927200, average reward : -55.689998626708984\n",
            "episode : 4, timestep : 7929600, average reward : -55.65999984741211\n",
            "[7929856] Avg reward (last 50 episodes): -0.09670305252075195\n",
            "episode : 4, timestep : 7932000, average reward : -58.11000061035156\n",
            "episode : 4, timestep : 7934400, average reward : -76.7699966430664\n",
            "episode : 4, timestep : 7936800, average reward : -54.38999938964844\n",
            "[7938048] Avg reward (last 50 episodes): -0.10271136462688446\n",
            "episode : 5, timestep : 7939200, average reward : -72.5999984741211\n",
            "episode : 4, timestep : 7941600, average reward : -56.34000015258789\n",
            "episode : 6, timestep : 7944000, average reward : -83.75\n",
            "[7946240] Avg reward (last 50 episodes): 0.015287987887859344\n",
            "episode : 4, timestep : 7946400, average reward : -76.79000091552734\n",
            "episode : 4, timestep : 7948800, average reward : -56.33000183105469\n",
            "episode : 4, timestep : 7951200, average reward : -56.630001068115234\n",
            "episode : 4, timestep : 7953600, average reward : -51.70000076293945\n",
            "[7954432] Avg reward (last 50 episodes): -0.04486193507909775\n",
            "episode : 4, timestep : 7956000, average reward : -56.849998474121094\n",
            "episode : 4, timestep : 7958400, average reward : -58.630001068115234\n",
            "episode : 4, timestep : 7960800, average reward : -57.20000076293945\n",
            "[7962624] Avg reward (last 50 episodes): -0.09834866225719452\n",
            "episode : 4, timestep : 7963200, average reward : -59.66999816894531\n",
            "episode : 4, timestep : 7965600, average reward : -57.47999954223633\n",
            "episode : 5, timestep : 7968000, average reward : -79.23999786376953\n",
            "episode : 4, timestep : 7970400, average reward : -57.900001525878906\n",
            "[7970816] Avg reward (last 50 episodes): -0.11579900979995728\n",
            "episode : 4, timestep : 7972800, average reward : -58.290000915527344\n",
            "episode : 4, timestep : 7975200, average reward : -58.29999923706055\n",
            "episode : 4, timestep : 7977600, average reward : -57.220001220703125\n",
            "[7979008] Avg reward (last 50 episodes): -0.08573156595230103\n",
            "episode : 4, timestep : 7980000, average reward : -58.0099983215332\n",
            "episode : 4, timestep : 7982400, average reward : -57.310001373291016\n",
            "episode : 4, timestep : 7984800, average reward : -57.970001220703125\n",
            "[7987200] Avg reward (last 50 episodes): -0.09234479069709778\n",
            "episode : 4, timestep : 7987200, average reward : -55.900001525878906\n",
            "episode : 4, timestep : 7989600, average reward : -57.11000061035156\n",
            "episode : 4, timestep : 7992000, average reward : -54.790000915527344\n",
            "episode : 4, timestep : 7994400, average reward : -59.36000061035156\n",
            "[7995392] Avg reward (last 50 episodes): -0.07052719593048096\n",
            "episode : 4, timestep : 7996800, average reward : -57.56999969482422\n",
            "episode : 4, timestep : 7999200, average reward : -58.439998626708984\n",
            "episode : 4, timestep : 8001600, average reward : -54.68000030517578\n",
            "[8003584] Avg reward (last 50 episodes): -0.0919778048992157\n",
            "episode : 4, timestep : 8004000, average reward : -57.5\n",
            "episode : 4, timestep : 8006400, average reward : -56.18000030517578\n",
            "episode : 4, timestep : 8008800, average reward : -57.45000076293945\n",
            "episode : 4, timestep : 8011200, average reward : -58.040000915527344\n",
            "[8011776] Avg reward (last 50 episodes): -0.09264394640922546\n",
            "episode : 4, timestep : 8013600, average reward : -55.88999938964844\n",
            "episode : 4, timestep : 8016000, average reward : -58.33000183105469\n",
            "episode : 5, timestep : 8018400, average reward : -72.12000274658203\n",
            "setting action_std to  0.5772\n",
            "[8019968] Avg reward (last 50 episodes): -0.07936123013496399\n",
            "episode : 4, timestep : 8020800, average reward : -57.810001373291016\n",
            "episode : 4, timestep : 8023200, average reward : -59.2599983215332\n",
            "episode : 4, timestep : 8025600, average reward : -58.2400016784668\n",
            "episode : 4, timestep : 8028000, average reward : -56.22999954223633\n",
            "[8028160] Avg reward (last 50 episodes): -0.08564101904630661\n",
            "episode : 4, timestep : 8030400, average reward : -57.61000061035156\n",
            "episode : 4, timestep : 8032800, average reward : -57.349998474121094\n",
            "episode : 4, timestep : 8035200, average reward : -57.90999984741211\n",
            "[8036352] Avg reward (last 50 episodes): -0.08496470749378204\n",
            "episode : 4, timestep : 8037600, average reward : -57.2599983215332\n",
            "episode : 4, timestep : 8040000, average reward : -54.91999816894531\n",
            "episode : 4, timestep : 8042400, average reward : -53.380001068115234\n",
            "[8044544] Avg reward (last 50 episodes): -0.08519506454467773\n",
            "episode : 4, timestep : 8044800, average reward : -55.630001068115234\n",
            "episode : 4, timestep : 8047200, average reward : -56.349998474121094\n",
            "episode : 4, timestep : 8049600, average reward : -57.22999954223633\n",
            "episode : 4, timestep : 8052000, average reward : -58.380001068115234\n",
            "[8052736] Avg reward (last 50 episodes): -0.09162145853042603\n",
            "episode : 4, timestep : 8054400, average reward : -56.58000183105469\n",
            "episode : 4, timestep : 8056800, average reward : -53.7599983215332\n",
            "episode : 4, timestep : 8059200, average reward : -54.040000915527344\n",
            "[8060928] Avg reward (last 50 episodes): -0.08019866049289703\n",
            "episode : 4, timestep : 8061600, average reward : -53.560001373291016\n",
            "episode : 4, timestep : 8064000, average reward : -54.18000030517578\n",
            "episode : 4, timestep : 8066400, average reward : -54.900001525878906\n",
            "episode : 4, timestep : 8068800, average reward : -52.119998931884766\n",
            "[8069120] Avg reward (last 50 episodes): -0.08318819105625153\n",
            "episode : 4, timestep : 8071200, average reward : -76.69000244140625\n",
            "episode : 4, timestep : 8073600, average reward : -52.790000915527344\n",
            "episode : 5, timestep : 8076000, average reward : -71.41999816894531\n",
            "[8077312] Avg reward (last 50 episodes): -0.07671608775854111\n",
            "episode : 4, timestep : 8078400, average reward : -56.119998931884766\n",
            "episode : 4, timestep : 8080800, average reward : -55.400001525878906\n",
            "episode : 4, timestep : 8083200, average reward : -55.279998779296875\n",
            "[8085504] Avg reward (last 50 episodes): -0.08641153573989868\n",
            "episode : 5, timestep : 8085600, average reward : -68.93000030517578\n",
            "episode : 4, timestep : 8088000, average reward : -50.029998779296875\n",
            "episode : 4, timestep : 8090400, average reward : -53.290000915527344\n",
            "episode : 5, timestep : 8092800, average reward : -70.61000061035156\n",
            "[8093696] Avg reward (last 50 episodes): -0.11806641519069672\n",
            "episode : 4, timestep : 8095200, average reward : -54.47999954223633\n",
            "episode : 4, timestep : 8097600, average reward : -73.08000183105469\n",
            "episode : 4, timestep : 8100000, average reward : -50.91999816894531\n",
            "[8101888] Avg reward (last 50 episodes): -0.12816393375396729\n",
            "episode : 4, timestep : 8102400, average reward : -50.88999938964844\n",
            "episode : 4, timestep : 8104800, average reward : -57.459999084472656\n",
            "episode : 4, timestep : 8107200, average reward : -56.29999923706055\n",
            "episode : 4, timestep : 8109600, average reward : -54.65999984741211\n",
            "[8110080] Avg reward (last 50 episodes): -0.094414122402668\n",
            "episode : 4, timestep : 8112000, average reward : -52.16999816894531\n",
            "episode : 4, timestep : 8114400, average reward : -51.959999084472656\n",
            "episode : 4, timestep : 8116800, average reward : -53.209999084472656\n",
            "[8118272] Avg reward (last 50 episodes): -0.09506199508905411\n",
            "episode : 4, timestep : 8119200, average reward : -52.099998474121094\n",
            "setting action_std to  0.5769\n",
            "episode : 4, timestep : 8121600, average reward : -53.58000183105469\n",
            "episode : 4, timestep : 8124000, average reward : -54.2599983215332\n",
            "episode : 4, timestep : 8126400, average reward : -55.41999816894531\n",
            "[8126464] Avg reward (last 50 episodes): -0.0874183401465416\n",
            "episode : 4, timestep : 8128800, average reward : -56.06999969482422\n",
            "episode : 4, timestep : 8131200, average reward : -50.689998626708984\n",
            "episode : 5, timestep : 8133600, average reward : -69.62000274658203\n",
            "[8134656] Avg reward (last 50 episodes): -0.08518979698419571\n",
            "episode : 4, timestep : 8136000, average reward : -57.150001525878906\n",
            "episode : 4, timestep : 8138400, average reward : -57.220001220703125\n",
            "episode : 4, timestep : 8140800, average reward : -55.529998779296875\n",
            "[8142848] Avg reward (last 50 episodes): -0.13278590142726898\n",
            "episode : 5, timestep : 8143200, average reward : -67.69000244140625\n",
            "episode : 4, timestep : 8145600, average reward : -48.47999954223633\n",
            "episode : 5, timestep : 8148000, average reward : -68.25\n",
            "episode : 4, timestep : 8150400, average reward : -52.0\n",
            "[8151040] Avg reward (last 50 episodes): -0.16248784959316254\n",
            "episode : 4, timestep : 8152800, average reward : -48.93000030517578\n",
            "episode : 4, timestep : 8155200, average reward : -53.720001220703125\n",
            "episode : 4, timestep : 8157600, average reward : -56.16999816894531\n",
            "[8159232] Avg reward (last 50 episodes): -0.05545682832598686\n",
            "episode : 4, timestep : 8160000, average reward : -53.599998474121094\n",
            "episode : 4, timestep : 8162400, average reward : -51.7599983215332\n",
            "episode : 4, timestep : 8164800, average reward : -67.37999725341797\n",
            "episode : 4, timestep : 8167200, average reward : -50.880001068115234\n",
            "[8167424] Avg reward (last 50 episodes): -0.072034552693367\n",
            "episode : 5, timestep : 8169600, average reward : -70.23999786376953\n",
            "episode : 5, timestep : 8172000, average reward : -65.58999633789062\n",
            "episode : 4, timestep : 8174400, average reward : -56.099998474121094\n",
            "[8175616] Avg reward (last 50 episodes): -0.10445240885019302\n",
            "episode : 4, timestep : 8176800, average reward : -52.130001068115234\n",
            "episode : 4, timestep : 8179200, average reward : -46.040000915527344\n",
            "episode : 5, timestep : 8181600, average reward : -66.01000213623047\n",
            "[8183808] Avg reward (last 50 episodes): -0.03531963750720024\n",
            "episode : 4, timestep : 8184000, average reward : -49.13999938964844\n",
            "episode : 4, timestep : 8186400, average reward : -65.01000213623047\n",
            "episode : 4, timestep : 8188800, average reward : -50.880001068115234\n",
            "episode : 5, timestep : 8191200, average reward : -67.48999786376953\n",
            "[8192000] Avg reward (last 50 episodes): -0.13585256040096283\n",
            "episode : 4, timestep : 8193600, average reward : -93.93000030517578\n",
            "episode : 6, timestep : 8196000, average reward : -91.91999816894531\n",
            "episode : 7, timestep : 8198400, average reward : -100.12000274658203\n",
            "[8200192] Avg reward (last 50 episodes): -0.0908675491809845\n",
            "episode : 4, timestep : 8200800, average reward : -100.33999633789062\n",
            "episode : 5, timestep : 8203200, average reward : -64.41000366210938\n",
            "episode : 4, timestep : 8205600, average reward : -53.36000061035156\n",
            "episode : 6, timestep : 8208000, average reward : -78.12000274658203\n",
            "[8208384] Avg reward (last 50 episodes): -0.1303422898054123\n",
            "episode : 4, timestep : 8210400, average reward : -100.69000244140625\n",
            "episode : 7, timestep : 8212800, average reward : -99.9000015258789\n",
            "episode : 6, timestep : 8215200, average reward : -91.80000305175781\n",
            "[8216576] Avg reward (last 50 episodes): -0.2203737199306488\n",
            "episode : 6, timestep : 8217600, average reward : -123.51000213623047\n",
            "episode : 8, timestep : 8220000, average reward : -127.36000061035156\n",
            "setting action_std to  0.5766\n",
            "episode : 8, timestep : 8222400, average reward : -143.49000549316406\n",
            "[8224768] Avg reward (last 50 episodes): -2.05888722255826\n",
            "episode : 8, timestep : 8224800, average reward : -130.8699951171875\n",
            "episode : 7, timestep : 8227200, average reward : -133.3800048828125\n",
            "episode : 6, timestep : 8229600, average reward : -111.56999969482422\n",
            "episode : 9, timestep : 8232000, average reward : -131.83999633789062\n",
            "[8232960] Avg reward (last 50 episodes): -2.208866020143032\n",
            "episode : 6, timestep : 8234400, average reward : -111.54000091552734\n",
            "episode : 4, timestep : 8236800, average reward : -53.810001373291016\n",
            "episode : 4, timestep : 8239200, average reward : -74.1500015258789\n",
            "[8241152] Avg reward (last 50 episodes): 0.03410923108458519\n",
            "episode : 4, timestep : 8241600, average reward : -47.58000183105469\n",
            "episode : 4, timestep : 8244000, average reward : -83.54000091552734\n",
            "episode : 4, timestep : 8246400, average reward : -52.5\n",
            "episode : 4, timestep : 8248800, average reward : -50.189998626708984\n",
            "[8249344] Avg reward (last 50 episodes): 0.00835823267698288\n",
            "episode : 5, timestep : 8251200, average reward : -67.70999908447266\n",
            "episode : 4, timestep : 8253600, average reward : -55.15999984741211\n",
            "episode : 4, timestep : 8256000, average reward : -58.220001220703125\n",
            "[8257536] Avg reward (last 50 episodes): -0.19130821526050568\n",
            "episode : 4, timestep : 8258400, average reward : -57.540000915527344\n",
            "episode : 4, timestep : 8260800, average reward : -57.31999969482422\n",
            "episode : 4, timestep : 8263200, average reward : -54.47999954223633\n",
            "episode : 4, timestep : 8265600, average reward : -55.54999923706055\n",
            "[8265728] Avg reward (last 50 episodes): -0.09156309813261032\n",
            "episode : 4, timestep : 8268000, average reward : -52.61000061035156\n",
            "episode : 4, timestep : 8270400, average reward : -58.77000045776367\n",
            "episode : 4, timestep : 8272800, average reward : -57.5\n",
            "[8273920] Avg reward (last 50 episodes): -0.07807080447673798\n",
            "episode : 4, timestep : 8275200, average reward : -56.61000061035156\n",
            "episode : 4, timestep : 8277600, average reward : -55.4900016784668\n",
            "episode : 4, timestep : 8280000, average reward : -55.33000183105469\n",
            "[8282112] Avg reward (last 50 episodes): -0.2105751484632492\n",
            "episode : 4, timestep : 8282400, average reward : -55.72999954223633\n",
            "episode : 4, timestep : 8284800, average reward : -55.470001220703125\n",
            "episode : 4, timestep : 8287200, average reward : -57.83000183105469\n",
            "episode : 4, timestep : 8289600, average reward : -54.5\n",
            "[8290304] Avg reward (last 50 episodes): -0.12686771154403687\n",
            "episode : 4, timestep : 8292000, average reward : -55.59000015258789\n",
            "episode : 4, timestep : 8294400, average reward : -56.689998626708984\n",
            "episode : 4, timestep : 8296800, average reward : -56.5099983215332\n",
            "[8298496] Avg reward (last 50 episodes): -0.07217862457036972\n",
            "episode : 4, timestep : 8299200, average reward : -54.29999923706055\n",
            "episode : 4, timestep : 8301600, average reward : -52.7599983215332\n",
            "episode : 4, timestep : 8304000, average reward : -52.9900016784668\n",
            "episode : 4, timestep : 8306400, average reward : -57.619998931884766\n",
            "[8306688] Avg reward (last 50 episodes): -0.1380549818277359\n",
            "episode : 4, timestep : 8308800, average reward : -54.119998931884766\n",
            "episode : 4, timestep : 8311200, average reward : -53.47999954223633\n",
            "episode : 4, timestep : 8313600, average reward : -49.689998626708984\n",
            "[8314880] Avg reward (last 50 episodes): -0.07887005060911179\n",
            "episode : 4, timestep : 8316000, average reward : -54.20000076293945\n",
            "episode : 4, timestep : 8318400, average reward : -52.13999938964844\n",
            "setting action_std to  0.5763\n",
            "episode : 5, timestep : 8320800, average reward : -64.20999908447266\n",
            "[8323072] Avg reward (last 50 episodes): 0.04555249214172363\n",
            "episode : 4, timestep : 8323200, average reward : -49.88999938964844\n",
            "episode : 4, timestep : 8325600, average reward : -48.41999816894531\n",
            "episode : 4, timestep : 8328000, average reward : -55.4900016784668\n",
            "episode : 4, timestep : 8330400, average reward : -52.02000045776367\n",
            "[8331264] Avg reward (last 50 episodes): -0.08761592954397202\n",
            "episode : 4, timestep : 8332800, average reward : -48.38999938964844\n",
            "episode : 4, timestep : 8335200, average reward : -50.79999923706055\n",
            "episode : 5, timestep : 8337600, average reward : -67.97000122070312\n",
            "[8339456] Avg reward (last 50 episodes): 0.01693934202194214\n",
            "episode : 4, timestep : 8340000, average reward : -52.38999938964844\n",
            "episode : 5, timestep : 8342400, average reward : -78.08999633789062\n",
            "episode : 4, timestep : 8344800, average reward : -54.15999984741211\n",
            "episode : 4, timestep : 8347200, average reward : -53.08000183105469\n",
            "[8347648] Avg reward (last 50 episodes): -0.08697690069675446\n",
            "episode : 4, timestep : 8349600, average reward : -52.7599983215332\n",
            "episode : 4, timestep : 8352000, average reward : -55.25\n",
            "episode : 4, timestep : 8354400, average reward : -50.369998931884766\n",
            "[8355840] Avg reward (last 50 episodes): -0.07955209910869598\n",
            "episode : 5, timestep : 8356800, average reward : -67.25\n",
            "episode : 4, timestep : 8359200, average reward : -56.08000183105469\n",
            "episode : 4, timestep : 8361600, average reward : -52.310001373291016\n",
            "episode : 5, timestep : 8364000, average reward : -64.33000183105469\n",
            "[8364032] Avg reward (last 50 episodes): -0.097781702876091\n",
            "episode : 4, timestep : 8366400, average reward : -51.9900016784668\n",
            "episode : 4, timestep : 8368800, average reward : -44.970001220703125\n",
            "episode : 4, timestep : 8371200, average reward : -54.11000061035156\n",
            "[8372224] Avg reward (last 50 episodes): -0.03850647807121277\n",
            "episode : 4, timestep : 8373600, average reward : -54.79999923706055\n",
            "episode : 4, timestep : 8376000, average reward : -51.9900016784668\n",
            "episode : 5, timestep : 8378400, average reward : -65.80000305175781\n",
            "[8380416] Avg reward (last 50 episodes): -0.11100462079048157\n",
            "episode : 4, timestep : 8380800, average reward : -55.27000045776367\n",
            "episode : 4, timestep : 8383200, average reward : -56.63999938964844\n",
            "episode : 4, timestep : 8385600, average reward : -54.5\n",
            "episode : 4, timestep : 8388000, average reward : -50.63999938964844\n",
            "[8388608] Avg reward (last 50 episodes): -0.10428163409233093\n",
            "episode : 4, timestep : 8390400, average reward : -52.900001525878906\n",
            "episode : 4, timestep : 8392800, average reward : -55.72999954223633\n",
            "episode : 4, timestep : 8395200, average reward : -52.2400016784668\n",
            "[8396800] Avg reward (last 50 episodes): -0.10679129511117935\n",
            "episode : 4, timestep : 8397600, average reward : -57.189998626708984\n",
            "episode : 4, timestep : 8400000, average reward : -49.2599983215332\n",
            "episode : 4, timestep : 8402400, average reward : -54.72999954223633\n",
            "episode : 4, timestep : 8404800, average reward : -55.75\n",
            "[8404992] Avg reward (last 50 episodes): -0.11281901597976685\n",
            "episode : 4, timestep : 8407200, average reward : -80.2300033569336\n",
            "episode : 4, timestep : 8409600, average reward : -51.9900016784668\n",
            "episode : 4, timestep : 8412000, average reward : -50.43000030517578\n",
            "[8413184] Avg reward (last 50 episodes): -0.08415313810110092\n",
            "episode : 5, timestep : 8414400, average reward : -66.12999725341797\n",
            "episode : 4, timestep : 8416800, average reward : -52.709999084472656\n",
            "episode : 4, timestep : 8419200, average reward : -52.33000183105469\n",
            "setting action_std to  0.576\n",
            "[8421376] Avg reward (last 50 episodes): -0.215560182929039\n",
            "episode : 4, timestep : 8421600, average reward : -48.63999938964844\n",
            "episode : 4, timestep : 8424000, average reward : -48.380001068115234\n",
            "episode : 4, timestep : 8426400, average reward : -51.90999984741211\n",
            "episode : 4, timestep : 8428800, average reward : -51.849998474121094\n",
            "[8429568] Avg reward (last 50 episodes): -0.037444308400154114\n",
            "episode : 5, timestep : 8431200, average reward : -66.9000015258789\n",
            "episode : 5, timestep : 8433600, average reward : -60.369998931884766\n",
            "episode : 4, timestep : 8436000, average reward : -50.77000045776367\n",
            "[8437760] Avg reward (last 50 episodes): -0.25040584802627563\n",
            "episode : 4, timestep : 8438400, average reward : -52.029998779296875\n",
            "episode : 5, timestep : 8440800, average reward : -67.0\n",
            "episode : 4, timestep : 8443200, average reward : -53.220001220703125\n",
            "episode : 4, timestep : 8445600, average reward : -50.810001373291016\n",
            "[8445952] Avg reward (last 50 episodes): -0.09426169097423553\n",
            "episode : 4, timestep : 8448000, average reward : -54.31999969482422\n",
            "episode : 5, timestep : 8450400, average reward : -83.12999725341797\n",
            "episode : 6, timestep : 8452800, average reward : -74.13999938964844\n",
            "[8454144] Avg reward (last 50 episodes): -0.07609187066555023\n",
            "episode : 4, timestep : 8455200, average reward : -51.900001525878906\n",
            "episode : 4, timestep : 8457600, average reward : -55.369998931884766\n",
            "episode : 4, timestep : 8460000, average reward : -52.720001220703125\n",
            "[8462336] Avg reward (last 50 episodes): -0.14419350028038025\n",
            "episode : 4, timestep : 8462400, average reward : -52.220001220703125\n",
            "episode : 4, timestep : 8464800, average reward : -50.869998931884766\n",
            "episode : 4, timestep : 8467200, average reward : -47.470001220703125\n",
            "episode : 4, timestep : 8469600, average reward : -52.88999938964844\n",
            "[8470528] Avg reward (last 50 episodes): -0.06568294763565063\n",
            "episode : 4, timestep : 8472000, average reward : -53.75\n",
            "episode : 4, timestep : 8474400, average reward : -50.470001220703125\n",
            "episode : 5, timestep : 8476800, average reward : -66.63999938964844\n",
            "[8478720] Avg reward (last 50 episodes): -0.06969676166772842\n",
            "episode : 4, timestep : 8479200, average reward : -52.91999816894531\n",
            "episode : 4, timestep : 8481600, average reward : -47.849998474121094\n",
            "episode : 4, timestep : 8484000, average reward : -53.849998474121094\n",
            "episode : 4, timestep : 8486400, average reward : -53.380001068115234\n",
            "[8486912] Avg reward (last 50 episodes): -0.10230520367622375\n",
            "episode : 4, timestep : 8488800, average reward : -53.79999923706055\n",
            "episode : 4, timestep : 8491200, average reward : -52.86000061035156\n",
            "episode : 4, timestep : 8493600, average reward : -53.09000015258789\n",
            "[8495104] Avg reward (last 50 episodes): -0.08246567845344543\n",
            "episode : 4, timestep : 8496000, average reward : -53.880001068115234\n",
            "episode : 4, timestep : 8498400, average reward : -53.75\n",
            "episode : 4, timestep : 8500800, average reward : -53.0099983215332\n",
            "episode : 5, timestep : 8503200, average reward : -67.04000091552734\n",
            "[8503296] Avg reward (last 50 episodes): -0.15566810965538025\n",
            "episode : 4, timestep : 8505600, average reward : -54.11000061035156\n",
            "episode : 4, timestep : 8508000, average reward : -47.439998626708984\n",
            "episode : 4, timestep : 8510400, average reward : -52.810001373291016\n",
            "[8511488] Avg reward (last 50 episodes): -0.09318787604570389\n",
            "episode : 4, timestep : 8512800, average reward : -69.29000091552734\n",
            "episode : 5, timestep : 8515200, average reward : -61.22999954223633\n",
            "episode : 4, timestep : 8517600, average reward : -48.810001373291016\n",
            "[8519680] Avg reward (last 50 episodes): -0.09699372202157974\n",
            "episode : 4, timestep : 8520000, average reward : -44.380001068115234\n",
            "setting action_std to  0.5757\n",
            "episode : 5, timestep : 8522400, average reward : -63.619998931884766\n",
            "episode : 4, timestep : 8524800, average reward : -50.47999954223633\n",
            "episode : 4, timestep : 8527200, average reward : -49.400001525878906\n",
            "[8527872] Avg reward (last 50 episodes): -0.08308770507574081\n",
            "episode : 4, timestep : 8529600, average reward : -53.880001068115234\n",
            "episode : 4, timestep : 8532000, average reward : -51.060001373291016\n",
            "episode : 4, timestep : 8534400, average reward : -48.52000045776367\n",
            "[8536064] Avg reward (last 50 episodes): -0.030418455600738525\n",
            "episode : 6, timestep : 8536800, average reward : -72.81999969482422\n",
            "episode : 5, timestep : 8539200, average reward : -58.45000076293945\n",
            "episode : 4, timestep : 8541600, average reward : -44.939998626708984\n",
            "episode : 4, timestep : 8544000, average reward : -46.63999938964844\n",
            "[8544256] Avg reward (last 50 episodes): -0.09877566993236542\n",
            "episode : 5, timestep : 8546400, average reward : -56.08000183105469\n",
            "episode : 4, timestep : 8548800, average reward : -65.94000244140625\n",
            "episode : 5, timestep : 8551200, average reward : -61.0099983215332\n",
            "[8552448] Avg reward (last 50 episodes): -0.11273228377103806\n",
            "episode : 5, timestep : 8553600, average reward : -83.70999908447266\n",
            "episode : 4, timestep : 8556000, average reward : -50.119998931884766\n",
            "episode : 6, timestep : 8558400, average reward : -69.2699966430664\n",
            "[8560640] Avg reward (last 50 episodes): -0.1209685206413269\n",
            "episode : 6, timestep : 8560800, average reward : -70.58000183105469\n",
            "episode : 7, timestep : 8563200, average reward : -85.2699966430664\n",
            "episode : 6, timestep : 8565600, average reward : -80.73999786376953\n",
            "episode : 8, timestep : 8568000, average reward : -81.7300033569336\n",
            "[8568832] Avg reward (last 50 episodes): -0.049475718289613724\n",
            "episode : 4, timestep : 8570400, average reward : -76.43000030517578\n",
            "episode : 6, timestep : 8572800, average reward : -73.81999969482422\n",
            "episode : 4, timestep : 8575200, average reward : -88.6500015258789\n",
            "[8577024] Avg reward (last 50 episodes): -0.1115984246134758\n",
            "episode : 4, timestep : 8577600, average reward : -42.529998779296875\n",
            "episode : 11, timestep : 8580000, average reward : -113.63999938964844\n",
            "episode : 5, timestep : 8582400, average reward : -74.23999786376953\n",
            "episode : 8, timestep : 8584800, average reward : -94.31999969482422\n",
            "[8585216] Avg reward (last 50 episodes): -0.05874063819646835\n",
            "episode : 9, timestep : 8587200, average reward : -95.69000244140625\n",
            "episode : 10, timestep : 8589600, average reward : -97.01000213623047\n",
            "episode : 7, timestep : 8592000, average reward : -91.20999908447266\n",
            "[8593408] Avg reward (last 50 episodes): -0.13199231028556824\n",
            "episode : 6, timestep : 8594400, average reward : -68.62999725341797\n",
            "episode : 5, timestep : 8596800, average reward : -76.98999786376953\n",
            "episode : 6, timestep : 8599200, average reward : -77.75\n",
            "[8601600] Avg reward (last 50 episodes): 0.004925103858113289\n",
            "episode : 4, timestep : 8601600, average reward : -53.02000045776367\n",
            "episode : 5, timestep : 8604000, average reward : -90.69999694824219\n",
            "episode : 4, timestep : 8606400, average reward : -52.9900016784668\n",
            "episode : 4, timestep : 8608800, average reward : -50.36000061035156\n",
            "[8609792] Avg reward (last 50 episodes): -0.1542927473783493\n",
            "episode : 4, timestep : 8611200, average reward : -43.790000915527344\n",
            "episode : 5, timestep : 8613600, average reward : -79.23999786376953\n",
            "episode : 5, timestep : 8616000, average reward : -64.87999725341797\n",
            "[8617984] Avg reward (last 50 episodes): 0.005637476220726967\n",
            "episode : 4, timestep : 8618400, average reward : -46.90999984741211\n",
            "episode : 4, timestep : 8620800, average reward : -52.029998779296875\n",
            "setting action_std to  0.5754\n",
            "episode : 4, timestep : 8623200, average reward : -50.22999954223633\n",
            "episode : 4, timestep : 8625600, average reward : -55.52000045776367\n",
            "[8626176] Avg reward (last 50 episodes): -0.0905124694108963\n",
            "episode : 4, timestep : 8628000, average reward : -42.560001373291016\n",
            "episode : 4, timestep : 8630400, average reward : -46.43000030517578\n",
            "episode : 5, timestep : 8632800, average reward : -85.63999938964844\n",
            "[8634368] Avg reward (last 50 episodes): -0.15687620639801025\n",
            "episode : 5, timestep : 8635200, average reward : -65.83000183105469\n",
            "episode : 4, timestep : 8637600, average reward : -47.68000030517578\n",
            "episode : 4, timestep : 8640000, average reward : -47.97999954223633\n",
            "episode : 5, timestep : 8642400, average reward : -56.81999969482422\n",
            "[8642560] Avg reward (last 50 episodes): -0.1457558423280716\n",
            "episode : 4, timestep : 8644800, average reward : -65.83999633789062\n",
            "episode : 7, timestep : 8647200, average reward : -89.13999938964844\n",
            "episode : 4, timestep : 8649600, average reward : -44.52000045776367\n",
            "[8650752] Avg reward (last 50 episodes): -0.11988088488578796\n",
            "episode : 5, timestep : 8652000, average reward : -67.44000244140625\n",
            "episode : 4, timestep : 8654400, average reward : -47.02000045776367\n",
            "episode : 4, timestep : 8656800, average reward : -52.939998626708984\n",
            "[8658944] Avg reward (last 50 episodes): -0.20672547817230225\n",
            "episode : 4, timestep : 8659200, average reward : -49.02000045776367\n",
            "episode : 4, timestep : 8661600, average reward : -55.15999984741211\n",
            "episode : 5, timestep : 8664000, average reward : -62.72999954223633\n",
            "episode : 4, timestep : 8666400, average reward : -49.0099983215332\n",
            "[8667136] Avg reward (last 50 episodes): -0.04075424373149872\n",
            "episode : 4, timestep : 8668800, average reward : -50.09000015258789\n",
            "episode : 4, timestep : 8671200, average reward : -53.79999923706055\n",
            "episode : 6, timestep : 8673600, average reward : -72.33000183105469\n",
            "[8675328] Avg reward (last 50 episodes): -0.03324855491518974\n",
            "episode : 4, timestep : 8676000, average reward : -49.540000915527344\n",
            "episode : 4, timestep : 8678400, average reward : -43.290000915527344\n",
            "episode : 4, timestep : 8680800, average reward : -48.470001220703125\n",
            "episode : 6, timestep : 8683200, average reward : -91.0999984741211\n",
            "[8683520] Avg reward (last 50 episodes): -0.03864166513085365\n",
            "episode : 4, timestep : 8685600, average reward : -46.09000015258789\n",
            "episode : 4, timestep : 8688000, average reward : -41.7599983215332\n",
            "episode : 4, timestep : 8690400, average reward : -45.060001373291016\n",
            "[8691712] Avg reward (last 50 episodes): -0.09311903268098831\n",
            "episode : 4, timestep : 8692800, average reward : -51.0099983215332\n",
            "episode : 4, timestep : 8695200, average reward : -46.7400016784668\n",
            "episode : 4, timestep : 8697600, average reward : -45.59000015258789\n",
            "[8699904] Avg reward (last 50 episodes): 0.002613713499158621\n",
            "episode : 4, timestep : 8700000, average reward : -45.77000045776367\n",
            "episode : 4, timestep : 8702400, average reward : -47.2400016784668\n",
            "episode : 5, timestep : 8704800, average reward : -57.7599983215332\n",
            "episode : 4, timestep : 8707200, average reward : -43.95000076293945\n",
            "[8708096] Avg reward (last 50 episodes): -0.08355822414159775\n",
            "episode : 4, timestep : 8709600, average reward : -49.2599983215332\n",
            "episode : 4, timestep : 8712000, average reward : -47.72999954223633\n",
            "episode : 4, timestep : 8714400, average reward : -49.72999954223633\n",
            "[8716288] Avg reward (last 50 episodes): -0.041400860995054245\n",
            "episode : 4, timestep : 8716800, average reward : -48.29999923706055\n",
            "episode : 4, timestep : 8719200, average reward : -46.220001220703125\n",
            "setting action_std to  0.5751\n",
            "episode : 4, timestep : 8721600, average reward : -48.25\n",
            "episode : 4, timestep : 8724000, average reward : -47.06999969482422\n",
            "[8724480] Avg reward (last 50 episodes): -0.1150086298584938\n",
            "episode : 4, timestep : 8726400, average reward : -54.08000183105469\n",
            "episode : 4, timestep : 8728800, average reward : -49.65999984741211\n",
            "episode : 4, timestep : 8731200, average reward : -54.189998626708984\n",
            "[8732672] Avg reward (last 50 episodes): -0.08326976746320724\n",
            "episode : 5, timestep : 8733600, average reward : -65.87999725341797\n",
            "episode : 4, timestep : 8736000, average reward : -46.70000076293945\n",
            "episode : 4, timestep : 8738400, average reward : -49.5\n",
            "episode : 4, timestep : 8740800, average reward : -48.900001525878906\n",
            "[8740864] Avg reward (last 50 episodes): -0.14042511582374573\n",
            "episode : 4, timestep : 8743200, average reward : -54.459999084472656\n",
            "episode : 5, timestep : 8745600, average reward : -64.4800033569336\n",
            "episode : 4, timestep : 8748000, average reward : -47.36000061035156\n",
            "[8749056] Avg reward (last 50 episodes): -0.08954144269227982\n",
            "episode : 4, timestep : 8750400, average reward : -49.31999969482422\n",
            "episode : 4, timestep : 8752800, average reward : -55.459999084472656\n",
            "episode : 5, timestep : 8755200, average reward : -65.98999786376953\n",
            "[8757248] Avg reward (last 50 episodes): -0.10714469850063324\n",
            "episode : 4, timestep : 8757600, average reward : -49.189998626708984\n",
            "episode : 4, timestep : 8760000, average reward : -53.40999984741211\n",
            "episode : 4, timestep : 8762400, average reward : -68.61000061035156\n",
            "episode : 4, timestep : 8764800, average reward : -51.83000183105469\n",
            "[8765440] Avg reward (last 50 episodes): -0.14942331612110138\n",
            "episode : 5, timestep : 8767200, average reward : -67.48999786376953\n",
            "episode : 4, timestep : 8769600, average reward : -50.349998474121094\n",
            "episode : 4, timestep : 8772000, average reward : -53.970001220703125\n",
            "[8773632] Avg reward (last 50 episodes): -0.0831688866019249\n",
            "episode : 5, timestep : 8774400, average reward : -72.29000091552734\n",
            "episode : 4, timestep : 8776800, average reward : -56.27000045776367\n",
            "episode : 4, timestep : 8779200, average reward : -47.709999084472656\n",
            "episode : 4, timestep : 8781600, average reward : -50.16999816894531\n",
            "[8781824] Avg reward (last 50 episodes): -0.0834360420703888\n",
            "episode : 4, timestep : 8784000, average reward : -55.08000183105469\n",
            "episode : 4, timestep : 8786400, average reward : -74.08999633789062\n",
            "episode : 6, timestep : 8788800, average reward : -69.95999908447266\n",
            "[8790016] Avg reward (last 50 episodes): -0.15098519623279572\n",
            "episode : 7, timestep : 8791200, average reward : -83.86000061035156\n",
            "episode : 4, timestep : 8793600, average reward : -57.709999084472656\n",
            "episode : 4, timestep : 8796000, average reward : -73.5\n",
            "[8798208] Avg reward (last 50 episodes): -0.09236908704042435\n",
            "episode : 5, timestep : 8798400, average reward : -63.150001525878906\n",
            "episode : 4, timestep : 8800800, average reward : -50.65999984741211\n",
            "episode : 4, timestep : 8803200, average reward : -48.34000015258789\n",
            "episode : 5, timestep : 8805600, average reward : -64.68000030517578\n",
            "[8806400] Avg reward (last 50 episodes): -0.04819144681096077\n",
            "episode : 4, timestep : 8808000, average reward : -49.130001068115234\n",
            "episode : 5, timestep : 8810400, average reward : -62.400001525878906\n",
            "episode : 4, timestep : 8812800, average reward : -52.810001373291016\n",
            "[8814592] Avg reward (last 50 episodes): -2.121545380204916\n",
            "episode : 8, timestep : 8815200, average reward : -83.70999908447266\n",
            "episode : 4, timestep : 8817600, average reward : -52.43000030517578\n",
            "episode : 5, timestep : 8820000, average reward : -77.2699966430664\n",
            "setting action_std to  0.5748\n",
            "episode : 4, timestep : 8822400, average reward : -53.060001373291016\n",
            "[8822784] Avg reward (last 50 episodes): -0.05930164456367493\n",
            "episode : 5, timestep : 8824800, average reward : -87.88999938964844\n",
            "episode : 5, timestep : 8827200, average reward : -61.72999954223633\n",
            "episode : 6, timestep : 8829600, average reward : -75.2300033569336\n",
            "[8830976] Avg reward (last 50 episodes): -0.028085272759199142\n",
            "episode : 4, timestep : 8832000, average reward : -64.93000030517578\n",
            "episode : 6, timestep : 8834400, average reward : -78.72000122070312\n",
            "episode : 5, timestep : 8836800, average reward : -79.66000366210938\n",
            "[8839168] Avg reward (last 50 episodes): -0.041346896439790726\n",
            "episode : 5, timestep : 8839200, average reward : -62.709999084472656\n",
            "episode : 4, timestep : 8841600, average reward : -58.040000915527344\n",
            "episode : 7, timestep : 8844000, average reward : -80.23999786376953\n",
            "episode : 4, timestep : 8846400, average reward : -50.47999954223633\n",
            "[8847360] Avg reward (last 50 episodes): -0.09765176475048065\n",
            "episode : 4, timestep : 8848800, average reward : -49.34000015258789\n",
            "episode : 4, timestep : 8851200, average reward : -54.2400016784668\n",
            "episode : 5, timestep : 8853600, average reward : -65.87000274658203\n",
            "[8855552] Avg reward (last 50 episodes): -0.1521269679069519\n",
            "episode : 4, timestep : 8856000, average reward : -69.30000305175781\n",
            "episode : 8, timestep : 8858400, average reward : -82.91000366210938\n",
            "episode : 5, timestep : 8860800, average reward : -66.61000061035156\n",
            "episode : 5, timestep : 8863200, average reward : -61.959999084472656\n",
            "[8863744] Avg reward (last 50 episodes): -0.08532271534204483\n",
            "episode : 4, timestep : 8865600, average reward : -46.029998779296875\n",
            "episode : 5, timestep : 8868000, average reward : -88.05000305175781\n",
            "episode : 5, timestep : 8870400, average reward : -75.33000183105469\n",
            "[8871936] Avg reward (last 50 episodes): -0.08220024406909943\n",
            "episode : 7, timestep : 8872800, average reward : -81.58000183105469\n",
            "episode : 9, timestep : 8875200, average reward : -90.44999694824219\n",
            "episode : 7, timestep : 8877600, average reward : -77.19000244140625\n",
            "episode : 12, timestep : 8880000, average reward : -101.23999786376953\n",
            "[8880128] Avg reward (last 50 episodes): 0.016888825222849846\n",
            "episode : 7, timestep : 8882400, average reward : -84.55000305175781\n",
            "episode : 10, timestep : 8884800, average reward : -87.05999755859375\n",
            "episode : 6, timestep : 8887200, average reward : -90.68000030517578\n",
            "[8888320] Avg reward (last 50 episodes): -0.12081720679998398\n",
            "episode : 7, timestep : 8889600, average reward : -101.13999938964844\n",
            "episode : 5, timestep : 8892000, average reward : -60.720001220703125\n",
            "episode : 8, timestep : 8894400, average reward : -96.01000213623047\n",
            "[8896512] Avg reward (last 50 episodes): -0.04634842276573181\n",
            "episode : 9, timestep : 8896800, average reward : -85.95999908447266\n",
            "episode : 6, timestep : 8899200, average reward : -80.86000061035156\n",
            "episode : 8, timestep : 8901600, average reward : -92.16000366210938\n",
            "episode : 12, timestep : 8904000, average reward : -96.44999694824219\n",
            "[8904704] Avg reward (last 50 episodes): -0.09122732281684875\n",
            "episode : 9, timestep : 8906400, average reward : -88.77999877929688\n",
            "episode : 6, timestep : 8908800, average reward : -78.08999633789062\n",
            "episode : 10, timestep : 8911200, average reward : -99.5\n",
            "[8912896] Avg reward (last 50 episodes): -0.05858666077256203\n",
            "episode : 12, timestep : 8913600, average reward : -101.66999816894531\n",
            "episode : 9, timestep : 8916000, average reward : -88.55000305175781\n",
            "episode : 13, timestep : 8918400, average reward : -100.08000183105469\n",
            "episode : 11, timestep : 8920800, average reward : -104.93000030517578\n",
            "[8921088] Avg reward (last 50 episodes): -0.3065039813518524\n",
            "setting action_std to  0.5745\n",
            "episode : 14, timestep : 8923200, average reward : -109.44999694824219\n",
            "episode : 9, timestep : 8925600, average reward : -96.33999633789062\n",
            "episode : 13, timestep : 8928000, average reward : -107.68000030517578\n",
            "[8929280] Avg reward (last 50 episodes): -0.051458731293678284\n",
            "episode : 9, timestep : 8930400, average reward : -94.25\n",
            "episode : 8, timestep : 8932800, average reward : -87.86000061035156\n",
            "episode : 7, timestep : 8935200, average reward : -93.56999969482422\n",
            "[8937472] Avg reward (last 50 episodes): -0.05229249596595764\n",
            "episode : 9, timestep : 8937600, average reward : -90.22000122070312\n",
            "episode : 7, timestep : 8940000, average reward : -79.88999938964844\n",
            "episode : 9, timestep : 8942400, average reward : -94.4800033569336\n",
            "episode : 9, timestep : 8944800, average reward : -97.5\n",
            "[8945664] Avg reward (last 50 episodes): -0.09966327995061874\n",
            "episode : 10, timestep : 8947200, average reward : -95.25\n",
            "episode : 10, timestep : 8949600, average reward : -91.12000274658203\n",
            "episode : 14, timestep : 8952000, average reward : -105.80000305175781\n",
            "[8953856] Avg reward (last 50 episodes): -0.11142472177743912\n",
            "episode : 18, timestep : 8954400, average reward : -108.68000030517578\n",
            "episode : 7, timestep : 8956800, average reward : -91.16999816894531\n",
            "episode : 9, timestep : 8959200, average reward : -97.0999984741211\n",
            "episode : 12, timestep : 8961600, average reward : -102.93000030517578\n",
            "[8962048] Avg reward (last 50 episodes): -0.1306571513414383\n",
            "episode : 10, timestep : 8964000, average reward : -107.9800033569336\n",
            "episode : 19, timestep : 8966400, average reward : -110.5999984741211\n",
            "episode : 13, timestep : 8968800, average reward : -119.61000061035156\n",
            "[8970240] Avg reward (last 50 episodes): -0.08653417229652405\n",
            "episode : 12, timestep : 8971200, average reward : -117.27999877929688\n",
            "episode : 15, timestep : 8973600, average reward : -119.68000030517578\n",
            "episode : 15, timestep : 8976000, average reward : -117.93000030517578\n",
            "episode : 12, timestep : 8978400, average reward : -106.37000274658203\n",
            "[8978432] Avg reward (last 50 episodes): -0.09925079345703125\n",
            "episode : 11, timestep : 8980800, average reward : -105.31999969482422\n",
            "episode : 13, timestep : 8983200, average reward : -111.31999969482422\n",
            "episode : 10, timestep : 8985600, average reward : -109.08000183105469\n",
            "[8986624] Avg reward (last 50 episodes): -2.1542242849245667\n",
            "episode : 13, timestep : 8988000, average reward : -103.55999755859375\n",
            "episode : 10, timestep : 8990400, average reward : -115.33999633789062\n",
            "episode : 13, timestep : 8992800, average reward : -111.9800033569336\n",
            "[8994816] Avg reward (last 50 episodes): -2.302473141774535\n",
            "episode : 15, timestep : 8995200, average reward : -110.31999969482422\n",
            "episode : 12, timestep : 8997600, average reward : -107.44000244140625\n",
            "episode : 13, timestep : 9000000, average reward : -111.30000305175781\n",
            "episode : 11, timestep : 9002400, average reward : -110.26000213623047\n",
            "[9003008] Avg reward (last 50 episodes): -2.089222940914333\n",
            "episode : 15, timestep : 9004800, average reward : -108.86000061035156\n",
            "episode : 10, timestep : 9007200, average reward : -122.0\n",
            "episode : 17, timestep : 9009600, average reward : -111.97000122070312\n",
            "[9011200] Avg reward (last 50 episodes): -0.05737687274813652\n",
            "episode : 11, timestep : 9012000, average reward : -112.4000015258789\n",
            "episode : 12, timestep : 9014400, average reward : -107.16000366210938\n",
            "episode : 11, timestep : 9016800, average reward : -111.8499984741211\n",
            "episode : 10, timestep : 9019200, average reward : -104.19000244140625\n",
            "[9019392] Avg reward (last 50 episodes): -0.11600177735090256\n",
            "episode : 14, timestep : 9021600, average reward : -113.11000061035156\n",
            "setting action_std to  0.5742\n",
            "episode : 12, timestep : 9024000, average reward : -121.01000213623047\n",
            "episode : 18, timestep : 9026400, average reward : -116.0\n",
            "[9027584] Avg reward (last 50 episodes): -0.0871184766292572\n",
            "episode : 15, timestep : 9028800, average reward : -116.76000213623047\n",
            "episode : 11, timestep : 9031200, average reward : -122.45999908447266\n",
            "episode : 20, timestep : 9033600, average reward : -110.76000213623047\n",
            "[9035776] Avg reward (last 50 episodes): -0.08585463464260101\n",
            "episode : 13, timestep : 9036000, average reward : -102.41000366210938\n",
            "episode : 14, timestep : 9038400, average reward : -107.69000244140625\n",
            "episode : 14, timestep : 9040800, average reward : -104.20999908447266\n",
            "episode : 18, timestep : 9043200, average reward : -119.54000091552734\n",
            "[9043968] Avg reward (last 50 episodes): -0.08938129246234894\n",
            "episode : 15, timestep : 9045600, average reward : -116.68000030517578\n",
            "episode : 12, timestep : 9048000, average reward : -117.12999725341797\n",
            "episode : 8, timestep : 9050400, average reward : -114.91999816894531\n",
            "[9052160] Avg reward (last 50 episodes): -0.09345082938671112\n",
            "episode : 7, timestep : 9052800, average reward : -96.44000244140625\n",
            "episode : 14, timestep : 9055200, average reward : -116.83000183105469\n",
            "episode : 14, timestep : 9057600, average reward : -118.77999877929688\n",
            "episode : 14, timestep : 9060000, average reward : -98.54000091552734\n",
            "[9060352] Avg reward (last 50 episodes): -0.07262216508388519\n",
            "episode : 13, timestep : 9062400, average reward : -112.79000091552734\n",
            "episode : 8, timestep : 9064800, average reward : -101.66000366210938\n",
            "episode : 17, timestep : 9067200, average reward : -118.41000366210938\n",
            "[9068544] Avg reward (last 50 episodes): -0.1111692413687706\n",
            "episode : 8, timestep : 9069600, average reward : -94.4000015258789\n",
            "episode : 12, timestep : 9072000, average reward : -110.38999938964844\n",
            "episode : 10, timestep : 9074400, average reward : -107.54000091552734\n",
            "[9076736] Avg reward (last 50 episodes): -2.1042015528678895\n",
            "episode : 8, timestep : 9076800, average reward : -90.19999694824219\n",
            "episode : 7, timestep : 9079200, average reward : -101.83000183105469\n",
            "episode : 7, timestep : 9081600, average reward : -89.80999755859375\n",
            "episode : 7, timestep : 9084000, average reward : -104.55999755859375\n",
            "[9084928] Avg reward (last 50 episodes): -0.0760975107550621\n",
            "episode : 8, timestep : 9086400, average reward : -117.0\n",
            "episode : 9, timestep : 9088800, average reward : -98.20999908447266\n",
            "episode : 7, timestep : 9091200, average reward : -102.31999969482422\n",
            "[9093120] Avg reward (last 50 episodes): -0.06383360922336578\n",
            "episode : 11, timestep : 9093600, average reward : -110.30000305175781\n",
            "episode : 5, timestep : 9096000, average reward : -80.1500015258789\n",
            "episode : 15, timestep : 9098400, average reward : -116.88999938964844\n",
            "episode : 16, timestep : 9100800, average reward : -116.61000061035156\n",
            "[9101312] Avg reward (last 50 episodes): -0.08702857792377472\n",
            "episode : 7, timestep : 9103200, average reward : -95.81999969482422\n",
            "episode : 7, timestep : 9105600, average reward : -90.66999816894531\n",
            "episode : 8, timestep : 9108000, average reward : -104.62999725341797\n",
            "[9109504] Avg reward (last 50 episodes): -0.05844264477491379\n",
            "episode : 8, timestep : 9110400, average reward : -105.0199966430664\n",
            "episode : 6, timestep : 9112800, average reward : -68.0999984741211\n",
            "episode : 10, timestep : 9115200, average reward : -98.75\n",
            "episode : 11, timestep : 9117600, average reward : -96.58999633789062\n",
            "[9117696] Avg reward (last 50 episodes): -2.1269326522015035\n",
            "episode : 9, timestep : 9120000, average reward : -86.23999786376953\n",
            "episode : 13, timestep : 9122400, average reward : -101.38999938964844\n",
            "setting action_std to  0.5739\n",
            "episode : 9, timestep : 9124800, average reward : -84.5999984741211\n",
            "[9125888] Avg reward (last 50 episodes): -0.1379561573266983\n",
            "episode : 5, timestep : 9127200, average reward : -57.130001068115234\n",
            "episode : 10, timestep : 9129600, average reward : -95.70999908447266\n",
            "episode : 4, timestep : 9132000, average reward : -57.83000183105469\n",
            "[9134080] Avg reward (last 50 episodes): -0.09313689917325974\n",
            "episode : 11, timestep : 9134400, average reward : -89.2699966430664\n",
            "episode : 8, timestep : 9136800, average reward : -88.06999969482422\n",
            "episode : 7, timestep : 9139200, average reward : -84.5999984741211\n",
            "episode : 10, timestep : 9141600, average reward : -93.58999633789062\n",
            "[9142272] Avg reward (last 50 episodes): -0.09550052881240845\n",
            "episode : 11, timestep : 9144000, average reward : -94.7300033569336\n",
            "episode : 11, timestep : 9146400, average reward : -95.98999786376953\n",
            "episode : 6, timestep : 9148800, average reward : -67.36000061035156\n",
            "[9150464] Avg reward (last 50 episodes): -2.168603397393599\n",
            "episode : 15, timestep : 9151200, average reward : -100.33000183105469\n",
            "episode : 11, timestep : 9153600, average reward : -108.94999694824219\n",
            "episode : 13, timestep : 9156000, average reward : -104.91000366210938\n",
            "episode : 13, timestep : 9158400, average reward : -105.0199966430664\n",
            "[9158656] Avg reward (last 50 episodes): -0.1019684225320816\n",
            "episode : 9, timestep : 9160800, average reward : -90.5\n",
            "episode : 9, timestep : 9163200, average reward : -88.12000274658203\n",
            "episode : 12, timestep : 9165600, average reward : -96.4800033569336\n",
            "[9166848] Avg reward (last 50 episodes): -0.10588984191417694\n",
            "episode : 7, timestep : 9168000, average reward : -83.05000305175781\n",
            "episode : 10, timestep : 9170400, average reward : -86.41000366210938\n",
            "episode : 7, timestep : 9172800, average reward : -83.63999938964844\n",
            "[9175040] Avg reward (last 50 episodes): -0.051349662244319916\n",
            "episode : 12, timestep : 9175200, average reward : -102.30999755859375\n",
            "episode : 11, timestep : 9177600, average reward : -87.0\n",
            "episode : 10, timestep : 9180000, average reward : -89.66000366210938\n",
            "episode : 9, timestep : 9182400, average reward : -90.80999755859375\n",
            "[9183232] Avg reward (last 50 episodes): -2.0935049068741503\n",
            "episode : 9, timestep : 9184800, average reward : -98.7300033569336\n",
            "episode : 15, timestep : 9187200, average reward : -100.2300033569336\n",
            "episode : 13, timestep : 9189600, average reward : -96.01000213623047\n",
            "[9191424] Avg reward (last 50 episodes): -2.0982653461955487\n",
            "episode : 9, timestep : 9192000, average reward : -96.52999877929688\n",
            "episode : 10, timestep : 9194400, average reward : -94.61000061035156\n",
            "episode : 16, timestep : 9196800, average reward : -99.2300033569336\n",
            "episode : 14, timestep : 9199200, average reward : -101.31999969482422\n",
            "[9199616] Avg reward (last 50 episodes): -0.05909125879406929\n",
            "episode : 10, timestep : 9201600, average reward : -91.86000061035156\n",
            "episode : 13, timestep : 9204000, average reward : -111.43000030517578\n",
            "episode : 12, timestep : 9206400, average reward : -96.41000366210938\n",
            "[9207808] Avg reward (last 50 episodes): -0.2408568412065506\n",
            "episode : 14, timestep : 9208800, average reward : -99.55999755859375\n",
            "episode : 5, timestep : 9211200, average reward : -70.62999725341797\n",
            "episode : 8, timestep : 9213600, average reward : -79.16000366210938\n",
            "[9216000] Avg reward (last 50 episodes): -0.08522644639015198\n",
            "episode : 5, timestep : 9216000, average reward : -71.56999969482422\n",
            "episode : 10, timestep : 9218400, average reward : -92.19999694824219\n",
            "episode : 8, timestep : 9220800, average reward : -86.27999877929688\n",
            "setting action_std to  0.5736\n",
            "episode : 11, timestep : 9223200, average reward : -95.75\n",
            "[9224192] Avg reward (last 50 episodes): -0.04689063876867294\n",
            "episode : 9, timestep : 9225600, average reward : -92.05999755859375\n",
            "episode : 9, timestep : 9228000, average reward : -92.55000305175781\n",
            "episode : 10, timestep : 9230400, average reward : -88.66000366210938\n",
            "[9232384] Avg reward (last 50 episodes): -0.09940648078918457\n",
            "episode : 7, timestep : 9232800, average reward : -86.4800033569336\n",
            "episode : 13, timestep : 9235200, average reward : -100.13999938964844\n",
            "episode : 17, timestep : 9237600, average reward : -114.41999816894531\n",
            "episode : 12, timestep : 9240000, average reward : -98.16999816894531\n",
            "[9240576] Avg reward (last 50 episodes): -0.08067656308412552\n",
            "episode : 12, timestep : 9242400, average reward : -92.77999877929688\n",
            "episode : 13, timestep : 9244800, average reward : -105.12000274658203\n",
            "episode : 10, timestep : 9247200, average reward : -85.72000122070312\n",
            "[9248768] Avg reward (last 50 episodes): -2.188988681025803\n",
            "episode : 14, timestep : 9249600, average reward : -106.91999816894531\n",
            "episode : 7, timestep : 9252000, average reward : -84.55000305175781\n",
            "episode : 10, timestep : 9254400, average reward : -88.20999908447266\n",
            "episode : 13, timestep : 9256800, average reward : -102.62000274658203\n",
            "[9256960] Avg reward (last 50 episodes): -0.03271147608757019\n",
            "episode : 4, timestep : 9259200, average reward : -46.40999984741211\n",
            "episode : 12, timestep : 9261600, average reward : -104.01000213623047\n",
            "episode : 9, timestep : 9264000, average reward : -81.37000274658203\n",
            "[9265152] Avg reward (last 50 episodes): -0.09911933541297913\n",
            "episode : 11, timestep : 9266400, average reward : -96.12000274658203\n",
            "episode : 18, timestep : 9268800, average reward : -106.41000366210938\n",
            "episode : 15, timestep : 9271200, average reward : -107.66999816894531\n",
            "[9273344] Avg reward (last 50 episodes): -0.17685091495513916\n",
            "episode : 10, timestep : 9273600, average reward : -98.5199966430664\n",
            "episode : 6, timestep : 9276000, average reward : -80.6500015258789\n",
            "episode : 10, timestep : 9278400, average reward : -92.43000030517578\n",
            "episode : 9, timestep : 9280800, average reward : -84.11000061035156\n",
            "[9281536] Avg reward (last 50 episodes): 0.09653033316135406\n",
            "episode : 5, timestep : 9283200, average reward : -63.04999923706055\n",
            "episode : 4, timestep : 9285600, average reward : -44.790000915527344\n",
            "episode : 4, timestep : 9288000, average reward : -44.939998626708984\n",
            "[9289728] Avg reward (last 50 episodes): -0.0696658343076706\n",
            "episode : 4, timestep : 9290400, average reward : -57.18000030517578\n",
            "episode : 6, timestep : 9292800, average reward : -74.87000274658203\n",
            "episode : 6, timestep : 9295200, average reward : -69.47000122070312\n",
            "episode : 4, timestep : 9297600, average reward : -42.58000183105469\n",
            "[9297920] Avg reward (last 50 episodes): -2.2193758684024214\n",
            "episode : 7, timestep : 9300000, average reward : -106.04000091552734\n",
            "episode : 9, timestep : 9302400, average reward : -105.30999755859375\n",
            "episode : 7, timestep : 9304800, average reward : -91.3499984741211\n",
            "[9306112] Avg reward (last 50 episodes): -0.07839586585760117\n",
            "episode : 7, timestep : 9307200, average reward : -77.81999969482422\n",
            "episode : 5, timestep : 9309600, average reward : -62.31999969482422\n",
            "episode : 4, timestep : 9312000, average reward : -50.08000183105469\n",
            "[9314304] Avg reward (last 50 episodes): -0.06613146513700485\n",
            "episode : 5, timestep : 9314400, average reward : -79.30999755859375\n",
            "episode : 5, timestep : 9316800, average reward : -75.08999633789062\n",
            "episode : 4, timestep : 9319200, average reward : -66.23999786376953\n",
            "episode : 5, timestep : 9321600, average reward : -63.36000061035156\n",
            "[9322496] Avg reward (last 50 episodes): -0.05260326713323593\n",
            "setting action_std to  0.5733\n",
            "episode : 5, timestep : 9324000, average reward : -61.060001373291016\n",
            "episode : 5, timestep : 9326400, average reward : -61.189998626708984\n",
            "episode : 4, timestep : 9328800, average reward : -52.5\n",
            "[9330688] Avg reward (last 50 episodes): -0.07282093167304993\n",
            "episode : 4, timestep : 9331200, average reward : -48.58000183105469\n",
            "episode : 4, timestep : 9333600, average reward : -44.380001068115234\n",
            "episode : 4, timestep : 9336000, average reward : -44.11000061035156\n",
            "episode : 5, timestep : 9338400, average reward : -64.23999786376953\n",
            "[9338880] Avg reward (last 50 episodes): -0.14311662316322327\n",
            "episode : 4, timestep : 9340800, average reward : -45.61000061035156\n",
            "episode : 4, timestep : 9343200, average reward : -44.970001220703125\n",
            "episode : 4, timestep : 9345600, average reward : -47.33000183105469\n",
            "[9347072] Avg reward (last 50 episodes): -0.05029136314988136\n",
            "episode : 5, timestep : 9348000, average reward : -55.13999938964844\n",
            "episode : 4, timestep : 9350400, average reward : -65.08000183105469\n",
            "episode : 5, timestep : 9352800, average reward : -59.810001373291016\n",
            "episode : 5, timestep : 9355200, average reward : -62.59000015258789\n",
            "[9355264] Avg reward (last 50 episodes): -0.08292502164840698\n",
            "episode : 4, timestep : 9357600, average reward : -68.12999725341797\n",
            "episode : 4, timestep : 9360000, average reward : -45.970001220703125\n",
            "episode : 5, timestep : 9362400, average reward : -57.529998779296875\n",
            "[9363456] Avg reward (last 50 episodes): -0.15710757672786713\n",
            "episode : 4, timestep : 9364800, average reward : -42.31999969482422\n",
            "episode : 5, timestep : 9367200, average reward : -76.56999969482422\n",
            "episode : 4, timestep : 9369600, average reward : -39.060001373291016\n",
            "[9371648] Avg reward (last 50 episodes): -0.0670563355088234\n",
            "episode : 4, timestep : 9372000, average reward : -39.77000045776367\n",
            "episode : 5, timestep : 9374400, average reward : -57.0099983215332\n",
            "episode : 5, timestep : 9376800, average reward : -55.630001068115234\n",
            "episode : 4, timestep : 9379200, average reward : -68.33999633789062\n",
            "[9379840] Avg reward (last 50 episodes): -0.18388454616069794\n",
            "episode : 4, timestep : 9381600, average reward : -67.87999725341797\n",
            "episode : 5, timestep : 9384000, average reward : -59.45000076293945\n",
            "episode : 4, timestep : 9386400, average reward : -46.0\n",
            "[9388032] Avg reward (last 50 episodes): -0.06169053912162781\n",
            "episode : 4, timestep : 9388800, average reward : -46.959999084472656\n",
            "episode : 5, timestep : 9391200, average reward : -57.2599983215332\n",
            "episode : 5, timestep : 9393600, average reward : -74.66999816894531\n",
            "episode : 7, timestep : 9396000, average reward : -72.18000030517578\n",
            "[9396224] Avg reward (last 50 episodes): -0.09576590359210968\n",
            "episode : 7, timestep : 9398400, average reward : -87.3499984741211\n",
            "episode : 4, timestep : 9400800, average reward : -43.959999084472656\n",
            "episode : 6, timestep : 9403200, average reward : -68.72000122070312\n",
            "[9404416] Avg reward (last 50 episodes): -0.0696120336651802\n",
            "episode : 4, timestep : 9405600, average reward : -42.66999816894531\n",
            "episode : 7, timestep : 9408000, average reward : -89.83000183105469\n",
            "episode : 6, timestep : 9410400, average reward : -72.95999908447266\n",
            "[9412608] Avg reward (last 50 episodes): -2.2543684187158943\n",
            "episode : 8, timestep : 9412800, average reward : -108.22000122070312\n",
            "episode : 8, timestep : 9415200, average reward : -92.88999938964844\n",
            "episode : 6, timestep : 9417600, average reward : -80.05000305175781\n",
            "episode : 6, timestep : 9420000, average reward : -69.97000122070312\n",
            "[9420800] Avg reward (last 50 episodes): -0.11691368371248245\n",
            "episode : 4, timestep : 9422400, average reward : -49.34000015258789\n",
            "setting action_std to  0.573\n",
            "episode : 4, timestep : 9424800, average reward : -46.810001373291016\n",
            "episode : 5, timestep : 9427200, average reward : -63.45000076293945\n",
            "[9428992] Avg reward (last 50 episodes): -0.12812113761901855\n",
            "episode : 5, timestep : 9429600, average reward : -59.97999954223633\n",
            "episode : 4, timestep : 9432000, average reward : -43.45000076293945\n",
            "episode : 4, timestep : 9434400, average reward : -46.709999084472656\n",
            "episode : 4, timestep : 9436800, average reward : -43.0099983215332\n",
            "[9437184] Avg reward (last 50 episodes): -0.10014626383781433\n",
            "episode : 4, timestep : 9439200, average reward : -44.4900016784668\n",
            "episode : 4, timestep : 9441600, average reward : -46.43000030517578\n",
            "episode : 4, timestep : 9444000, average reward : -44.650001525878906\n",
            "[9445376] Avg reward (last 50 episodes): -0.0849815383553505\n",
            "episode : 5, timestep : 9446400, average reward : -82.33000183105469\n",
            "episode : 5, timestep : 9448800, average reward : -52.599998474121094\n",
            "episode : 4, timestep : 9451200, average reward : -43.31999969482422\n",
            "[9453568] Avg reward (last 50 episodes): 0.08933845162391663\n",
            "episode : 4, timestep : 9453600, average reward : -43.54999923706055\n",
            "episode : 4, timestep : 9456000, average reward : -70.69000244140625\n",
            "episode : 4, timestep : 9458400, average reward : -46.130001068115234\n",
            "episode : 4, timestep : 9460800, average reward : -43.13999938964844\n",
            "[9461760] Avg reward (last 50 episodes): 0.038030389696359634\n",
            "episode : 4, timestep : 9463200, average reward : -41.119998931884766\n",
            "episode : 4, timestep : 9465600, average reward : -43.9900016784668\n",
            "episode : 4, timestep : 9468000, average reward : -42.779998779296875\n",
            "[9469952] Avg reward (last 50 episodes): 0.03147361800074577\n",
            "episode : 4, timestep : 9470400, average reward : -41.5099983215332\n",
            "episode : 4, timestep : 9472800, average reward : -43.36000061035156\n",
            "episode : 7, timestep : 9475200, average reward : -75.97000122070312\n",
            "episode : 7, timestep : 9477600, average reward : -72.43000030517578\n",
            "[9478144] Avg reward (last 50 episodes): 0.024179086089134216\n",
            "episode : 5, timestep : 9480000, average reward : -75.93000030517578\n",
            "episode : 6, timestep : 9482400, average reward : -82.76000213623047\n",
            "episode : 4, timestep : 9484800, average reward : -43.560001373291016\n",
            "[9486336] Avg reward (last 50 episodes): -0.10153617709875107\n",
            "episode : 5, timestep : 9487200, average reward : -56.849998474121094\n",
            "episode : 5, timestep : 9489600, average reward : -55.029998779296875\n",
            "episode : 4, timestep : 9492000, average reward : -48.72999954223633\n",
            "episode : 5, timestep : 9494400, average reward : -53.52000045776367\n",
            "[9494528] Avg reward (last 50 episodes): -0.050420284271240234\n",
            "episode : 4, timestep : 9496800, average reward : -67.33000183105469\n",
            "episode : 4, timestep : 9499200, average reward : -37.43000030517578\n",
            "episode : 5, timestep : 9501600, average reward : -56.4900016784668\n",
            "[9502720] Avg reward (last 50 episodes): -0.22395877540111542\n",
            "episode : 6, timestep : 9504000, average reward : -73.5999984741211\n",
            "episode : 4, timestep : 9506400, average reward : -44.90999984741211\n",
            "episode : 4, timestep : 9508800, average reward : -49.0099983215332\n",
            "[9510912] Avg reward (last 50 episodes): -0.052650582045316696\n",
            "episode : 5, timestep : 9511200, average reward : -80.04000091552734\n",
            "episode : 4, timestep : 9513600, average reward : -60.130001068115234\n",
            "episode : 5, timestep : 9516000, average reward : -57.40999984741211\n",
            "episode : 4, timestep : 9518400, average reward : -45.779998779296875\n",
            "[9519104] Avg reward (last 50 episodes): -0.11820418387651443\n",
            "episode : 5, timestep : 9520800, average reward : -59.290000915527344\n",
            "episode : 6, timestep : 9523200, average reward : -64.7699966430664\n",
            "setting action_std to  0.5727\n",
            "episode : 4, timestep : 9525600, average reward : -40.52000045776367\n",
            "[9527296] Avg reward (last 50 episodes): -0.06408441066741943\n",
            "episode : 4, timestep : 9528000, average reward : -37.540000915527344\n",
            "episode : 4, timestep : 9530400, average reward : -39.810001373291016\n",
            "episode : 4, timestep : 9532800, average reward : -58.72999954223633\n",
            "episode : 4, timestep : 9535200, average reward : -42.4900016784668\n",
            "[9535488] Avg reward (last 50 episodes): 0.03148280456662178\n",
            "episode : 4, timestep : 9537600, average reward : -35.189998626708984\n",
            "episode : 6, timestep : 9540000, average reward : -71.3499984741211\n",
            "episode : 4, timestep : 9542400, average reward : -40.77000045776367\n",
            "[9543680] Avg reward (last 50 episodes): -0.014659489504992962\n",
            "episode : 4, timestep : 9544800, average reward : -67.66999816894531\n",
            "episode : 6, timestep : 9547200, average reward : -92.22000122070312\n",
            "episode : 4, timestep : 9549600, average reward : -40.349998474121094\n",
            "[9551872] Avg reward (last 50 episodes): -2.2743066753447057\n",
            "episode : 6, timestep : 9552000, average reward : -83.91999816894531\n",
            "episode : 4, timestep : 9554400, average reward : -41.4900016784668\n",
            "episode : 5, timestep : 9556800, average reward : -77.94000244140625\n",
            "episode : 5, timestep : 9559200, average reward : -63.31999969482422\n",
            "[9560064] Avg reward (last 50 episodes): -0.0898713618516922\n",
            "episode : 4, timestep : 9561600, average reward : -40.869998931884766\n",
            "episode : 4, timestep : 9564000, average reward : -41.18000030517578\n",
            "episode : 4, timestep : 9566400, average reward : -50.130001068115234\n",
            "[9568256] Avg reward (last 50 episodes): -0.021590011194348335\n",
            "episode : 4, timestep : 9568800, average reward : -42.66999816894531\n",
            "episode : 4, timestep : 9571200, average reward : -46.88999938964844\n",
            "episode : 4, timestep : 9573600, average reward : -45.02000045776367\n",
            "episode : 5, timestep : 9576000, average reward : -62.779998779296875\n",
            "[9576448] Avg reward (last 50 episodes): -0.16484381258487701\n",
            "episode : 4, timestep : 9578400, average reward : -45.2400016784668\n",
            "episode : 4, timestep : 9580800, average reward : -40.91999816894531\n",
            "episode : 4, timestep : 9583200, average reward : -70.31999969482422\n",
            "[9584640] Avg reward (last 50 episodes): -0.14701971411705017\n",
            "episode : 4, timestep : 9585600, average reward : -47.66999816894531\n",
            "episode : 6, timestep : 9588000, average reward : -68.44000244140625\n",
            "episode : 4, timestep : 9590400, average reward : -44.2599983215332\n",
            "episode : 4, timestep : 9592800, average reward : -45.130001068115234\n",
            "[9592832] Avg reward (last 50 episodes): -0.06176160275936127\n",
            "episode : 4, timestep : 9595200, average reward : -47.91999816894531\n",
            "episode : 5, timestep : 9597600, average reward : -103.33000183105469\n",
            "episode : 4, timestep : 9600000, average reward : -46.650001525878906\n",
            "[9601024] Avg reward (last 50 episodes): 0.05489257723093033\n",
            "episode : 4, timestep : 9602400, average reward : -38.310001373291016\n",
            "episode : 4, timestep : 9604800, average reward : -43.099998474121094\n",
            "episode : 5, timestep : 9607200, average reward : -64.08999633789062\n",
            "[9609216] Avg reward (last 50 episodes): -0.0224405899643898\n",
            "episode : 4, timestep : 9609600, average reward : -67.81999969482422\n",
            "episode : 4, timestep : 9612000, average reward : -42.68000030517578\n",
            "episode : 4, timestep : 9614400, average reward : -41.810001373291016\n",
            "episode : 4, timestep : 9616800, average reward : -44.0099983215332\n",
            "[9617408] Avg reward (last 50 episodes): -0.054169341921806335\n",
            "episode : 4, timestep : 9619200, average reward : -42.099998474121094\n",
            "episode : 4, timestep : 9621600, average reward : -46.84000015258789\n",
            "setting action_std to  0.5724\n",
            "episode : 4, timestep : 9624000, average reward : -43.63999938964844\n",
            "[9625600] Avg reward (last 50 episodes): -0.05927775800228119\n",
            "episode : 4, timestep : 9626400, average reward : -43.72999954223633\n",
            "episode : 5, timestep : 9628800, average reward : -67.19000244140625\n",
            "episode : 4, timestep : 9631200, average reward : -73.12999725341797\n",
            "episode : 4, timestep : 9633600, average reward : -46.34000015258789\n",
            "[9633792] Avg reward (last 50 episodes): -0.13694709539413452\n",
            "episode : 4, timestep : 9636000, average reward : -49.45000076293945\n",
            "episode : 4, timestep : 9638400, average reward : -51.16999816894531\n",
            "episode : 4, timestep : 9640800, average reward : -51.040000915527344\n",
            "[9641984] Avg reward (last 50 episodes): -0.02765081822872162\n",
            "episode : 4, timestep : 9643200, average reward : -51.439998626708984\n",
            "episode : 5, timestep : 9645600, average reward : -55.93000030517578\n",
            "episode : 4, timestep : 9648000, average reward : -48.02000045776367\n",
            "[9650176] Avg reward (last 50 episodes): 0.012650884687900543\n",
            "episode : 4, timestep : 9650400, average reward : -36.90999984741211\n",
            "episode : 4, timestep : 9652800, average reward : -44.4900016784668\n",
            "episode : 4, timestep : 9655200, average reward : -43.86000061035156\n",
            "episode : 4, timestep : 9657600, average reward : -46.02000045776367\n",
            "[9658368] Avg reward (last 50 episodes): -0.07041215896606445\n",
            "episode : 4, timestep : 9660000, average reward : -52.54999923706055\n",
            "episode : 4, timestep : 9662400, average reward : -54.0\n",
            "episode : 4, timestep : 9664800, average reward : -52.40999984741211\n",
            "[9666560] Avg reward (last 50 episodes): -0.16194477677345276\n",
            "episode : 5, timestep : 9667200, average reward : -66.88999938964844\n",
            "episode : 5, timestep : 9669600, average reward : -71.4000015258789\n",
            "episode : 4, timestep : 9672000, average reward : -49.04999923706055\n",
            "episode : 4, timestep : 9674400, average reward : -50.040000915527344\n",
            "[9674752] Avg reward (last 50 episodes): -0.09747272729873657\n",
            "episode : 4, timestep : 9676800, average reward : -51.720001220703125\n",
            "episode : 4, timestep : 9679200, average reward : -73.23999786376953\n",
            "episode : 4, timestep : 9681600, average reward : -47.18000030517578\n",
            "[9682944] Avg reward (last 50 episodes): -0.05184684693813324\n",
            "episode : 4, timestep : 9684000, average reward : -49.43000030517578\n",
            "episode : 4, timestep : 9686400, average reward : -44.099998474121094\n",
            "episode : 4, timestep : 9688800, average reward : -45.790000915527344\n",
            "[9691136] Avg reward (last 50 episodes): -0.02433682046830654\n",
            "episode : 5, timestep : 9691200, average reward : -69.2699966430664\n",
            "episode : 4, timestep : 9693600, average reward : -50.84000015258789\n",
            "episode : 4, timestep : 9696000, average reward : -47.40999984741211\n",
            "episode : 4, timestep : 9698400, average reward : -51.45000076293945\n",
            "[9699328] Avg reward (last 50 episodes): -0.020328745245933533\n",
            "episode : 4, timestep : 9700800, average reward : -51.959999084472656\n",
            "episode : 4, timestep : 9703200, average reward : -80.86000061035156\n",
            "episode : 4, timestep : 9705600, average reward : -78.75\n",
            "[9707520] Avg reward (last 50 episodes): -0.09344553202390671\n",
            "episode : 4, timestep : 9708000, average reward : -53.52000045776367\n",
            "episode : 4, timestep : 9710400, average reward : -52.130001068115234\n",
            "episode : 4, timestep : 9712800, average reward : -58.040000915527344\n",
            "episode : 4, timestep : 9715200, average reward : -51.08000183105469\n",
            "[9715712] Avg reward (last 50 episodes): -0.0567014105618\n",
            "episode : 4, timestep : 9717600, average reward : -56.470001220703125\n",
            "episode : 4, timestep : 9720000, average reward : -60.310001373291016\n",
            "episode : 4, timestep : 9722400, average reward : -55.79999923706055\n",
            "setting action_std to  0.5721\n",
            "[9723904] Avg reward (last 50 episodes): -0.09248363226652145\n",
            "episode : 4, timestep : 9724800, average reward : -49.09000015258789\n",
            "episode : 4, timestep : 9727200, average reward : -51.61000061035156\n",
            "episode : 4, timestep : 9729600, average reward : -50.11000061035156\n",
            "episode : 4, timestep : 9732000, average reward : -53.56999969482422\n",
            "[9732096] Avg reward (last 50 episodes): -0.06493491679430008\n",
            "episode : 4, timestep : 9734400, average reward : -51.95000076293945\n",
            "episode : 4, timestep : 9736800, average reward : -58.36000061035156\n",
            "episode : 4, timestep : 9739200, average reward : -54.790000915527344\n",
            "[9740288] Avg reward (last 50 episodes): -0.08423910290002823\n",
            "episode : 4, timestep : 9741600, average reward : -56.720001220703125\n",
            "episode : 5, timestep : 9744000, average reward : -71.4800033569336\n",
            "episode : 4, timestep : 9746400, average reward : -58.52000045776367\n",
            "[9748480] Avg reward (last 50 episodes): -0.1073203757405281\n",
            "episode : 4, timestep : 9748800, average reward : -56.119998931884766\n",
            "episode : 4, timestep : 9751200, average reward : -76.5999984741211\n",
            "episode : 4, timestep : 9753600, average reward : -53.79999923706055\n",
            "episode : 4, timestep : 9756000, average reward : -55.189998626708984\n",
            "[9756672] Avg reward (last 50 episodes): -0.16603803634643555\n",
            "episode : 5, timestep : 9758400, average reward : -70.6500015258789\n",
            "episode : 4, timestep : 9760800, average reward : -56.54999923706055\n",
            "episode : 4, timestep : 9763200, average reward : -59.43000030517578\n",
            "[9764864] Avg reward (last 50 episodes): -0.07914692163467407\n",
            "episode : 4, timestep : 9765600, average reward : -55.81999969482422\n",
            "episode : 4, timestep : 9768000, average reward : -57.310001373291016\n",
            "episode : 4, timestep : 9770400, average reward : -73.44999694824219\n",
            "episode : 4, timestep : 9772800, average reward : -54.689998626708984\n",
            "[9773056] Avg reward (last 50 episodes): -0.1262061446905136\n",
            "episode : 5, timestep : 9775200, average reward : -64.43000030517578\n",
            "episode : 4, timestep : 9777600, average reward : -54.68000030517578\n",
            "episode : 4, timestep : 9780000, average reward : -56.5\n",
            "[9781248] Avg reward (last 50 episodes): -0.09736132621765137\n",
            "episode : 4, timestep : 9782400, average reward : -59.13999938964844\n",
            "episode : 4, timestep : 9784800, average reward : -49.34000015258789\n",
            "episode : 4, timestep : 9787200, average reward : -52.5099983215332\n",
            "[9789440] Avg reward (last 50 episodes): -0.08285386860370636\n",
            "episode : 4, timestep : 9789600, average reward : -53.130001068115234\n",
            "episode : 4, timestep : 9792000, average reward : -49.959999084472656\n",
            "episode : 4, timestep : 9794400, average reward : -52.220001220703125\n",
            "episode : 4, timestep : 9796800, average reward : -49.599998474121094\n",
            "[9797632] Avg reward (last 50 episodes): -0.009742463007569313\n",
            "episode : 4, timestep : 9799200, average reward : -51.61000061035156\n",
            "episode : 4, timestep : 9801600, average reward : -52.16999816894531\n",
            "episode : 4, timestep : 9804000, average reward : -51.97999954223633\n",
            "[9805824] Avg reward (last 50 episodes): -0.08576515316963196\n",
            "episode : 4, timestep : 9806400, average reward : -53.16999816894531\n",
            "episode : 4, timestep : 9808800, average reward : -52.2599983215332\n",
            "episode : 4, timestep : 9811200, average reward : -54.20000076293945\n",
            "episode : 6, timestep : 9813600, average reward : -80.37000274658203\n",
            "[9814016] Avg reward (last 50 episodes): 0.007694963365793228\n",
            "episode : 4, timestep : 9816000, average reward : -53.45000076293945\n",
            "episode : 5, timestep : 9818400, average reward : -92.43000030517578\n",
            "episode : 4, timestep : 9820800, average reward : -57.56999969482422\n",
            "[9822208] Avg reward (last 50 episodes): -0.07489370554685593\n",
            "episode : 4, timestep : 9823200, average reward : -52.83000183105469\n",
            "setting action_std to  0.5718\n",
            "episode : 4, timestep : 9825600, average reward : -57.400001525878906\n",
            "episode : 5, timestep : 9828000, average reward : -68.88999938964844\n",
            "[9830400] Avg reward (last 50 episodes): -0.179733544588089\n",
            "episode : 4, timestep : 9830400, average reward : -55.970001220703125\n",
            "episode : 4, timestep : 9832800, average reward : -54.290000915527344\n",
            "episode : 4, timestep : 9835200, average reward : -60.31999969482422\n",
            "episode : 4, timestep : 9837600, average reward : -57.0099983215332\n",
            "[9838592] Avg reward (last 50 episodes): -0.08042443543672562\n",
            "episode : 4, timestep : 9840000, average reward : -55.15999984741211\n",
            "episode : 4, timestep : 9842400, average reward : -55.540000915527344\n",
            "episode : 4, timestep : 9844800, average reward : -57.36000061035156\n",
            "[9846784] Avg reward (last 50 episodes): -0.09027092903852463\n",
            "episode : 4, timestep : 9847200, average reward : -54.689998626708984\n",
            "episode : 4, timestep : 9849600, average reward : -68.97000122070312\n",
            "episode : 4, timestep : 9852000, average reward : -55.060001373291016\n",
            "episode : 6, timestep : 9854400, average reward : -83.80000305175781\n",
            "[9854976] Avg reward (last 50 episodes): -0.06157246604561806\n",
            "episode : 4, timestep : 9856800, average reward : -52.7599983215332\n",
            "episode : 4, timestep : 9859200, average reward : -56.209999084472656\n",
            "episode : 4, timestep : 9861600, average reward : -56.189998626708984\n",
            "[9863168] Avg reward (last 50 episodes): -0.0902889147400856\n",
            "episode : 4, timestep : 9864000, average reward : -56.63999938964844\n",
            "episode : 4, timestep : 9866400, average reward : -58.459999084472656\n",
            "episode : 4, timestep : 9868800, average reward : -52.70000076293945\n",
            "episode : 4, timestep : 9871200, average reward : -55.779998779296875\n",
            "[9871360] Avg reward (last 50 episodes): -0.17147710919380188\n",
            "episode : 4, timestep : 9873600, average reward : -57.95000076293945\n",
            "episode : 4, timestep : 9876000, average reward : -53.349998474121094\n",
            "episode : 4, timestep : 9878400, average reward : -54.15999984741211\n",
            "[9879552] Avg reward (last 50 episodes): -0.08290058374404907\n",
            "episode : 4, timestep : 9880800, average reward : -53.540000915527344\n",
            "episode : 4, timestep : 9883200, average reward : -52.20000076293945\n",
            "episode : 4, timestep : 9885600, average reward : -50.33000183105469\n",
            "[9887744] Avg reward (last 50 episodes): -0.17681573331356049\n",
            "episode : 4, timestep : 9888000, average reward : -53.0099983215332\n",
            "episode : 5, timestep : 9890400, average reward : -70.01000213623047\n",
            "episode : 5, timestep : 9892800, average reward : -80.94999694824219\n",
            "episode : 4, timestep : 9895200, average reward : -54.810001373291016\n",
            "[9895936] Avg reward (last 50 episodes): -0.08983224630355835\n",
            "episode : 5, timestep : 9897600, average reward : -69.52999877929688\n",
            "episode : 4, timestep : 9900000, average reward : -53.939998626708984\n",
            "episode : 5, timestep : 9902400, average reward : -67.77999877929688\n",
            "[9904128] Avg reward (last 50 episodes): -0.3309842646121979\n",
            "episode : 5, timestep : 9904800, average reward : -66.88999938964844\n",
            "episode : 4, timestep : 9907200, average reward : -53.560001373291016\n",
            "episode : 4, timestep : 9909600, average reward : -75.55000305175781\n",
            "episode : 4, timestep : 9912000, average reward : -53.720001220703125\n",
            "[9912320] Avg reward (last 50 episodes): -0.09290766716003418\n",
            "episode : 4, timestep : 9914400, average reward : -54.54999923706055\n",
            "episode : 5, timestep : 9916800, average reward : -71.47000122070312\n",
            "episode : 4, timestep : 9919200, average reward : -58.06999969482422\n",
            "[9920512] Avg reward (last 50 episodes): -0.0382271371781826\n",
            "episode : 4, timestep : 9921600, average reward : -52.77000045776367\n",
            "episode : 6, timestep : 9924000, average reward : -73.13999938964844\n",
            "setting action_std to  0.5715\n",
            "episode : 4, timestep : 9926400, average reward : -51.47999954223633\n",
            "[9928704] Avg reward (last 50 episodes): -0.10543752461671829\n",
            "episode : 4, timestep : 9928800, average reward : -76.6500015258789\n",
            "episode : 6, timestep : 9931200, average reward : -93.37000274658203\n",
            "episode : 6, timestep : 9933600, average reward : -85.25\n",
            "episode : 4, timestep : 9936000, average reward : -67.20999908447266\n",
            "[9936896] Avg reward (last 50 episodes): 0.02619791217148304\n",
            "episode : 4, timestep : 9938400, average reward : -50.060001373291016\n",
            "episode : 4, timestep : 9940800, average reward : -49.83000183105469\n",
            "episode : 4, timestep : 9943200, average reward : -49.68000030517578\n",
            "[9945088] Avg reward (last 50 episodes): -0.08670489490032196\n",
            "episode : 4, timestep : 9945600, average reward : -54.939998626708984\n",
            "episode : 6, timestep : 9948000, average reward : -77.69999694824219\n",
            "episode : 4, timestep : 9950400, average reward : -49.20000076293945\n",
            "episode : 5, timestep : 9952800, average reward : -62.4900016784668\n",
            "[9953280] Avg reward (last 50 episodes): -0.01800539344549179\n",
            "episode : 4, timestep : 9955200, average reward : -81.54000091552734\n",
            "episode : 4, timestep : 9957600, average reward : -51.11000061035156\n",
            "episode : 4, timestep : 9960000, average reward : -54.220001220703125\n",
            "[9961472] Avg reward (last 50 episodes): -0.13710446655750275\n",
            "episode : 4, timestep : 9962400, average reward : -48.7400016784668\n",
            "episode : 4, timestep : 9964800, average reward : -52.54999923706055\n",
            "episode : 4, timestep : 9967200, average reward : -51.33000183105469\n",
            "episode : 4, timestep : 9969600, average reward : -48.86000061035156\n",
            "[9969664] Avg reward (last 50 episodes): -0.1426215022802353\n",
            "episode : 4, timestep : 9972000, average reward : -54.34000015258789\n",
            "episode : 4, timestep : 9974400, average reward : -50.060001373291016\n",
            "episode : 4, timestep : 9976800, average reward : -57.959999084472656\n",
            "[9977856] Avg reward (last 50 episodes): -0.08888955414295197\n",
            "episode : 4, timestep : 9979200, average reward : -56.2400016784668\n",
            "episode : 5, timestep : 9981600, average reward : -69.33000183105469\n",
            "episode : 4, timestep : 9984000, average reward : -53.810001373291016\n",
            "[9986048] Avg reward (last 50 episodes): -0.09638935327529907\n",
            "episode : 5, timestep : 9986400, average reward : -67.8499984741211\n",
            "episode : 4, timestep : 9988800, average reward : -54.040000915527344\n",
            "episode : 4, timestep : 9991200, average reward : -53.529998779296875\n",
            "episode : 4, timestep : 9993600, average reward : -52.93000030517578\n",
            "[9994240] Avg reward (last 50 episodes): -0.11034655570983887\n",
            "episode : 4, timestep : 9996000, average reward : -56.709999084472656\n",
            "episode : 5, timestep : 9998400, average reward : -67.1500015258789\n",
            "finished training at :  20250630-185633\n"
          ]
        }
      ],
      "source": [
        "from math import log\n",
        "env_name = \"BipedalWalker-v3\"\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "\n",
        "eps_clip = 0.2\n",
        "K_epochs = 10\n",
        "gamma = 0.99\n",
        "lr_actor = 2.5e-4\n",
        "lr_critic = 5e-4\n",
        "random_seed = 13\n",
        "\n",
        "action_std = 0.6 # Initialize action_std\n",
        "\n",
        "log_dir = 'PPO_Bipelarwalk-v3_logs'\n",
        "if not os.path.exists(log_dir):\n",
        "  os.makedirs(log_dir)\n",
        "\n",
        "log_dir = log_dir + '/' + env_name + '/'\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "      os.makedirs(log_dir)\n",
        "\n",
        "run_num = 0\n",
        "current_num_files = next(os.walk(log_dir))[2]\n",
        "run_num = len(current_num_files)\n",
        "\n",
        "log_dir = log_dir + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "os.makedirs(log_dir)\n",
        "\n",
        "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
        "\n",
        "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
        "print(\"logging at : \" + log_f_name)\n",
        "\n",
        "print(\"state space dimension : \", state_dim)\n",
        "print(\"action space dimension : \", action_dim)\n",
        "print(\"starting std of action distribution\", action_std)\n",
        "\n",
        "print('-' * 50)\n",
        "print('PPO K epochs', K_epochs)\n",
        "print('PPO eps clip', eps_clip)\n",
        "print('PPO gamma', gamma)\n",
        "print('PPO learning rate actor', lr_actor)\n",
        "print('PPO learning rate critic', lr_critic)\n",
        "print('random seed', random_seed)\n",
        "print('-' * 50)\n",
        "\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma,K_epochs, eps_clip, action_std)\n",
        "\n",
        "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "print(\"started training at : \", start_time)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "log_f = open(log_f_name, \"w+\")\n",
        "log_f.write('episode, timestpe, reward \\n')\n",
        "\n",
        "print_running_reward = 0\n",
        "print_running_episodes = 0\n",
        "\n",
        "log_running_reward = 0\n",
        "log_running_episodes = 0\n",
        "\n",
        "max_training_steps = int(10e6)\n",
        "batch_size = 8192\n",
        "time_step = 0\n",
        "i_episode = 0\n",
        "\n",
        "max_ep_len = 600\n",
        "update_timestep = 2049\n",
        "log_freq = max_ep_len * 2\n",
        "print_freq = max_ep_len * 4\n",
        "\n",
        "action_std_decay_rate = 0.0001\n",
        "min_action_std = 0.1\n",
        "save_model_freq = int(2e4)\n",
        "\n",
        "action_std_decay_freq = 100000  # new\n",
        "last_decay_timestep = 0\n",
        "\n",
        "\n",
        "directory = directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}.pth\".format(env_name, random_seed)\n",
        "\n",
        "episode_rewards = []\n",
        "\n",
        "while time_step <= max_training_steps:\n",
        "  state, info = env.reset()\n",
        "  current_ep_reward = 0\n",
        "\n",
        "  for t in range(1, max_ep_len + 1):\n",
        "    action = ppo_agent.select_action(state) #select action\n",
        "    state, reward, done, truncated, info = env.step(action) #get next state, reward, if terminal from env\n",
        "    ppo_agent.buffer.rewards.append(reward) #append reward to buffer\n",
        "    ppo_agent.buffer.is_terminals.append(done) #append is terminal or not to buffer\n",
        "\n",
        "    time_step += 1\n",
        "    current_ep_reward += reward\n",
        "    episode_rewards.append(reward)\n",
        "\n",
        "    if len(ppo_agent.buffer.rewards) >= batch_size:\n",
        "      actor_loss, critic_loss, entropy = ppo_agent.update()\n",
        "      if time_step > 500000 and (time_step - last_decay_timestep) >= action_std_decay_freq:\n",
        "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "        last_decay_timestep = time_step\n",
        "      avg_reward = np.mean(episode_rewards[-50:])  # or longer window\n",
        "      print(f\"[{time_step}] Avg reward (last 50 episodes): {avg_reward}\")\n",
        "\n",
        "    if time_step % log_freq == 0:\n",
        "      log_average_reward = round(log_running_reward / log_running_episodes, 4)\n",
        "      log_f.write('{},{},{}\\n'.format(log_running_episodes, time_step, log_average_reward))\n",
        "      log_f.flush()\n",
        "\n",
        "      log_running_reward = 0\n",
        "      log_running_episodes = 0\n",
        "\n",
        "    if time_step % print_freq == 0:\n",
        "      print_average_reward = round(print_running_reward / print_running_episodes, 2)\n",
        "      print('episode : {}, timestep : {}, average reward : {}'.format(print_running_episodes, time_step, print_average_reward))\n",
        "      print_running_reward = 0\n",
        "      print_running_episodes = 0\n",
        "\n",
        "    if time_step % save_model_freq == 0 and time_step != 0:\n",
        "      ppo_agent.save(checkpoint_path)\n",
        "\n",
        "    if done or truncated: # Also check for truncation\n",
        "      break\n",
        "  print_running_reward += current_ep_reward\n",
        "  print_running_episodes += 1\n",
        "\n",
        "  log_running_reward += current_ep_reward\n",
        "  log_running_episodes += 1\n",
        "\n",
        "  i_episode += 1\n",
        "\n",
        "  # Decay action_std after each episode\n",
        "  if time_step > 500000 and (time_step - last_decay_timestep) >= action_std_decay_freq:\n",
        "    ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "    last_decay_timestep = time_step\n",
        "\n",
        "log_f.close()\n",
        "env.close()\n",
        "print(\"finished training at : \", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFAHgKypKFx2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Replace with the actual path to your log file\n",
        "log_file = '/content/PPO_Bipelarwalk-v3_logs/BipedalWalker-v3/20250629-045736/PPO_BipedalWalker-v3_log_0.csv'\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(log_file)\n",
        "\n",
        "# Strip whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "print(df.columns)\n",
        "plt.plot(df['timestpe'], df['reward'], label='Average Episode Reward', color='blue')\n",
        "\n",
        "# Smoothing using rolling average (optional)\n",
        "df['smoothed'] = df['reward'].rolling(window=10).mean()\n",
        "plt.plot(df['timestpe'], df['smoothed'], label='Smoothed Reward (window=10)', color='orange', linestyle='--')\n",
        "\n",
        "plt.title('PPO Training Reward Progress on BipedalWalker-v3')\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Reward')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}